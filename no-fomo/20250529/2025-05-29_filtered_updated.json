[
  {
    "id": "mDSMsZjDuSl5qcWckFSXrA",
    "source": "wechat",
    "url": "https://mp.weixin.qq.com/s/mDSMsZjDuSl5qcWckFSXrA",
    "title": "还得是华为！Pangu Ultra MoE架构：不用GPU，你也可以这样训练准万亿MoE大模型",
    "summary": "华为盘古团队发布Pangu Ultra MoE模型架构与训练方法，揭示其如何在昇腾NPU上成功训练准万亿MoE大模型而无需GPU。通过创新性的DSSN稳定架构和TinyInit小初始化方法，该模型解决了超大规模MoE训练稳定性难题，实现10+T tokens数据长稳训练。同时，引入EP group loss优化负载均衡，提升专家特化能力。Pangu Ultra MoE还融合MLA和MTP等先进架构，配合Dropless训练及迭代强化学习等技术，显著提升模型效率和推理性能。这标志着华为在芯片协同大模型领域取得突破性进展，为超大规模AI模型训练提供了新范式。",
    "keywords": [
      "PanguUltraMoE",
      "华为",
      "昇腾NPU",
      "MoE大模型",
      "训练方法",
      "稳定性",
      "负载均衡",
      "投机推理"
    ],
    "area": [
      "人工智能",
      "大模型",
      "深度学习"
    ],
    "published_time": "2025-05-29T04:53:51.000Z",
    "download_time": "2025-05-29T23:47:27.988944",
    "visual_resource": [
      "screenshot/wechat_wx_4d9e09e5.jpg"
    ],
    "extra_info": null
  },
  {
    "id": "lCjfKhFfOdTtC6uEvhJG4w",
    "source": "wechat",
    "url": "https://mp.weixin.qq.com/s/lCjfKhFfOdTtC6uEvhJG4w",
    "title": "AI仅凭“自信”学会推理，浙大校友复刻DeepSeek长思维链涌现，强化学习无需外部奖励信号",
    "summary": "加州大学伯克利分校团队提出突破性AI训练范式INTUITOR，使大语言模型首次能仅凭自身“自信度”学会复杂推理，实现长思维链涌现，彻底摆脱对外部奖励信号或人工标注数据的依赖。该方法通过优化模型内在置信度信号，有效规避了传统强化学习高昂成本及“奖励黑客”等问题。实验证明，INTUITOR在数学推理、代码生成及指令遵循任务上显著提升模型性能，尤其展现出卓越的结构化推理能力及多任务泛化性。此研究不仅为大模型训练带来新突破，更为AI迈向更自主、类人化的学习范式开启了全新可能。",
    "keywords": [
      "大模型",
      "强化学习",
      "内在奖励",
      "置信度",
      "长思维链",
      "推理能力",
      "AI训练"
    ],
    "area": [
      "人工智能",
      "机器学习",
      "大模型"
    ],
    "published_time": "2025-05-29T04:42:32.000Z",
    "download_time": "2025-05-29T23:49:09.156781",
    "visual_resource": [
      "screenshot/wechat_wx_2d97fb51.jpg"
    ],
    "extra_info": null
  },
  {
    "id": "wrq2ZkidYQ5PRGl525ol8A",
    "source": "wechat",
    "url": "https://mp.weixin.qq.com/s/wrq2ZkidYQ5PRGl525ol8A",
    "title": "刚刚，AI科学家Zochi在ACL「博士毕业」，Beta测试今日上线",
    "summary": "Intology公司近日宣布其“AI科学家”Zochi的论文被自然语言处理顶级会议ACL主会录用，标志着Zochi成为首个独立通过A*级别科学会议同行评审的人工智能系统，初步实现“博士级”智能体。Zochi自主完成了针对大型语言模型的“越狱”方法“Tempest”的设计、实验及论文撰写，成功率高达97-100%，揭示了当前LLM安全机制的潜在漏洞。尽管其提交方式引发部分争议，但Zochi在模型微调、生物计算等多个领域展现出卓越的自主研究能力和超越人类中位数表现的水平，预示着AI在科学发现领域的巨大潜力。",
    "keywords": [
      "AI科学家",
      "Zochi",
      "ACL",
      "同行评审",
      "大型语言模型",
      "智能体",
      "越狱",
      "自主研究"
    ],
    "area": [
      "人工智能",
      "智能体",
      "大模型"
    ],
    "published_time": "2025-05-29T04:53:51.000Z",
    "download_time": "2025-05-29T23:47:37.462327",
    "visual_resource": [
      "screenshot/wechat_wx_fca33049.jpg"
    ],
    "extra_info": null
  },
  {
    "id": "fq3F4OnOaG9PaF4_NKuRyg",
    "source": "wechat",
    "url": "https://mp.weixin.qq.com/s/fq3F4OnOaG9PaF4_NKuRyg",
    "title": "成本暴降88%！通义实验室、北大发布ZeroSearch，无需搜索即可激活LLM检索能力",
    "summary": "通义实验室与北京大学联合发布ZeroSearch框架，旨在解决大型语言模型（LLM）强化学习训练中，因频繁调用真实搜索引擎导致的高昂API成本及文档质量不可控问题。ZeroSearch通过创新性地利用LLM模拟搜索引擎，结合结构化训练模板、模拟搜索微调和基于课程学习的文档生成策略，实现了训练成本降低88%，并在多项任务上超越依赖真实搜索的方法。该框架显著提升了LLM的检索能力和推理表现，展示了其在基础模型和指令微调模型上的强大泛化能力，以及通过仅3B参数规模的模型便能激活检索能力，14B模型甚至超越谷歌搜索引擎的潜力，为LLM的推理能力激发提供了经济高效且高性能的新范式。",
    "keywords": [
      "ZeroSearch",
      "大模型",
      "强化学习",
      "检索增强生成",
      "成本优化",
      "课程学习",
      "检索能力"
    ],
    "area": [
      "大模型",
      "自然语言处理",
      "智能体"
    ],
    "published_time": "2025-05-29T04:53:51.000Z",
    "download_time": "2025-05-29T23:47:14.546914",
    "visual_resource": [
      "screenshot/wechat_wx_59538ad4.jpg"
    ],
    "extra_info": null
  },
  {
    "id": "TRtITbsVftG8zGR1HecljQ",
    "source": "wechat",
    "url": "https://mp.weixin.qq.com/s/TRtITbsVftG8zGR1HecljQ",
    "title": "SOTA大模型遇上加密数据评测：Qwen3未破10%，o1也栽了丨上海AI Lab等联合研究",
    "summary": "上海AI Lab联合推出的CipherBank评测揭示，当前SOTA大语言模型在密码学解密任务中表现普遍不佳，连最新的Qwen3系列准确率也未破10%。该评测聚焦真实隐私场景数据和多类型加密算法，旨在考验模型的严密逻辑与细节精确度。结果显示，即使是Claude-3.5和o1等领先模型，准确率也未能突破50%，暴露出LLM在处理结构化与符号化推理方面的显著短板。研究指出，模型惧怕长文本、噪音干扰、数字转换，且存在提示依赖症。未来AI发展需摆脱过度语义依赖，增强模式学习与泛化能力，并优化推理执行稳定性，以克服在密码学领域的挑战。",
    "keywords": [
      "大语言模型",
      "密码学",
      "CipherBank",
      "解密",
      "评测",
      "推理能力",
      "SOTA"
    ],
    "area": [
      "人工智能",
      "大模型",
      "自然语言处理"
    ],
    "published_time": "2025-05-29T04:42:32.000Z",
    "download_time": "2025-05-29T23:49:26.338471",
    "visual_resource": [
      "screenshot/wechat_wx_4080906e.jpg"
    ],
    "extra_info": null
  },
  {
    "id": "VE-3UCGJrHQ3feBga7svzA",
    "source": "wechat",
    "url": "https://mp.weixin.qq.com/s/VE-3UCGJrHQ3feBga7svzA",
    "title": "基准测试揭秘大模型“字数危机”：26个模型长文本生成普遍拉胯，最大输出长度过度宣传",
    "summary": "最新研究《LIFEBENCH》深入揭示大语言模型（LLMs）在遵循长度指令，特别是长文本生成方面的普遍不足。通过对26个主流模型进行基准测试，结果显示大多数模型在明确要求生成特定长度文本时表现糟糕，尤其在长文本场景中得分普遍低于40分，远低于其声称的最大输出能力。研究发现，模型存在缺乏准确长度感知、对输入长度敏感及懒惰生成策略等核心瓶颈。文章强调，未来需通过增强预训练数据和引入预规划策略，全面提升大模型对长度指令的遵循能力与实际表现。",
    "keywords": [
      "大语言模型",
      "长度指令",
      "长文本生成",
      "LIFEBENCH",
      "基准测试",
      "模型能力瓶颈",
      "生成式AI",
      "模型评估"
    ],
    "area": [
      "大模型",
      "自然语言处理",
      "生成式AI"
    ],
    "published_time": "2025-05-29T04:42:32.000Z",
    "download_time": "2025-05-29T23:49:37.340212",
    "visual_resource": [
      "screenshot/wechat_wx_80e9060d.jpg"
    ],
    "extra_info": null
  },
  {
    "id": "agenticSeek",
    "source": "GitHub",
    "url": "https://github.com/Fosowl/agenticSeek",
    "title": "AgenticSeek: Private, Local Manus Alternative.",
    "summary": "AgenticSeek是一个100%本地化、注重隐私的AI助手，旨在成为Manus AI的替代品。它完全在用户设备上运行，无需云服务，确保数据安全。该助手基于本地推理模型，具备自主网络浏览、代码编写、智能代理选择、复杂任务规划与执行以及语音交互能力。它为用户提供了一个完全私有、无云依赖的个人AI助理解决方案。",
    "keywords": [
      "本地AI",
      "隐私保护",
      "智能体",
      "网络浏览",
      "代码生成",
      "任务规划",
      "语音交互",
      "大模型"
    ],
    "area": [
      "人工智能",
      "智能体",
      "大模型"
    ],
    "published_time": "2025-05-28T06:42:18+00:00",
    "download_time": "2024-07-28 08:00:00",
    "visual_resource": [
      "https://raw.githubusercontent.com/Fosowl/agenticSeek/main/media/agentic_seek_logo.png"
    ],
    "extra_info": null
  },
  {
    "id": "langflow",
    "source": "GitHub",
    "url": "https://github.com/langflow-ai/langflow",
    "title": "Langflow",
    "summary": "Langflow是一个强大的工具，专注于构建和部署AI驱动的智能体及工作流。它提供直观的可视化构建界面和内置API服务器，能够将创建的智能体轻松转化为可集成到任何应用的技术接口。Langflow全面支持主流大语言模型、向量数据库和不断丰富的AI工具库，核心特性包括可视化构建、代码级定制、交互式Playground、多智能体编排、灵活的API部署选项以及与可观测性平台的集成。该项目支持自托管部署，并提供DataStax托管服务，具备企业级安全性和可扩展性。",
    "keywords": [
      "智能体",
      "工作流",
      "可视化构建",
      "API服务",
      "大语言模型",
      "向量数据库",
      "AI工具",
      "多智能体"
    ],
    "area": [
      "人工智能",
      "大模型",
      "智能体"
    ],
    "published_time": "2025-05-28T21:21:05Z",
    "download_time": "2024-07-29 10:00:00",
    "visual_resource": [
      "https://github.com/langflow-ai/langflow/raw/main/docs/static/img/langflow-logo-color-black-solid.svg",
      "https://api.star-history.com/svg?repos=langflow-ai/langflow&type=Timeline",
      "https://contrib.rocks/image?repo=langflow-ai/langflow"
    ],
    "extra_info": null
  },
  {
    "id": "ai-agents-for-beginners",
    "source": "GitHub",
    "url": "https://github.com/microsoft/ai-agents-for-beginners",
    "title": "AI Agents for Beginners - A Course",
    "summary": "微软发布面向初学者的AI智能体课程，共11节课，涵盖构建AI智能体的基础知识。课程内容包括智能体框架探索、设计模式（工具使用、RAG、规划、多智能体、元认知等）以及生产实践。课程使用微软的Azure AI Agent Service、Semantic Kernel和AutoGen等框架和服务，提供Python代码示例，支持Azure AI Foundry和GitHub Models。",
    "keywords": [
      "AI智能体",
      "智能体框架",
      "设计模式",
      "Semantic Kernel",
      "AutoGen",
      "RAG",
      "多智能体"
    ],
    "area": [
      "人工智能",
      "智能体",
      "生成式AI"
    ],
    "published_time": "2025-05-26T09:37:24Z",
    "download_time": "2024-07-29 10:00:00",
    "visual_resource": [
      "https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/images/repo-thumbnail.png"
    ],
    "extra_info": null
  },
  {
    "id": "chatgpt-on-wechat",
    "source": "GitHub",
    "url": "https://github.com/zhayujie/chatgpt-on-wechat",
    "title": "chatgpt-on-wechat",
    "summary": "chatgpt-on-wechat（CoW）是一个基于大模型的智能对话机器人项目，支持微信公众号、企业微信、飞书、钉钉等多平台接入。项目集成了GPT、Claude、Gemini、文心一言等多种主流大模型，具备处理文本、语音、图片的多模态能力。通过丰富的插件系统，可扩展联网搜索、文档总结、角色扮演等功能，并支持基于LinkAI平台构建自有知识库，适用于智能客服、私域运营等企业级AI应用场景。",
    "keywords": [
      "大模型",
      "智能对话机器人",
      "微信",
      "企业微信",
      "飞书",
      "钉钉",
      "语音识别",
      "图像生成",
      "插件",
      "知识库"
    ],
    "area": [
      "人工智能",
      "大模型",
      "自然语言处理"
    ],
    "published_time": "2025-05-25T09:44:28Z",
    "download_time": "2024-05-25 10:00:00",
    "visual_resource": [
      "https://cdn.link-ai.tech/image/link-ai-intro.jpg"
    ],
    "extra_info": null
  },
  {
    "id": "LivePortrait",
    "source": "GitHub",
    "url": "https://github.com/KwaiVGI/LivePortrait",
    "title": "LivePortrait: Efficient Portrait Animation with Stitching and Retargeting Control",
    "summary": "LivePortrait是一个高效的肖像动画生成项目，基于PyTorch实现，支持图像或视频驱动，具备拼接和重定向控制能力。其核心技术特点包括区域控制、精确编辑、动物模式支持、视频编辑（v2v）以及驱动视频自动裁剪等。项目提供了Windows一键安装包和macOS支持，并可通过Gradio界面或HuggingFace Space便捷体验。该技术在肖像动画、视频编辑及实时人脸控制等领域具有广泛应用潜力。",
    "keywords": [
      "肖像动画",
      "人脸动画",
      "视频生成",
      "计算机视觉",
      "深度学习",
      "PyTorch",
      "Gradio"
    ],
    "area": [
      "人工智能",
      "计算机视觉",
      "生成式AI"
    ],
    "published_time": "2025-02-28T13:56:34Z",
    "download_time": "2024-07-26 10:00:00",
    "visual_resource": [
      "https://raw.githubusercontent.com/KwaiVGI/LivePortrait/main/assets/docs/showcase2.gif",
      "https://raw.githubusercontent.com/KwaiVGI/LivePortrait/main/assets/docs/inference.gif",
      "https://raw.githubusercontent.com/KwaiVGI/LivePortrait/main/assets/docs/inference-animals.gif"
    ],
    "extra_info": null
  },
  {
    "id": "xiaozhi-esp32",
    "source": "GitHub",
    "url": "https://github.com/78/xiaozhi-esp32",
    "title": "小智 AI 聊天机器人 （XiaoZhi AI Chatbot）",
    "summary": "小智AI聊天机器人是一个开源项目，旨在帮助用户入门AI硬件开发，将大语言模型应用于ESP32等硬件设备。项目支持Wi-Fi/4G连接、离线唤醒、流式语音对话、多语言识别（SenseVoice）、声纹识别、多种大模型（Qwen, DeepSeek, Doubao）集成及TTS功能。它兼容多种ESP32芯片平台和开源硬件，提供软硬件教程，是探索AI与嵌入式结合的良好实践平台。",
    "keywords": [
      "AI聊天机器人",
      "ESP32",
      "大语言模型",
      "语音识别",
      "硬件开发",
      "物联网",
      "SenseVoice",
      "Qwen"
    ],
    "area": [
      "人工智能",
      "大模型",
      "机器人"
    ],
    "published_time": "2025-05-29T12:12:21+00:00",
    "download_time": "2024-07-29 10:00:00",
    "visual_resource": [
      "https://github.com/78/xiaozhi-esp32/raw/main/docs/wiring2.jpg",
      "https://github.com/78/xiaozhi-esp32/raw/main/docs/v1/espbox3.jpg"
    ],
    "extra_info": null
  },
  {
    "id": "2505.22457",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2505.22457",
    "title": "通过下一事件预测增强视频推理",
    "summary": "下一词元预测作为使大语言模型（LLMs）能够进行推理的基础学习任务。但是，当旨在赋予多模态大语言模型（MLLMs）处理视频输入的时间推理能力时，学习任务应该是什么？现有的任务，如视频问答，通常依赖于人类或更强的多模态大语言模型的标注，而视频字幕则倾向于将时间推理与空间信息纠缠在一起。为了弥补这一空白，我们提出了下一事件预测（NEP），这是一个利用未来视频片段作为丰富、自监督信号以促进时间推理的学习任务。我们将每个视频分割成过去和未来的帧：多模态大语言模型将过去的帧作为输入，并预测从未来帧提取的事件摘要，从而鼓励模型进行时间推理以完成任务。为了支持这项任务，我们整理了V1-33K数据集，该数据集包含33,000个自动提取的视频片段，涵盖了各种现实场景。我们进一步探索了一系列视频指令微调策略，以研究它们对时间推理的影响。为了评估进展，我们引入了FutureBench基准测试，用于评估预测未见过的未来事件的连贯性。实验验证了下一事件预测为增强多模态大语言模型的时间推理提供了一个可扩展且有效的训练范式。",
    "keywords": [
      "下一事件预测",
      "时间推理",
      "多模态大模型",
      "视频理解",
      "自监督学习"
    ],
    "area": [
      "视频理解",
      "多模态",
      "大模型"
    ],
    "published_time": "2025-05-28T15:13:34.000Z",
    "download_time": "2025-05-29 07:06:02",
    "visual_resource": [
      "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.22457.png"
    ],
    "extra_info": null
  },
  {
    "id": "2505.12667",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2505.12667",
    "title": "Safe-Sora：基于图形水印的安全文本到视频生成",
    "summary": "生成式视频模型的爆炸性增长加剧了对人工智能生成内容可靠版权保护的需求。尽管隐形生成水印在图像合成领域广受欢迎，但在视频生成领域的研究却相对不足。为弥补这一空白，我们提出了 Safe-Sora，这是首个将图形水印直接嵌入视频生成过程的框架。基于水印性能与水印和载体内容（即视频）之间视觉相似度密切相关的观察，我们引入了一种层级式由粗到精的自适应匹配机制。具体而言，水印图像被分割成块，每个块被分配给最相似的视频帧，并进一步定位到最佳空间区域以实现无缝嵌入。为了实现水印块在视频帧间的时空融合，我们开发了一种结合 3D 小波变换增强的 Mamba 架构，并采用了新颖的时空局部扫描策略，在水印嵌入和提取过程中有效建模长程依赖性。据我们所知，这是首次将状态空间模型应用于水印技术，为高效且鲁棒的水印保护开辟了新途径。广泛的实验表明，Safe-Sora 在视频质量、水印保真度及鲁棒性方面取得了最先进的性能，这主要归功于我们提出的方法。我们的代码将在论文发表后发布。",
    "keywords": [
      "Safe-Sora",
      "图形水印",
      "生成式视频",
      "Mamba 架构",
      "鲁棒性"
    ],
    "area": [
      "生成式AI",
      "计算机视觉",
      "多模态"
    ],
    "published_time": "2025-05-19T03:31:31.000Z",
    "download_time": "2025-05-29 07:12:56",
    "visual_resource": [
      "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.12667.png"
    ],
    "extra_info": null
  },
  {
    "id": "2505.20715",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2505.20715",
    "title": "MUSEG：通过时间戳感知多片段对齐增强视频时间理解",
    "summary": "视频时间理解对于多模态大型语言模型（MLLMs）推理视频中的事件至关重要。尽管通用视频理解取得了最新进展，但当前的多模态大模型在细粒度时间推理方面仍然存在困难。尽管最近探索了强化学习（RL）来解决此问题，但现有的强化学习方法效果仍然有限。在这项工作中，我们提出了 MUSEG，一种新颖的基于强化学习的方法，通过引入时间戳感知多片段对齐来增强时间理解。MUSEG 使多模态大模型能够将查询与多个相关的视频片段对齐，从而促进更全面的时间推理。为了促进有效学习，我们设计了一种定制的强化学习训练策略，采用分阶段奖励，逐步引导模型进行时间定位推理。在时间对齐和时间敏感的视频问答任务上的大量实验表明，MUSEG 显著优于现有方法，并在不同的时间理解场景中表现出良好的泛化能力。",
    "keywords": [
      "多片段对齐",
      "视频时间理解",
      "MLLMs",
      "强化学习",
      "时间推理"
    ],
    "area": [
      "多模态",
      "大模型",
      "视频理解"
    ],
    "published_time": "2025-05-27T04:50:07.000Z",
    "download_time": "2025-05-29 07:12:23",
    "visual_resource": [
      "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.20715.png"
    ],
    "extra_info": null
  },
  {
    "id": "2505.20411",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2505.20411",
    "title": "SWE-rebench：用于软件工程Agent任务收集和去污染评估的自动化流程",
    "summary": "基于LLM的Agent在日益增长的软件工程（SWE）任务中展现出令人瞩目的能力。然而，推进该领域面临两个关键挑战。首先，高质量的训练数据稀缺，特别是反映真实世界SWE场景的数据，Agent必须在此场景下与开发环境交互，执行代码并根据其行动结果调整行为。现有数据集要么仅限于一次性代码生成，要么由小规模、手动整理的交互式任务集合组成，缺乏规模和多样性。其次，新颖的交互式SWE任务的缺乏影响了对快速改进模型的评估，因为静态基准测试由于污染问题很快就会过时。为了解决这些局限性，我们引入了一种新颖、自动化且可扩展的流程，用于持续从不同的GitHub仓库中提取真实世界的交互式SWE任务。利用该流程，我们构建了SWE-rebench，这是一个包含超过21,000个基于Python的交互式SWE任务的公开数据集，适用于大规模SWE Agent的强化学习。此外，我们利用通过SWE-rebench方法收集的持续涌现的新鲜任务，构建了一个用于Agent化软件工程的无污染基准测试。我们将各种LLM在该基准测试上的结果与SWE-bench Verified上的结果进行比较，并发现某些语言模型的性能可能由于污染问题而被高估。",
    "keywords": [
      "SWE-rebench",
      "软件工程Agent",
      "自动化流程",
      "去污染评估",
      "交互式任务数据集"
    ],
    "area": [
      "人工智能",
      "大模型",
      "智能体"
    ],
    "published_time": "2025-05-26T18:01:00.000Z",
    "download_time": "2025-05-29 07:05:14",
    "visual_resource": [
      "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.20411.png"
    ],
    "extra_info": null
  },
  {
    "id": "2505.21582",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2505.21582",
    "title": "AITEE -- 电气工程智能体导师",
    "summary": "智能辅导系统结合大型语言模型为满足学生的多元化需求和促进自主高效学习提供了一种有前景的方法。尽管大型语言模型具备良好的电气工程基础知识，但在解决与电路相关的具体问题方面能力仍显不足。在本文中，我们介绍了 AITEE，一个基于智能体的电气工程辅导系统，旨在全程陪伴学生学习过程，提供个性化支持，并促进自主学习。AITEE 通过一种改进的电路重建过程支持手绘和数字电路，从而实现与学生的自然交互。我们新颖的基于图的相似性度量通过检索增强生成方法从讲义中识别相关上下文，而并行 Spice 仿真进一步提高了应用解题方法的准确性。该系统采用苏格拉底式对话来通过引导式提问培养学习者的自主性。实验评估表明，AITEE 在领域特定知识应用方面显著优于基线方法，即使是中等规模的 LLM 模型也表现出可接受的性能。我们的结果突出了智能体导师在电气工程教育中提供可扩展、个性化和有效学习环境的潜力。",
    "keywords": [
      "智能辅导系统",
      "大模型",
      "智能体",
      "电气工程",
      "检索增强生成 (RAG)"
    ],
    "area": [
      "人工智能",
      "大模型",
      "智能体"
    ],
    "published_time": "2025-05-27T10:07:05.000Z",
    "download_time": "2025-05-29 07:13:28",
    "visual_resource": [
      "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.21582.png"
    ],
    "extra_info": null
  },
  {
    "id": "2505.22312",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2505.22312",
    "title": "天工开源推理模型 1 号技术报告",
    "summary": "DeepSeek-R1 的成功凸显了强化学习 (RL) 在增强大型语言模型 (LLMs) 推理能力方面的重要作用。在本文中，我们提出了 Skywork-OR1，一种针对长链思维 (CoT) 模型的有效且可扩展的强化学习实现。基于 DeepSeek-R1-Distill 模型系列，我们的强化学习方法取得了显著的性能提升，将 Skywork-OR1-32B 模型在 AIME24、AIME25 和 LiveCodeBench 上的平均准确率从 57.8% 提高到 72.8% (+15.0%)，将 7B 模型从 43.6% 提高到 57.5% (+13.9%)。我们的 Skywork-OR1-32B 模型在 AIME24 和 AIME25 基准测试上超越了 DeepSeek-R1 和 Qwen3-32B，并在 LiveCodeBench 上取得了可比结果。Skywork-OR1-7B 和 Skywork-OR1-Math-7B 模型在同等规模模型中展现出具有竞争力的推理能力。我们对训练管线的核心组件进行了全面的消融研究，以验证其有效性。此外，我们深入研究了熵塌缩现象，确定了影响熵动态的关键因素，并表明缓解过早的熵塌缩对于提高测试性能至关重要。为了支持社区研究，我们完全开源了我们的模型权重、训练代码和训练数据集。",
    "keywords": [
      "Skywork-OR1",
      "强化学习",
      "大型语言模型",
      "链式思考",
      "推理能力"
    ],
    "area": [
      "人工智能",
      "大模型",
      "机器学习"
    ],
    "published_time": "2025-05-28T12:56:04.000Z",
    "download_time": "2025-05-29 07:04:39",
    "visual_resource": [
      "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.22312.png"
    ],
    "extra_info": null
  }
]