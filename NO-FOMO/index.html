<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Filtered Content</title>
    <style>
        body {
            font-family: sans-serif;
            line-height: 1.6;
            margin: 0;
            padding: 20px;
            background-color: #f4f4f4;
        }
        .container {
            max-width: 1000px;
            margin: auto;
            background: #fff;
            padding: 20px;
            border-radius: 8px;
            box-shadow: 0 0 10px rgba(0,0,0,0.1);
        }
        .source-group {
            margin-bottom: 30px;
            border-bottom: 2px solid #eee;
            padding-bottom: 20px;
        }
        .source-group:last-child {
            border-bottom: none;
        }
        .item-card {
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 15px;
            margin-bottom: 15px;
            background-color: #f9f9f9;
        }
        .item-card h3 {
            margin-top: 0;
            color: #333;
        }
        .item-card img {
            max-width: 100%;
            height: auto;
            border-radius: 4px;
            margin-top: 10px;
            margin-bottom: 10px;
        }
        .item-card p {
            margin-bottom: 10px;
        }
        .item-card .keywords, .item-card .area {
            font-size: 0.9em;
            color: #555;
        }
        .item-card .keywords span, .item-card .area span {
            background-color: #e7e7e7;
            padding: 2px 6px;
            border-radius: 3px;
            margin-right: 5px;
            display: inline-block;
            margin-bottom: 3px;
        }
        a {
            color: #007bff;
            text-decoration: none;
        }
        a:hover {
            text-decoration: underline;
        }
        .published-time {
            font-size: 0.85em;
            color: #777;
            margin-bottom: 8px;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>Filtered Content (2025-05-20 to 2025-05-21)</h1>

        <div class="source-group">
            <h2>GitHub</h2>
            <div class="item-card">
                <h3>HeyPuter/puter: 🌐 The Internet OS! Free, Open-Source, and Self-Hostable.</h3>
                <p class="published-time">Published: 2025-05-20T12:02:39.000Z</p>
                <p><strong>Summary:</strong> Puter是一个开放源代码的互联网操作系统，设计用于非常快速和易于扩展。它提供了一个隐私优先的个人云，允许用户在任何时间和地点访问其文件、应用程序和游戏。此外，Puter提供一个平台，可以用来构建和发布网站、网络应用和游戏。它提供一个替代DropBox、Google Drive及OneDrive等的强大工具，并可以作为服务器及工作站的远程桌面环境。Puter也是一个友好的开源项目和社区，让用户学习关于网络开发、云计算、分布式系统等知识。</p>
                <img src="https://assets.puter.site/puter.com-screenshot-3.webp" alt="Visual for HeyPuter/puter: 🌐 The Internet OS! Free, Open-Source, and Self-Hostable.">
                <p><a href="https://github.com/HeyPuter/puter" target="_blank">Read more</a></p>
                <p class="keywords">Keywords: <span>互联网操作系统</span> <span>开放源码</span> <span>云计算</span> <span>远程桌面</span> <span>个人云</span></p>
                <p class="area">Area: <span>智能体</span> <span>其他</span> <span>计算机视觉</span></p>
            </div>
            <div class="item-card">
                <h3>kortix-ai/suna: Suna - Open Source Generalist AI Agent</h3>
                <p class="published-time">Published: 2025-05-20T12:02:39.000Z</p>
                <p><strong>Summary:</strong> Suna 是一个完全开源的 AI 助手，能够通过自然对话帮助用户完成实际任务。它结合了浏览器自动化、文件管理、网络爬虫、命令行执行等强大功能，形成一个有效的工具包，解决复杂问题并自动化工作流程。通过无缝的界面理解用户需求并提供结果。</p>
                <img src="https://raw.githubusercontent.com/kortix-ai/suna/main/frontend/public/banner.png" alt="Visual for kortix-ai/suna: Suna - Open Source Generalist AI Agent">
                <p><a href="https://github.com/kortix-ai/suna" target="_blank">Read more</a></p>
                <p class="keywords">Keywords: <span>AI助手</span> <span>开源</span> <span>自动化</span> <span>文件管理</span> <span>数据分析</span></p>
                <p class="area">Area: <span>人工智能</span> <span>自动化</span> <span>生成式AI</span></p>
            </div>
            <div class="item-card">
                <h3>An AI Hedge Fund Team</h3>
                <p class="published-time">Published: 2025-05-20T12:02:39.000Z</p>
                <p><strong>Summary:</strong> 本项目是一个人工智能驱动的对冲基金概念验证，旨在研究如何利用人工智能做出交易决策。项目设置了多个模拟知名投资者的代理人，这些代理人通过不同策略分析市场，并生成交易信号，最终由投资组合管理者决定实施。项目仅用于教育和研究目的。</p>
                <img src="https://raw.githubusercontent.com/yourusername/yourrepo/main/assets/hedge-fund-banner.png" alt="Visual for An AI Hedge Fund Team">
                <p><a href="https://github.com/virattt/ai-hedge-fund" target="_blank">Read more</a></p>
                <p class="keywords">Keywords: <span>AI</span> <span>对冲基金</span> <span>交易决策</span> <span>代理人</span> <span>教育</span></p>
                <p class="area">Area: <span>人工智能</span> <span>金融</span> <span>智能体</span></p>
            </div>
        </div>
        <div class="source-group">
            <h2>Twitter</h2>
            <div class="item-card">
                <h3>Everybody is doing AI agents</h3>
                <p class="published-time">Published: 2025-05-20T12:57:00Z</p>
                <p><strong>Summary:</strong> 大家现在都在做AI代理。这是一个做得很好的应用示例：@genspark_ai的AI Sheets让你可以直接与电子表格对话，你可以上传文件，询问任何数据分析问题，它会自动分析所有内容，提取信息...</p>
                <p><a href="https://x.com/fchollet/status/1924509605050327475" target="_blank">Read more</a></p>
                <p class="keywords">Keywords: <span>AI代理</span> <span>应用</span> <span>AI Sheets</span> <span>数据分析</span> <span>电子表格</span></p>
                <p class="area">Area: <span>人工智能</span> <span>智能体</span> <span>自然语言处理</span></p>
            </div>
        </div>
        <div class="source-group">
            <h2>wechat</h2>
            <div class="item-card">
                <h3>微软一夜50弹，纳德拉要建智能体伊甸园！0代码引发编程科研大地震</h3>
                <p class="published-time">Published: 2025-05-20T04:56:18.000Z</p>
                <p><strong>Summary:</strong> 微软Build 2025大会上，纳德拉宣布进入AI智能体时代，发布了包括Coding Agent、Microsoft Discovery、NLWeb等在内的多项重大更新。Coding Agent通过GitHub Copilot实现全能编程，提升开发效率；Microsoft Discovery平台变革科研流程，加速科学发现；NLWeb实现自然语言与网站交互。微软还与xAI合作，将Grok系列模型接入Azure，并透露Grok 3.5将基于第一性原理进行推理。大会展示了AI智能体在编程、科研等领域的广泛应用，以及微软在构建开放智能体生态系统上的决心。</p>
                <img src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/UicQ7HgWiaUb3vXaRQMFkL6tdYCdhQibnauH1shpUj153PSbMJ5DRiaXUdZ3vH6JqrtVZAiapALGnV1iahj0l7yzh8kQ/0?wx_fmt=jpeg" alt="Visual for 微软一夜50弹，纳德拉要建智能体伊甸园！0代码引发编程科研大地震">
                <p><a href="https://mp.weixin.qq.com/s/ecGIOeZk4wA-rx5UPiTxgg" target="_blank">Read more</a></p>
                <p class="keywords">Keywords: <span>微软发布</span> <span>AI智能体时代</span> <span>Coding Agent编程</span> <span>Microsoft Discovery科研</span> <span>Grok 3.5推理</span> <span>GitHub Copilot</span> <span>NLWeb交互</span> <span>纳德拉宣布</span></p>
                <p class="area">Area: <span>人工智能</span> <span>深度学习</span> <span>生成式AI</span></p>
            </div>
        </div>
        <div class="source-group">
            <h2>huggingface</h2>
            <div class="item-card">
                <h3>AdaptThink：推理模型可学会何时进行思考</h3>
                <p class="published-time">Published: 2025-05-19T17:50:52.000Z</p>
                <p><strong>Summary:</strong> 近来，大型推理模型通过采用类人式深度思考，在各种任务上取得了令人瞩目的表现。然而，冗长的思考过程显著增加了推理开销，使效率成为一个关键瓶颈。在这项工作中，我们首先证明，NoThinking（即提示推理模型跳过思考直接生成最终解决方案）对于相对简单的任务而言，在性能和效率两方面都是更好的选择。受此启发，我们提出了 AdaptThink，这是一种新颖的强化学习算法，旨在教导推理模型根据问题难度自适应地选择最优的思考模式。具体而言，AdaptThink包含两个核心组件：（1）一个约束优化目标，鼓励模型在保持整体性能的同时选择 NoThinking；（2）一种重要性采样策略，在on-policy训练期间平衡 Thinking 和 NoThinking 样本，从而实现冷启动，并使模型能够在整个训练过程中探索和利用这两种思考模式。我们的实验表明，AdaptThink在显著降低推理成本的同时，进一步提升了性能。值得注意的是，在三个数学数据集上，AdaptThink将 DeepSeek-R1-Distill-Qwen-1.5B 的平均响应长度缩短了 53%，并将其准确率提高了 2.4%，这突显了自适应思考模式选择在优化推理质量与效率平衡方面的潜力。我们的代码和模型可在 https://github.com/THU-KEG/AdaptThink 获取。</p>
                <img src="https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.13417.png" alt="Visual for AdaptThink：推理模型可学会何时进行思考">
                <p><a href="https://huggingface.co/papers/2505.13417" target="_blank">Read more</a></p>
                <p class="keywords">Keywords: <span>推理模型</span> <span>思考模式</span> <span>效率优化</span> <span>强化学习</span> <span>自适应选择</span></p>
                <p class="area">Area: <span>人工智能</span> <span>机器学习</span> <span>大模型</span></p>
            </div>
            <div class="item-card">
                <h3>无思：大型语言模型学会何时思考</h3>
                <p class="published-time">Published: 2025-05-19T17:24:16.000Z</p>
                <p><strong>Summary:</strong> 具备扩展链式思考能力的推理语言模型，在需要复杂逻辑推理的任务上已经展现出卓越的性能。然而，为所有查询应用详细推理常常导致显著的计算效率低下，尤其是在许多问题存在直接解决方案的情况下。这引出了一个开放性问题：大型语言模型能否学会何时思考？为了回答这个问题，我们提出了 Thinkless，一个可学习的框架，使大型语言模型能够根据任务复杂度和模型能力，自适应地选择简略推理或长形式推理。Thinkless 在强化学习范式下进行训练，并采用两个控制 token，<short> 用于简洁响应，<think> 用于详细推理。我们方法的核心是解耦组相对策略优化（DeGRPO）算法，该算法将混合推理的学习目标分解为两个组成部分：(1) 一个控制 token 损失，用于管理推理模式的选择；以及 (2) 一个响应损失，用于提高生成答案的准确性。这种解耦的公式能够对每个目标项的贡献进行细粒度控制，稳定训练并有效防止在 vanilla GRPO 中观察到的崩溃。实验结果表明，在 Minerva Algebra、MATH-500 和 GSM8K 等多个基准数据集上，Thinkless 能够将长链思考的使用减少 50% - 90%，显著提高了推理语言模型的效率。代码已开源于 https://github.com/VainF/Thinkless</p>
                <img src="https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.13379.png" alt="Visual for 无思：大型语言模型学会何时思考">
                <p><a href="https://huggingface.co/papers/2505.13379" target="_blank">Read more</a></p>
                <p class="keywords">Keywords: <span>推理语言模型</span> <span>自适应推理</span> <span>强化学习</span> <span>策略优化</span> <span>效率优化</span></p>
                <p class="area">Area: <span>大型语言模型</span> <span>自然语言处理</span> <span>机器学习</span></p>
            </div>
            <div class="item-card">
                <h3>通过用户界面分解与合成实现计算机使用定位能力的规模化</h3>
                <p class="published-time">Published: 2025-05-19T15:09:23.000Z</p>
                <p><strong>Summary:</strong> 图形用户界面（GUI）定位，即将自然语言指令映射到图形用户界面上的特定操作的能力，仍然是计算机使用智能体开发中的关键瓶颈。当前的评测基准将定位任务过度简化为简短的指向性表达，未能捕捉到需要软件常识、布局理解和精细操作能力的真实世界交互的复杂性。为了解决这些局限性，我们引入了OSWorld-G，这是一个综合性评测基准，包含跨越文本匹配、元素识别、布局理解和精确操作等多种任务类型的564个精细标注样本。此外，我们通过任务的多视角解耦合成并发布了最大的计算机使用定位数据集Jedi，该数据集包含400万个样本。我们在Jedi上训练的多尺度模型通过在ScreenSpot-v2、ScreenSpot-Pro和我们的OSWorld-G上超越现有方法证明了其有效性。此外，我们证明了使用Jedi改进定位能力能够直接增强通用基础模型在复杂计算机任务上的智能体能力，将OSWorld上的性能从5%提升到27%。通过详细的消融研究，我们确定了影响定位性能的关键因素，并验证了结合针对不同界面元素的专项数据可以实现对新界面的组合泛化。所有的评测基准、数据、检查点和代码均已开源，可在https://osworld-grounding.github.io获取。</p>
                <img src="https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.13227.png" alt="Visual for 通过用户界面分解与合成实现计算机使用定位能力的规模化">
                <p><a href="https://huggingface.co/papers/2505.13227" target="_blank">Read more</a></p>
                <p class="keywords">Keywords: <span>GUI Grounding</span> <span>用户界面分解与合成</span> <span>OSWorld-G</span> <span>Jedi</span> <span>计算机使用智能体</span></p>
                <p class="area">Area: <span>智能体</span> <span>多模态</span> <span>自然语言处理</span></p>
            </div>
            <div class="item-card">
                <h3>AdaCoT：通过强化学习实现帕累托最优的自适应思维链触发</h3>
                <p class="published-time">Published: 2025-05-17T08:27:00.000Z</p>
                <p><strong>Summary:</strong> 大语言模型（LLMs）展现出卓越的能力，但在需要复杂推理的任务上常面临挑战。思维链（CoT）提示显著增强了推理能力，但它不加区分地为所有查询生成冗长的推理步骤，特别对于简单输入，导致计算成本高昂且效率低下。为了解决这一关键问题，我们引入了 AdaCoT（自适应思维链），这是一个使 LLMs 能够自适应决定何时调用 CoT 的新颖框架。AdaCoT 将自适应推理构建为一个帕累托优化问题，旨在平衡模型性能与调用 CoT 相关的成本（包括频率和计算开销）。我们提出一种基于强化学习（RL）的方法，具体利用近端策略优化（PPO），通过调整惩罚系数来动态控制 CoT 触发决策边界，从而使模型能够根据隐式的查询复杂度判断 CoT 的必要性。一个关键的技术贡献是选择性损失掩码（SLM），它旨在对抗多阶段 RL 训练中的决策边界崩溃，确保稳健和稳定的自适应触发。实验结果表明，AdaCoT 成功地沿着帕累托前沿行进，显著减少了对于不需要复杂推理的查询的 CoT 使用。例如，在我们实际生产流量测试集上，AdaCoT 将 CoT 触发率降低至低至 3.18%，并将平均响应 token 数减少了 69.06%，同时在复杂任务上保持了高性能。</p>
                <img src="https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.11896.png" alt="Visual for AdaCoT：通过强化学习实现帕累托最优的自适应思维链触发">
                <p><a href="https://huggingface.co/papers/2505.11896" target="_blank">Read more</a></p>
                <p class="keywords">Keywords: <span>大语言模型 (LLMs)</span> <span>思维链 (CoT)</span> <span>自适应触发</span> <span>强化学习 (RL)</span> <span>帕累托优化</span></p>
                <p class="area">Area: <span>大模型</span> <span>自然语言处理</span> <span>机器学习</span></p>
            </div>
            <div class="item-card">
                <h3>语言模型的模型链学习</h3>
                <p class="published-time">Published: 2025-05-17T04:06:12.000Z</p>
                <p><strong>Summary:</strong> 在本文中，我们提出了一种新颖的学习范式，称之为模型链（Chain-of-Model, CoM）。该范式将因果关系以链式风格融入到每一层的隐藏状态中，从而在模型训练中引入显著的扩展效率，并在部署中提供灵活的推理。我们引入了表示链（Chain-of-Representation, CoR）的概念，将每一层的隐藏状态视为在隐藏维度层面由多个子表示（即链）组合而成。在每一层中，输出表示中的每个链只能看到输入表示中其所有前置链。因此，基于 CoM 框架构建的模型可以通过在先前模型（即链）的基础上增加链的数量来逐步扩展模型尺寸，并通过使用不同数量的链为弹性推理提供多种不同尺寸的子模型。基于这一原则，我们设计了语言模型链（Chain-of-Language-Model, CoLM），它将 CoM 的思想融入到 Transformer 架构的每一层中。基于 CoLM，我们通过引入 KV 共享机制进一步提出了 CoLM-Air，该机制计算第一个链内的所有键和值，并在所有链之间共享。这种设计展示了额外的可扩展性，例如支持无缝的语言模型切换、预填充加速等。实验结果表明，我们的 CoLM 系列模型可以实现与标准 Transformer 相当的性能，同时提供了更大的灵活性，例如通过渐进式扩展提高训练效率，并为弹性推理提供多种不同尺寸的模型，为构建语言模型开辟了一条新途径。我们的代码将来会在 https://github.com/microsoft/CoLM 发布。</p>
                <img src="https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.11820.png" alt="Visual for 语言模型的模型链学习">
                <p><a href="https://huggingface.co/papers/2505.11820" target="_blank">Read more</a></p>
                <p class="keywords">Keywords: <span>Chain-of-Model</span> <span>语言模型</span> <span>深度学习</span> <span>扩展效率</span> <span>弹性推理</span></p>
                <p class="area">Area: <span>自然语言处理</span> <span>深度学习</span> <span>大模型</span></p>
            </div>
            <div class="item-card">
                <h3>差分注意力：通过差分校正实现快速准确的稀疏注意力推理</h3>
                <p class="published-time">Published: 2025-05-16T13:48:33.000Z</p>
                <p><strong>Summary:</strong> Transformer的注意力机制具有二次复杂度，导致处理长序列时推理成本高、延迟大。然而，注意力矩阵大多是稀疏的，这意味着可以省略许多条目来提高推理效率。稀疏注意力推理方法旨在减轻这种计算负担；然而，它们也伴随着令人烦恼的性能下降。我们发现这种性能下降的一个原因是稀疏计算导致了注意力输出的分布偏移。这种分布偏移导致解码阶段的查询无法与预填充阶段的相应键良好对齐，从而导致性能下降。我们提出了一种简单、新颖且有效的程序来校正这种分布偏移，使稀疏注意力输出的分布更接近二次注意力。我们的方法可以应用于任何稀疏注意力方法之上，平均性能提升36%pt，在13.1万 RULER 基准上应用滑动窗口注意力和 Sink tokens 时，恢复了二次注意力的88%的准确率，且仅增加了少量开销。我们的方法可以相对于完整二次注意力保持约98.5%的稀疏度，使得在处理100万 token 预填充时，我们的模型比 Flash Attention 2 快32倍。</p>
                <img src="https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.11254.png" alt="Visual for 差分注意力：通过差分校正实现快速准确的稀疏注意力推理">
                <p><a href="https://huggingface.co/papers/2505.11254" target="_blank">Read more</a></p>
                <p class="keywords">Keywords: <span>Delta Attention</span> <span>稀疏注意力</span> <span>注意力推理</span> <span>分布偏移</span> <span>差分校正</span></p>
                <p class="area">Area: <span>深度学习</span> <span>自然语言处理</span> <span>大模型</span></p>
            </div>
        </div>

    </div>
</body>
</html>