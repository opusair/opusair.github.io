[
  {
    "id": "twitter_OpenRouterAI_1965451870794559609",
    "source": "Twitter",
    "url": "https://twitter.com/OpenRouterAI/status/1965451870794559609",
    "published_time": "2025-09-09T16:26:56.000Z",
    "download_time": "2025-09-10 06:00:31",
    "visual_resource": [
      "screenshot/twitter/OpenRouterAI_1965451870794559609.png"
    ],
    "extra_info": "{\"username\": \"OpenRouterAI\", \"tweet_id\": \"1965451870794559609\"}",
    "title_en": "OpenRouterAI_Welcomes NVIDIA and Launches Nemotron Nano 9B Model",
    "summary_en": "OpenRouter announced the welcoming of NVIDIA to its platform and the launch of its first model, Nemotron Nano 9B. This model is offered for free, features a 128k context window, is pre-trained from scratch with reasoning capabilities, and is ZDR-enabled. This marks a significant step for OpenRouter in building its model ecosystem, providing users with a high-performance and easily accessible AI model.",
    "keywords_en": [
      "OpenRouter",
      "NVIDIA",
      "Nemotron Nano 9B",
      "Large Language Model",
      "Free Model",
      "Context Window"
    ],
    "area_en": [
      "Large Language Model",
      "Product Launch",
      "Tech News"
    ]
  },
  {
    "id": "twitter_wavespeed_ai_1965358098945867967",
    "source": "Twitter",
    "url": "https://x.com/wavespeed_ai/status/1965358098945867967/photo/1",
    "published_time": "2025-09-09T10:14:20.000Z",
    "download_time": "2025-09-10 06:17:45",
    "visual_resource": [
      "screenshot/twitter/wavespeed_ai_1965358098945867967.png"
    ],
    "extra_info": "{\"username\": \"wavespeed_ai\", \"tweet_id\": \"1965358098945867967\"}",
    "title_en": "wavespeed_ai_Seedream 4.0 Launch: New Breakthrough in AI Image Generation",
    "summary_en": "WaveSpeedAI has officially launched Seedream 4.0, representing a significant advancement in the field of AI image generation. This cutting-edge version introduces several key features, including highly precise prompt editing, ensuring extreme fidelity and meticulous feature preservation in generated images. Furthermore, it boasts a deep understanding of user intent, facilitating more accurate and desired outputs. The system also supports versatile multi-image input and output capabilities, coupled with ultra-fast and ultra-HD rendering, designed to deliver an unparalleled image creation experience right from the initial concept phase.",
    "keywords_en": [
      "Seedream 4.0",
      "AI Image Generation",
      "Image Fidelity",
      "Prompt Editing",
      "WaveSpeedAI",
      "HD Rendering"
    ],
    "area_en": [
      "Generative AI",
      "Product Launch",
      "Computer Vision"
    ]
  },
  {
    "id": "twitter_Thom_Wolf_1965521320306942312",
    "source": "Twitter",
    "url": "https://x.com/Thom_Wolf/status/1965521320306942312",
    "published_time": "2025-09-09T21:02:55.000Z",
    "download_time": "2025-09-10 06:22:59",
    "visual_resource": [
      "screenshot/twitter/Thom_Wolf_1965521320306942312.png"
    ],
    "extra_info": "{\"username\": \"Thom_Wolf\", \"tweet_id\": \"1965521320306942312\"}",
    "title_en": "Thom_Wolf_Exploring Diffusion Models in Text and Code Generation",
    "summary_en": "Prominent AI researcher Thomas Wolf, in a recent tweet, questioned why there aren't more teams and startups focusing on diffusion models for text and code generation. He highlighted the significant potential of these models in such applications, implicitly calling for greater attention and investment in this promising yet seemingly underexplored technological frontier, prompting reflection on its commercialization and industrialization progress.",
    "keywords_en": [
      "Diffusion Models",
      "Text Generation",
      "Code Generation",
      "Generative AI",
      "Industry Observation"
    ],
    "area_en": [
      "Generative AI",
      "Natural Language Processing",
      "Industry News"
    ]
  },
  {
    "id": "twitter_natolambert_1965470452316561785",
    "source": "Twitter",
    "url": "https://x.com/natolambert/status/1965470452316561785",
    "published_time": "2025-09-09T17:40:47.000Z",
    "download_time": "2025-09-10 06:16:00",
    "visual_resource": [
      "screenshot/twitter/natolambert_1965470452316561785.png"
    ],
    "extra_info": "{\"username\": \"natolambert\", \"tweet_id\": \"1965470452316561785\"}",
    "title_en": "natolambert_K2 Think Model Launch: A Mathematical Reasoning System Based on Qwen 2.5 32B",
    "summary_en": "Nathan Lambert retweeted and commented on Taylor W. Killian's announcement of the K2 Think model. K2 Think, built by LLM360, is based on Qwen 2.5 32B, distinct from LLM360's K2 65B base model. Primarily designed for mathematical reasoning, it has proven quite versatile and is now live as a deployed reasoning system at k2think.ai. Lambert also hinted at the team's further plans in the fully open-source space.",
    "keywords_en": [
      "K2 Think",
      "LLM360",
      "Qwen 2.5 32B",
      "Mathematical Reasoning",
      "Open Source Model",
      "Model Launch"
    ],
    "area_en": [
      "Large Language Model",
      "Open Source",
      "Tech News"
    ]
  },
  {
    "id": "twitter_abeirami_1965402721579860318",
    "source": "Twitter",
    "url": "https://x.com/abeirami/status/1965402721579860318",
    "published_time": "2025-09-09T13:11:38.000Z",
    "download_time": "2025-09-10 06:21:04",
    "visual_resource": [
      "screenshot/twitter/abeirami_1965402721579860318.png"
    ],
    "extra_info": "{\"username\": \"abeirami\", \"tweet_id\": \"1965402721579860318\"}",
    "title_en": "abeirami_LLM Nonlinear Reasoning and Human Cognition Challenges",
    "summary_en": "Ahmad Beirami and Minh Nhat Nguyen's tweets discuss the limitations of Large Language Models (LLMs) in simulating human-like nonlinear reasoning. Minh Nhat points out that current LLM reasoning and training are largely based on linear logic, failing to fully explore the inherent nonlinearity of human thought. Beirami humorously questions if anyone is training LLMs for nonlinear breakthrough reasoning akin to a \"hangover shower breakthrough.\" This prompts reflection on the future direction of LLM development and the simulation of deeper cognitive abilities, emphasizing the necessity of moving beyond linear paradigms.",
    "keywords_en": [
      "Large Language Models",
      "Nonlinear Reasoning",
      "Human Cognition",
      "AI Reasoning",
      "LLM Capabilities"
    ],
    "area_en": [
      "Artificial Intelligence",
      "Large Language Model",
      "Research Progress"
    ]
  },
  {
    "id": "twitter_fchollet_1965551724653109514",
    "source": "Twitter",
    "url": "https://x.com/fchollet/status/1965551724653109514",
    "published_time": "2025-09-09T23:03:43.000Z",
    "download_time": "2025-09-10 06:10:11",
    "visual_resource": [
      "screenshot/twitter/fchollet_1965551724653109514.png"
    ],
    "extra_info": "{\"username\": \"fchollet\", \"tweet_id\": \"1965551724653109514\"}",
    "title_en": "fchollet_Understanding vs. Memorization: Human Learning Superior to AI Models",
    "summary_en": "Prominent AI researcher François Chollet argues that a student who truly understands the physics principle F=ma possesses a superior ability to solve novel problems compared to a Transformer model that has merely memorized every physics textbook. This profound observation underscores the fundamental distinction between human understanding and AI's current reliance on pattern recognition and vast data memorization. It highlights a significant challenge for contemporary AI models in achieving true generalization and tackling unfamiliar scenarios, suggesting that deep comprehension remains a key differentiator.",
    "keywords_en": [
      "François Chollet",
      "Understanding",
      "Memorization",
      "Transformer",
      "Artificial Intelligence",
      "Learning Capability"
    ],
    "area_en": [
      "Artificial Intelligence",
      "Deep Learning",
      "Research Progress"
    ]
  },
  {
    "id": "eMy2hRb7joKQHqfaUKTOSA",
    "source": "wechat",
    "url": "https://mp.weixin.qq.com/s/eMy2hRb7joKQHqfaUKTOSA",
    "published_time": "2025-09-09T23:30:27.000Z",
    "download_time": "2025-09-10T14:44:02.589623",
    "visual_resource": [
      "screenshot/wechat/wechat_image_eMy2hRb7joKQHqfaUKTOSA.png"
    ],
    "extra_info": null,
    "title_en": "Domestic Vidu Q1 Surprises with Reference-Based Image Generation, Achieving High Consistency and Realism",
    "summary_en": "Less than 10 days after Google's Nano Banana release, China's Vidu Q1 launched its \"reference-based image generation\" feature, marking a significant breakthrough in image synthesis. This new capability supports up to seven reference images, demonstrating exceptional performance in consistency, realism, clarity, and semantic understanding, surpassing Flux Kontext and rivaling Nano Banana. Vidu Q1 particularly emphasizes its \"production-level application\" potential. By ensuring robust subject consistency and offering extensive creative freedom, it effectively addresses common issues of instability and discontinuity in AI-generated content. This makes Vidu Q1 highly valuable for industries such as e-commerce, advertising, and media, signaling a new era where AI video and image generation tools become truly usable for professional scenarios.",
    "keywords_en": [
      "Vidu Q1",
      "Reference-based Image Generation",
      "Image Generation",
      "Consistency",
      "Generative AI"
    ],
    "area_en": [
      "Generative AI",
      "Computer Vision",
      "Multimodal"
    ]
  },
  {
    "id": "5GmgV9wzEi53cDlE4CTohw",
    "source": "wechat",
    "url": "https://mp.weixin.qq.com/s/5GmgV9wzEi53cDlE4CTohw",
    "published_time": "2025-09-09T23:30:27.000Z",
    "download_time": "2025-09-10T14:43:56.095398",
    "visual_resource": [
      "screenshot/wechat/wechat_image_5GmgV9wzEi53cDlE4CTohw.png"
    ],
    "extra_info": null,
    "title_en": "DeepMind's RoboBallet: AlphaGo Author-Led System Enables Collision-Free Collaboration of 8 Robotic Arms, Published in Science Robotics",
    "summary_en": "DeepMind's latest research, RoboBallet, led by AlphaGo author Matthew Lai, innovatively integrates Graph Neural Networks (GNNs) with Reinforcement Learning (RL) to address complex motion planning, task assignment, and scheduling challenges in large-scale multi-robot collaboration. This system efficiently coordinates up to eight robotic arms, achieving collision-free operation with planning steps as fast as 0.3 milliseconds, and demonstrates remarkable zero-shot generalization capabilities. By modeling the scene as a graph structure and utilizing GNNs as the policy network, RoboBallet significantly enhances the efficiency and robustness of multi-robot cooperation in automated manufacturing. It offers a highly efficient and scalable solution for industrial applications, overcoming traditional algorithmic limitations in complex, high-dimensional environments.",
    "keywords_en": [
      "RoboBallet",
      "Robotic Arm",
      "Graph Neural Network",
      "Reinforcement Learning",
      "Multi-Robot Collaboration",
      "Zero-Shot Generalization"
    ],
    "area_en": [
      "Robotics",
      "Artificial Intelligence",
      "Deep Learning"
    ]
  },
  {
    "id": "jBjb04y8XY03huEMNbu5tw",
    "source": "wechat",
    "url": "https://mp.weixin.qq.com/s/jBjb04y8XY03huEMNbu5tw",
    "published_time": "2025-09-09T12:17:47.000Z",
    "download_time": "2025-09-10T14:44:28.808981",
    "visual_resource": [
      "screenshot/wechat/wechat_image_jBjb04y8XY03huEMNbu5tw.png"
    ],
    "extra_info": null,
    "title_en": "Wenxin X1.1 Launched: Three Key Capabilities Highlighted with Hands-on Testing",
    "summary_en": "Baidu has officially launched Wenxin Large Model X1.1, demonstrating significant advancements in factuality, instruction following, and agent capabilities. Hands-on tests reveal its performance surpasses DeepSeek R1-0528 and is comparable to leading models like GPT-5 and Gemini 2.5 Pro. The article showcases its robust functionalities through practical examples such as intelligent customer service, code generation, and logical reasoning. Concurrently, Baidu has open-sourced the deep thinking model ERNIE-4.5-21B-A3B-Thinking, introduced the ERNIEKit development suite, and upgraded its PaddlePaddle framework to v3.2, comprehensively optimizing model training and inference efficiency. This strategic move underscores Baidu's commitment to a full-stack AI ecosystem, encompassing chips, frameworks, models, and applications, aimed at continuously lowering AI development barriers and empowering innovation for developers.",
    "keywords_en": [
      "Wenxin Large Model",
      "PaddlePaddle",
      "AI Agent",
      "Deep Thinking",
      "Open Source",
      "Large Model Development"
    ],
    "area_en": [
      "Large Language Model",
      "AI Agent",
      "Deep Learning"
    ]
  },
  {
    "id": "Mu2cj_ZugmQxCiJklHj9uQ",
    "source": "wechat",
    "url": "https://mp.weixin.qq.com/s/Mu2cj_ZugmQxCiJklHj9uQ",
    "published_time": "2025-09-09T13:30:52.000Z",
    "download_time": "2025-09-10T14:43:59.050950",
    "visual_resource": [
      "screenshot/wechat/wechat_image_Mu2cj_ZugmQxCiJklHj9uQ.png"
    ],
    "extra_info": null,
    "title_en": "China's AI Overtakes with Domestic GPU Training! Transformer-Free, Native Brain-Inspired Spiking Large Model \"SpikingBrain\" Emerges",
    "summary_en": "“SpikingBrain,” a novel brain-inspired spiking large model developed by researchers from institutions including the Chinese Academy of Sciences, aims to overcome the limitations of Transformer architecture and reliance on NVIDIA GPUs. By adopting a linear complexity architecture and a pulse-based computing mechanism, SpikingBrain achieves significant breakthroughs in long sequence processing efficiency, domestic hardware compatibility, and low-power applications. The model successfully completed full-process training and deployment on domestic MetaX GPU clusters, validating the capability of China's AI software and hardware ecosystem to support large-scale model training. SpikingBrain's performance matches mainstream models, demonstrating over 100x inference speed improvement when processing 4M long sequences, and its spiking scheme boosts energy efficiency by 43 times. This marks a crucial step for China in independent AI innovation concerning foundational model architecture, training algorithms, and hardware adaptation. It offers an asymmetric competitive advantage by addressing the efficiency bottleneck of long sequences and enabling autonomous control over AI computing power, positioning China to potentially lead the development of next-generation AI technologies. This innovation paves the way for energy-efficient, self-reliant AI systems, reducing dependence on external supplies and fostering a robust domestic AI ecosystem.",
    "keywords_en": [
      "SpikingBrain",
      "Brain-inspired Large Model",
      "Domestic GPU",
      "Spiking Computation",
      "Long Sequence Processing"
    ],
    "area_en": [
      "Artificial Intelligence",
      "Large Language Model",
      "Deep Learning"
    ]
  },
  {
    "id": "z0Zlbmn90CD0C-PmDoEWDQ",
    "source": "wechat",
    "url": "https://mp.weixin.qq.com/s/z0Zlbmn90CD0C-PmDoEWDQ",
    "published_time": "2025-09-09T21:39:20.000Z",
    "download_time": "2025-09-10T14:43:54.151987",
    "visual_resource": [
      "screenshot/wechat/wechat_image_z0Zlbmn90CD0C-PmDoEWDQ.png"
    ],
    "extra_info": null,
    "title_en": "Universal Problem Solver Prototype Emerges! Google DeepMind's Major Research Autonomously Discovers 40 New Algorithms",
    "summary_en": "Google DeepMind has unveiled a groundbreaking AI system prototype designed to automate scientific discovery and software development. Central to this system are the concepts of \"empirical software\" and \"scoreable tasks,\" which transform open-ended scientific problems into quantifiable, optimizable engineering challenges. The system leverages large language models for code generation, execution, and scoring, guided by an AlphaZero-inspired PUCT tree search algorithm for intelligent iterative optimization. It achieves universality through ranking score normalization and integrates research ideas and method recombination via advanced prompt engineering. This AI has autonomously discovered 40 new algorithms, achieving significant breakthroughs in diverse fields such as bioinformatics, satellite image semantic segmentation, neuron activity prediction, time series forecasting, and numerical integration. By dramatically accelerating the scientific \"trial-and-error\" process, the system demonstrates immense potential for automating R&D workflows across various industries.",
    "keywords_en": [
      "Universal Problem Solver",
      "AI Scientific Discovery",
      "Empirical Software",
      "Scoreable Task",
      "Code Generation",
      "Tree Search"
    ],
    "area_en": [
      "Artificial Intelligence",
      "Large Language Model",
      "Generative AI"
    ]
  },
  {
    "id": "m3cMf_o8nQMGhY18tZ7i0g",
    "source": "wechat",
    "url": "https://mp.weixin.qq.com/s/m3cMf_o8nQMGhY18tZ7i0g",
    "published_time": "2025-09-09T23:30:27.000Z",
    "download_time": "2025-09-10T14:43:56.872024",
    "visual_resource": [
      "screenshot/wechat/wechat_image_m3cMf_o8nQMGhY18tZ7i0g.png"
    ],
    "extra_info": null,
    "title_en": "ByteDance Introduces Sparse Attention for Video Generation, Achieving 20x Computation Reduction and 17.79x Speedup",
    "summary_en": "Addressing the significant computational bottleneck of Full Attention mechanisms in Video Diffusion Transformer (DiT) models, particularly for high-resolution, long video generation, ByteDance has introduced the Bidirectional Sparse Attention (BSA) framework. This novel approach is the first to dynamically sparsify both Query and Key-Value pairs within 3D Full Attention, employing distinct dynamic sparsification strategies to enhance training and inference efficiency. BSA tackles the inherent sparsity and dynamic nature of attention computations in DiT. Specifically, it utilizes a Query-Sparse method to efficiently select optimal query tokens based on semantic redundancy and dynamic spatiotemporal characteristics, alongside a KV-Sparse method that dynamically identifies critical Key-Value pairs using statistical thresholds, adapting to varying input content without fixed sparse patterns. Extensive experiments demonstrate that BSA substantially accelerates DiT model training, achieving up to a 20-fold reduction in FLOPs and a remarkable 17.79-fold speedup in attention training. Crucially, it maintains or even surpasses the generation quality of Full Attention, while also significantly reducing inference latency from 31 seconds to 5.2 seconds (a 6.2x improvement). This breakthrough marks a significant efficiency revolution in the field of video generation, making high-quality, long video synthesis more practical and scalable.",
    "keywords_en": [
      "Video Generation",
      "Sparse Attention",
      "DiT Model",
      "Computational Efficiency",
      "Diffusion Model"
    ],
    "area_en": [
      "Generative AI",
      "Video Understanding",
      "Deep Learning"
    ]
  },
  {
    "id": "jaaz",
    "source": "GitHub",
    "url": "https://github.com/11cafe/jaaz",
    "published_time": "2025-09-10T01:49:47Z",
    "download_time": "2024-05-15 10:30:00",
    "visual_resource": [
      "screenshot/github/jaaz.png"
    ],
    "extra_info": null,
    "title_en": "Jaaz.app",
    "summary_en": "Jaaz.app is an innovative open-source multimodal canvas creative AI tool, positioned as a privacy-first, locally deployable alternative to popular platforms like Canva. It features an advanced AI agent system that facilitates rapid image and video generation from a single prompt. Key functionalities include \"Magic Canvas\" and \"Magic Video,\" allowing users to create content intuitively through simple sketching or step-by-step descriptions, with the AI instantly interpreting and generating results without the need for intricate text prompts. The platform supports integration with various leading AI models such as GPT-4o and Midjourney. Furthermore, Jaaz.app provides an infinite canvas for visual storyboarding, cross-platform compatibility for Windows and macOS, and robust enterprise-grade private deployment options, ensuring paramount data security and full commercial usage rights for its users.",
    "keywords_en": [
      "Multimodal",
      "AI Creation",
      "Image Generation",
      "Video Generation",
      "AI Agent",
      "Open Source",
      "Local Deployment",
      "Privacy Protection"
    ],
    "area_en": [
      "Multimodal",
      "Generative AI",
      "AI Agent"
    ]
  },
  {
    "id": "AutoAgent",
    "source": "GitHub",
    "url": "https://github.com/HKUDS/AutoAgent",
    "published_time": "2025-09-01T03:00:03Z",
    "download_time": "2024-07-29 10:00:00",
    "visual_resource": [
      "https://raw.githubusercontent.com/HKUDS/AutoAgent/main/assets/autoagent-intro.svg",
      "https://raw.githubusercontent.com/HKUDS/AutoAgent/main/assets/video_v1_compressed.mp4",
      "https://raw.githubusercontent.com/HKUDS/AutoAgent/main/assets/cover.png"
    ],
    "extra_info": null,
    "title_en": "AutoAgent: Fully-Automated & Zero-Code LLM Agent Framework",
    "summary_en": "AutoAgent is a cutting-edge, fully-automated, and zero-code large language model (LLM) agent framework designed to simplify the creation and deployment of sophisticated LLM agents through natural language interactions. It has achieved top performance on the GAIA Benchmark, showcasing capabilities comparable to advanced deep research agents. A key feature is its Agentic-RAG system, equipped with a native self-managing vector database, which surpasses industry-leading solutions. AutoAgent offers universal LLM support, flexible function-calling and ReAct interaction modes, and provides distinct user, agent editor, and workflow editor modes. This dynamic, extensible, and lightweight framework empowers users to effortlessly build, customize, and manage AI applications, making advanced LLM agent development accessible to all.",
    "keywords_en": [
      "LLM Agent",
      "Zero-Code Development",
      "Automation Framework",
      "Retrieval-Augmented Generation",
      "Multi-Agent System",
      "Natural Language Interaction",
      "Vector Database"
    ],
    "area_en": [
      "Artificial Intelligence",
      "Large Language Model",
      "AI Agent"
    ]
  },
  {
    "id": "XLeRobot",
    "source": "GitHub",
    "url": "https://github.com/Vector-Wangel/XLeRobot",
    "published_time": "2025-09-10T04:08:11Z",
    "download_time": "2024-05-15 12:30:00",
    "visual_resource": [
      "screenshot/github/XLeRobot.png"
    ],
    "extra_info": null,
    "title_en": "XLeRobot 🤖",
    "summary_en": "XLeRobot is an open-source, low-cost embodied AI robot platform designed to make embodied AI accessible to everyone, costing less than an iPhone. Built upon existing robust projects like LeRobot, it provides comprehensive guides from hardware assembly to software control. The platform supports various teleoperation methods, including keyboard and Xbox controllers, and features robust simulation capabilities. Focused on general manipulation and household tasks, XLeRobot offers an affordable experimental and development platform for robotics enthusiasts and researchers.",
    "keywords_en": [
      "Embodied AI",
      "Robotics",
      "Low-cost",
      "Open-source Hardware",
      "Home Robot",
      "Robotic Arm",
      "Simulation",
      "Teleoperation"
    ],
    "area_en": [
      "Robotics",
      "Artificial Intelligence",
      "Machine Learning"
    ]
  },
  {
    "id": "Daft",
    "source": "GitHub",
    "url": "https://github.com/Eventual-Inc/Daft",
    "published_time": "2025-09-10T01:41:43Z",
    "download_time": "2024-05-15 10:00:00",
    "visual_resource": [
      "https://daft.ai/images/diagram.png",
      "https://github-production-user-asset-6210df.s3.amazonaws.com/2550285/243524430-338e427d-f049-40b3-b555-4059d6be7bfd.png"
    ],
    "extra_info": null,
    "title_en": "Daft: Unified Engine for Data Analytics, Engineering & ML/AI",
    "summary_en": "Daft is a distributed query engine implemented in Rust, supporting Python or SQL, designed for large-scale data processing, analytics, engineering, and ML/AI workloads. It offers a familiar interactive API, such as a Lazy Python Dataframe, and leverages a powerful Query Optimizer for efficient execution. Daft integrates seamlessly with data catalogs like Apache Iceberg and features a rich multimodal type-system, efficiently handling complex data types such as images, URLs, and tensors. Built on the Apache Arrow in-memory format, it ensures seamless data interchange. Its record-setting I/O performance is optimized for cloud storage integrations like S3. Daft is also built for interactive computing with intelligent caching and can scale to large clusters via native integration with Ray, making it ideal for both interactive data exploration and distributed environments.",
    "keywords_en": [
      "Distributed Query Engine",
      "Data Analytics",
      "Machine Learning",
      "Multimodal Data",
      "Apache Arrow",
      "Rust",
      "Python",
      "SQL"
    ],
    "area_en": [
      "Artificial Intelligence",
      "Machine Learning",
      "Multimodal"
    ]
  },
  {
    "id": "llm-app",
    "source": "GitHub",
    "url": "https://github.com/pathwaycom/llm-app",
    "published_time": "2025-07-30T12:13:38Z",
    "download_time": "2024-05-16 08:00:00",
    "visual_resource": [
      "https://github.com/pathwaycom/llm-app/blob/main/examples/pipelines/gpt_4o_multimodal_rag/gpt4o_with_pathway_comparison.gif",
      "https://github.com/pathwaycom/llm-app/blob/main/examples/pipelines/drive_alert/drive_alert_demo.gif"
    ],
    "extra_info": null,
    "title_en": "Pathway AI Pipelines",
    "summary_en": "Pathway AI Pipelines provide a robust and efficient solution for rapidly deploying AI applications, specializing in high-accuracy Retrieval-Augmented Generation (RAG) and scalable enterprise AI search. These pipelines leverage the most current knowledge from various data sources, offering ready-to-use Large Language Model (LLM) App Templates that can be deployed on-cloud or on-premises. They seamlessly connect and synchronize with diverse data sources, including file systems, Google Drive, Sharepoint, S3, and Kafka, handling all data additions, deletions, and updates in real-time. A key feature is the built-in data indexing, enabling lightning-fast vector, hybrid, and full-text search capabilities, all managed in-memory with caching, thus eliminating external infrastructure dependencies. This comprehensive approach significantly simplifies the development and deployment of sophisticated AI applications, particularly for managing and querying vast document collections with continuously updated information.",
    "keywords_en": [
      "AI Pipelines",
      "RAG",
      "Large Language Models",
      "Data Indexing",
      "Vector Search",
      "Real-time Data",
      "Enterprise Search"
    ],
    "area_en": [
      "Artificial Intelligence",
      "Large Language Model",
      "Natural Language Processing"
    ]
  },
  {
    "id": "system-prompts-and-models-of-ai-tools",
    "source": "GitHub",
    "url": "https://github.com/x1xhlol/system-prompts-and-models-of-ai-tools",
    "published_time": "2025-09-08T16:52:23Z",
    "download_time": "2024-05-16 08:00:00",
    "visual_resource": [
      "https://api.star-history.com/svg?repos=x1xhlol/system-prompts-and-models-of-ai-tools&type=Date"
    ],
    "extra_info": null,
    "title_en": "System Prompts and Models of AI Tools",
    "summary_en": "This GitHub repository compiles over 20,000 lines of system prompts and model information from various AI tools, offering deep insights into their internal structure and functionality. It serves as a valuable resource for understanding how AI tools operate and critically highlights potential security vulnerabilities faced by AI startups concerning exposed system instructions and model configurations. The project also promotes a security audit service designed to help companies identify and protect their AI systems from potential data leaks.",
    "keywords_en": [
      "System Prompts",
      "AI Models",
      "AI Tools",
      "AI Security",
      "Prompt Engineering",
      "AI Agent"
    ],
    "area_en": [
      "Artificial Intelligence",
      "Large Language Model",
      "AI Agent"
    ]
  },
  {
    "id": "2509.06917",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2509.06917",
    "published_time": "2025-09-08T17:28:42.000Z",
    "download_time": "2025-09-09 23:27:10",
    "visual_resource": [
      "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2509.06917.png"
    ],
    "extra_info": "{\"url\": \"https://huggingface.co/papers/2509.06917\", \"arxiv_url\": \"https://arxiv.org/abs/2509.06917\"}",
    "title_en": "Paper2Agent: Reimagining Research Papers As Interactive and Reliable AI\n  Agents",
    "summary_en": "We introduce Paper2Agent, an automated framework that converts research\npapers into AI agents. Paper2Agent transforms research output from passive\nartifacts into active systems that can accelerate downstream use, adoption, and\ndiscovery. Conventional research papers require readers to invest substantial\neffort to understand and adapt a paper's code, data, and methods to their own\nwork, creating barriers to dissemination and reuse. Paper2Agent addresses this\nchallenge by automatically converting a paper into an AI agent that acts as a\nknowledgeable research assistant. It systematically analyzes the paper and the\nassociated codebase using multiple agents to construct a Model Context Protocol\n(MCP) server, then iteratively generates and runs tests to refine and robustify\nthe resulting MCP. These paper MCPs can then be flexibly connected to a chat\nagent (e.g. Claude Code) to carry out complex scientific queries through\nnatural language while invoking tools and workflows from the original paper. We\ndemonstrate Paper2Agent's effectiveness in creating reliable and capable paper\nagents through in-depth case studies. Paper2Agent created an agent that\nleverages AlphaGenome to interpret genomic variants and agents based on ScanPy\nand TISSUE to carry out single-cell and spatial transcriptomics analyses. We\nvalidate that these paper agents can reproduce the original paper's results and\ncan correctly carry out novel user queries. By turning static papers into\ndynamic, interactive AI agents, Paper2Agent introduces a new paradigm for\nknowledge dissemination and a foundation for the collaborative ecosystem of AI\nco-scientists.",
    "keywords_en": [
      "AI Agents",
      "Research Papers",
      "Automated Framework",
      "Knowledge Dissemination",
      "Model Context Protocol"
    ],
    "area_en": [
      "Artificial Intelligence",
      "AI Agent",
      "Natural Language Processing"
    ]
  },
  {
    "id": "2509.06160",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2509.06160",
    "published_time": "2025-09-07T18:07:58.000Z",
    "download_time": "2025-09-09 23:27:11",
    "visual_resource": [
      "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2509.06160.png"
    ],
    "extra_info": "{\"url\": \"https://huggingface.co/papers/2509.06160\", \"arxiv_url\": \"https://arxiv.org/abs/2509.06160\"}",
    "title_en": "Reverse-Engineered Reasoning for Open-Ended Generation",
    "summary_en": "While the ``deep reasoning'' paradigm has spurred significant advances in\nverifiable domains like mathematics, its application to open-ended, creative\ngeneration remains a critical challenge. The two dominant methods for\ninstilling reasoning -- reinforcement learning (RL) and instruction\ndistillation -- falter in this area; RL struggles with the absence of clear\nreward signals and high-quality reward models, while distillation is\nprohibitively expensive and capped by the teacher model's capabilities. To\novercome these limitations, we introduce REverse-Engineered Reasoning (REER), a\nnew paradigm that fundamentally shifts the approach. Instead of building a\nreasoning process ``forwards'' through trial-and-error or imitation, REER works\n``backwards'' from known-good solutions to computationally discover the latent,\nstep-by-step deep reasoning process that could have produced them. Using this\nscalable, gradient-free approach, we curate and open-source DeepWriting-20K, a\nlarge-scale dataset of 20,000 deep reasoning trajectories for open-ended tasks.\nOur model, DeepWriter-8B, trained on this data, not only surpasses strong\nopen-source baselines but also achieves performance competitive with, and at\ntimes superior to, leading proprietary models like GPT-4o and Claude 3.5.",
    "keywords_en": [
      "Reverse-Engineered Reasoning",
      "Open-Ended Generation",
      "Deep Reasoning",
      "Dataset",
      "Large Language Models"
    ],
    "area_en": [
      "Generative AI",
      "Large Language Model",
      "Deep Learning"
    ]
  },
  {
    "id": "2509.06155",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2509.06155",
    "published_time": "2025-09-07T17:55:03.000Z",
    "download_time": "2025-09-09 23:27:11",
    "visual_resource": [
      "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2509.06155.png"
    ],
    "extra_info": "{\"url\": \"https://huggingface.co/papers/2509.06155\", \"arxiv_url\": \"https://arxiv.org/abs/2509.06155\"}",
    "title_en": "UniVerse-1: Unified Audio-Video Generation via Stitching of Experts",
    "summary_en": "We introduce UniVerse-1, a unified, Veo-3-like model capable of\nsimultaneously generating coordinated audio and video. To enhance training\nefficiency, we bypass training from scratch and instead employ a stitching of\nexperts (SoE) technique. This approach deeply fuses the corresponding blocks of\npre-trained video and music generation experts models, thereby fully leveraging\ntheir foundational capabilities. To ensure accurate annotations and temporal\nalignment for both ambient sounds and speech with video content, we developed\nan online annotation pipeline that processes the required training data and\ngenerates labels during training process. This strategy circumvents the\nperformance degradation often caused by misalignment text-based annotations.\nThrough the synergy of these techniques, our model, after being finetuned on\napproximately 7,600 hours of audio-video data, produces results with\nwell-coordinated audio-visuals for ambient sounds generation and strong\nalignment for speech generation. To systematically evaluate our proposed\nmethod, we introduce Verse-Bench, a new benchmark dataset. In an effort to\nadvance research in audio-video generation and to close the performance gap\nwith state-of-the-art models such as Veo3, we make our model and code publicly\navailable. We hope this contribution will benefit the broader research\ncommunity. Project page: https://dorniwang.github.io/UniVerse-1/.",
    "keywords_en": [
      "Audio-Video Generation",
      "Stitching of Experts",
      "Multimodal AI",
      "Generative Models",
      "Benchmark Dataset"
    ],
    "area_en": [
      "Generative AI",
      "Multimodal",
      "Deep Learning"
    ]
  },
  {
    "id": "2509.06809",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2509.06809",
    "published_time": "2025-09-08T15:43:29.000Z",
    "download_time": "2025-09-09 23:27:11",
    "visual_resource": [
      "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2509.06809.png"
    ],
    "extra_info": "{\"url\": \"https://huggingface.co/papers/2509.06809\", \"arxiv_url\": \"https://arxiv.org/abs/2509.06809\"}",
    "title_en": "Saturation-Driven Dataset Generation for LLM Mathematical Reasoning in\n  the TPTP Ecosystem",
    "summary_en": "The scarcity of high-quality, logically sound data is a critical bottleneck\nfor advancing the mathematical reasoning of Large Language Models (LLMs). Our\nwork confronts this challenge by turning decades of automated theorem proving\nresearch into a scalable data engine. Rather than relying on error-prone LLMs\nor complex proof-assistant syntax like Lean and Isabelle, our framework\nleverages E-prover's saturation capabilities on the vast TPTP axiom library to\nderive a massive, guaranteed-valid corpus of theorems. Our pipeline is\nprincipled and simple: saturate axioms, filter for \"interesting\" theorems, and\ngenerate tasks. With no LLMs in the loop, we eliminate factual errors by\nconstruction. This purely symbolic data is then transformed into three\ndifficulty-controlled challenges: entailment verification, premise selection,\nand proof reconstruction. Our zero-shot experiments on frontier models reveal a\nclear weakness: performance collapses on tasks requiring deep, structural\nreasoning. Our framework provides both the diagnostic tool to measure this gap\nand a scalable source of symbolic training data to address it. We make the code\nand data publicly available.\n  https://github.com/sileod/reasoning_core\nhttps://hf.co/datasets/reasoning-core/rc1",
    "keywords_en": [
      "Large Language Models",
      "Mathematical Reasoning",
      "Automated Theorem Proving",
      "Dataset Generation",
      "Symbolic Reasoning"
    ],
    "area_en": [
      "Large Language Model",
      "Artificial Intelligence",
      "Natural Language Processing"
    ]
  },
  {
    "id": "2509.06949",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2509.06949",
    "published_time": "2025-09-08T17:58:06.000Z",
    "download_time": "2025-09-09 23:27:12",
    "visual_resource": [
      "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2509.06949.png"
    ],
    "extra_info": "{\"url\": \"https://huggingface.co/papers/2509.06949\", \"arxiv_url\": \"https://arxiv.org/abs/2509.06949\"}",
    "title_en": "Revolutionizing Reinforcement Learning Framework for Diffusion Large\n  Language Models",
    "summary_en": "We propose TraceRL, a trajectory-aware reinforcement learning framework for\ndiffusion language models (DLMs) that incorporates preferred inference\ntrajectory into post-training, and is applicable across different\narchitectures. Equipped with a diffusion-based value model that enhances\ntraining stability, we demonstrate improved reasoning performance on complex\nmath and coding tasks. Besides, it can also be applied to adapt block-specific\nmodels to larger blocks, which improves sampling flexibility. Employing\nTraceRL, we derive a series of state-of-the-art diffusion language models,\nnamely TraDo. Although smaller than 7B-scale AR models, TraDo-4B-Instruct still\nconsistently outperforms them across complex math reasoning tasks.\nTraDo-8B-Instruct achieves relative accuracy improvements of 6.1% over\nQwen2.5-7B-Instruct and 51.3% over Llama3.1-8B-Instruct on mathematical\nreasoning benchmarks. Through curriculum learning, we also derive the first\nlong-CoT DLM, outperforming Qwen2.5-7B-Instruct on MATH500 with an 18.1%\nrelative accuracy gain. To facilitate reproducible research and practical\napplications, we release a comprehensive open-source framework for building,\ntraining, and deploying diffusion LLMs across diverse architectures. The\nframework integrates accelerated KV-cache techniques and inference engines for\nboth inference and reinforcement learning, and includes implementations of\nvarious supervised fine-tuning and RL methods for mathematics, coding, and\ngeneral tasks. Code and Models: https://github.com/Gen-Verse/dLLM-RL",
    "keywords_en": [
      "Reinforcement Learning",
      "Diffusion Large Language Models",
      "Trajectory-aware",
      "Mathematical Reasoning",
      "Open-source Framework"
    ],
    "area_en": [
      "Large Language Model",
      "Natural Language Processing",
      "Machine Learning"
    ]
  },
  {
    "id": "2509.06501",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2509.06501",
    "published_time": "2025-09-08T10:07:03.000Z",
    "download_time": "2025-09-09 23:27:12",
    "visual_resource": [
      "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2509.06501.png"
    ],
    "extra_info": "{\"url\": \"https://huggingface.co/papers/2509.06501\", \"arxiv_url\": \"https://arxiv.org/abs/2509.06501\"}",
    "title_en": "WebExplorer: Explore and Evolve for Training Long-Horizon Web Agents",
    "summary_en": "The paradigm of Large Language Models (LLMs) has increasingly shifted toward\nagentic applications, where web browsing capabilities are fundamental for\nretrieving information from diverse online sources. However, existing\nopen-source web agents either demonstrate limited information-seeking abilities\non complex tasks or lack transparent implementations. In this work, we identify\nthat the key challenge lies in the scarcity of challenging data for information\nseeking. To address this limitation, we introduce WebExplorer: a systematic\ndata generation approach using model-based exploration and iterative,\nlong-to-short query evolution. This method creates challenging query-answer\npairs that require multi-step reasoning and complex web navigation. By\nleveraging our curated high-quality dataset, we successfully develop advanced\nweb agent WebExplorer-8B through supervised fine-tuning followed by\nreinforcement learning. Our model supports 128K context length and up to 100\ntool calling turns, enabling long-horizon problem solving. Across diverse\ninformation-seeking benchmarks, WebExplorer-8B achieves the state-of-the-art\nperformance at its scale. Notably, as an 8B-sized model, WebExplorer-8B is able\nto effectively search over an average of 16 turns after RL training, achieving\nhigher accuracy than WebSailor-72B on BrowseComp-en/zh and attaining the best\nperformance among models up to 100B parameters on WebWalkerQA and FRAMES.\nBeyond these information-seeking tasks, our model also achieves strong\ngeneralization on the HLE benchmark even though it is only trained on\nknowledge-intensive QA data. These results highlight our approach as a\npractical path toward long-horizon web agents.",
    "keywords_en": [
      "Web Agents",
      "Long-Horizon",
      "Data Generation",
      "Information Seeking",
      "Large Language Models"
    ],
    "area_en": [
      "AI Agent",
      "Large Language Model",
      "Artificial Intelligence"
    ]
  }
]