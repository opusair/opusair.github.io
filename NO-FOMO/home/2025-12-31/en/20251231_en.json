[
  {
    "id": "hackernews_46445195",
    "source": "Hacker News",
    "url": "https://kywch.github.io/blog/2025/12/curriculum-learning-2048-tetris/",
    "title": "Scaffolding to Superhuman: How Curriculum Learning Solved 2048 and Tetris",
    "summary": "A recent blog post titled 'Scaffolding to Superhuman: How Curriculum Learning Solved 2048 and Tetris' delves into the innovative application of curriculum learning to achieve superhuman performance in classic games, specifically 2048 and Tetris. The research showcases how a meticulously structured learning process, analogous to human educational scaffolding, can dramatically improve an AI agent's capacity to master intricate tasks. This methodology involves progressively increasing the complexity of the learning environment, enabling the AI to build foundational skills before tackling more challenging scenarios. This incremental approach effectively mitigates issues like premature convergence to suboptimal strategies, fostering the development of robust and adaptive game-playing intelligence. The successful resolution of these well-known games underscores curriculum learning's efficacy as a potent training paradigm, offering significant implications for advancing AI development not only in game artificial intelligence but also in broader applications requiring sophisticated strategic planning and problem-solving abilities.",
    "keywords": [
      "Curriculum Learning",
      "Reinforcement Learning",
      "Game AI",
      "Artificial Intelligence",
      "Machine Learning",
      "Tetris",
      "2048",
      "Game Solving"
    ],
    "area": [
      "Artificial Intelligence",
      "Machine Learning",
      "AI Agent"
    ],
    "published_time": "2025-12-31 15:52:51",
    "download_time": "2025-12-31 20:00:30",
    "extra_info": "{\"score\": 86, \"by\": \"a1k0n\", \"descendants\": 17, \"story_id\": 46445195}"
  },
  {
    "id": "hackernews_46442245",
    "source": "Hacker News",
    "url": "https://exopriors.com/scry",
    "title": "Show HN: Use Claude Code to Query 600 GB Indexes over Hacker News, ArXiv, etc.",
    "summary": "A new Show HN project, 'Exopriors Scry', introduces an advanced research tool leveraging Claude Code to query vast 600 GB indexes across prominent high-quality public commons sites such as Hacker News, arXiv, and LessWrong. This innovative platform provides a public, read-only SQL+vector database that allows users to embed their API key and utilize Claude's AI capabilities to generate complex SQL queries for nuanced information retrieval. Beyond direct querying, the service features an 'Alerts' functionality, enabling users to set specific, highly detailed criteria for email notifications when new content matches their interests, such as \"estrogen in a psychoactive context\" or specific biological metaphors in infrastructure discussions. The system currently indexes a significant portion of posts (1.4M out of 4.6M) and comments (15.6M out of 38M) using Voyage-3.5-lite, supporting sophisticated compositional vector search. This tool aims to revolutionize information discovery and monitoring over large, diverse datasets.",
    "keywords": [
      "Claude Code",
      "Vector Database",
      "SQL Queries",
      "Information Retrieval",
      "Semantic Search",
      "AI Agent",
      "Data Indexing",
      "Alerts System"
    ],
    "area": [
      "Artificial Intelligence",
      "AI Agent",
      "Natural Language Processing"
    ],
    "published_time": "2025-12-31 07:47:44",
    "download_time": "2025-12-31 20:00:29",
    "extra_info": "{\"score\": 248, \"by\": \"Xyra\", \"descendants\": 76, \"story_id\": 46442245}"
  },
  {
    "id": "hackernews_46444020",
    "source": "Hacker News",
    "url": "https://newsletter.semianalysis.com/p/how-ai-labs-are-solving-the-power",
    "title": "How AI labs are solving the power problem",
    "summary": "AI labs are increasingly confronting substantial challenges related to the escalating power consumption of their computational infrastructure, particularly driven by the training and inference requirements of large-scale AI models. The 'power problem' encompasses not only the direct electricity demand of high-performance GPUs and specialized AI accelerators but also the extensive energy needed for cooling systems and the overall operation of vast data centers. To address these critical issues, AI research institutions are actively exploring multifaceted solutions. These strategies include significant advancements in algorithmic efficiency, such as developing sparse models or more optimized neural network architectures that demand less computational power. Concurrently, there is a strong focus on hardware innovation, aiming to create more energy-efficient processors and specialized AI chips. Furthermore, labs are investigating the integration of sustainable and renewable energy sources to power their operations and implementing advanced cooling technologies to minimize energy waste. These concerted efforts are vital for ensuring the sustainable growth, economic viability, and environmental responsibility of the rapidly evolving AI landscape.",
    "keywords": [
      "AI Energy Consumption",
      "Sustainable AI",
      "AI Hardware",
      "Algorithmic Efficiency",
      "Data Center Energy",
      "Green AI"
    ],
    "area": [
      "Artificial Intelligence",
      "Machine Learning",
      "Deep Learning"
    ],
    "published_time": "2025-12-31 13:50:41",
    "download_time": "2025-12-31 20:00:38",
    "extra_info": "{\"score\": 63, \"by\": \"Symmetry\", \"descendants\": 103, \"story_id\": 46444020}"
  },
  {
    "id": "hackernews_46443767",
    "source": "Hacker News",
    "url": "https://carimbo.games/games/nintendo/",
    "title": "Claude wrote a functional NES emulator using my engine's API",
    "summary": "A notable advancement in AI-driven software development has been observed, with the AI model Claude successfully engineering a functional Nintendo Entertainment System (NES) emulator. This project exemplifies Claude's sophisticated capability to generate complex code, specifically designed to interact with an existing game engine's Application Programming Interface (API). The development involved Claude interpreting specific requirements for hardware emulation and translating them into functional, API-compliant software. This achievement underscores the increasing proficiency of large language models as advanced coding assistants, capable of not only generating substantial amounts of code but also ensuring its operational integrity and integration within established software ecosystems. The successful creation of an emulator, a task traditionally requiring deep human expertise in systems programming, showcases AI's potential to accelerate development cycles and innovate in specialized domains like retro gaming and custom software solutions. This case serves as a compelling illustration of AI agents' practical application in overcoming intricate technical challenges and expanding the scope of automated code generation.",
    "keywords": [
      "Claude",
      "NES Emulator",
      "API",
      "Code Generation",
      "AI Agent",
      "Game Development",
      "Software Engineering",
      "Hardware Emulation"
    ],
    "area": [
      "Artificial Intelligence",
      "AI Agent",
      "Generative AI"
    ],
    "published_time": "2025-12-31 13:07:22",
    "download_time": "2025-12-31 20:00:46",
    "extra_info": "{\"score\": 59, \"by\": \"delduca\", \"descendants\": 58, \"story_id\": 46443767}"
  },
  {
    "id": "hackernews_46446800",
    "source": "Hacker News",
    "url": "https://storage.courtlistener.com/recap/gov.uscourts.cand.461878/gov.uscourts.cand.461878.1.0.pdf",
    "title": "Court report detailing ChatGPT's involvement with a recent murder suicide [pdf]",
    "summary": "A significant court report has emerged, detailing the alleged involvement of OpenAI's ChatGPT in a recent murder-suicide case. The publicly available PDF document, filed within a legal proceeding, aims to outline the specific circumstances and the extent to which the large language model played a role in the tragic events. This development underscores a critical examination of the ethical implications and potential misuse of powerful AI technologies in real-world scenarios. Legal experts and AI ethicists are expected to analyze the report closely to understand the nature of ChatGPT's interaction, whether it involved providing instructions, influencing behavior, or being used in a manner that contributed to the outcome. The case highlights the pressing need for comprehensive regulatory frameworks and robust safety protocols to address the societal impact and potential liabilities associated with advanced artificial intelligence systems, particularly concerning human well-being and legal accountability.",
    "keywords": [
      "ChatGPT",
      "Artificial Intelligence",
      "Legal Implications",
      "AI Ethics",
      "Large Language Model",
      "AI Misuse",
      "Court Document"
    ],
    "area": [
      "Artificial Intelligence",
      "Large Language Model",
      "Natural Language Processing"
    ],
    "published_time": "2025-12-31 18:25:16",
    "download_time": "2025-12-31 20:00:49",
    "extra_info": "{\"score\": 75, \"by\": \"Mgtyalx\", \"descendants\": 53, \"story_id\": 46446800}"
  },
  {
    "id": "2512.21185",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2512.21185",
    "title": "UltraShape 1.0: High-Fidelity 3D Shape Generation via Scalable Geometric Refinement",
    "summary": "In this report, we introduce UltraShape 1.0, a scalable 3D diffusion framework for high-fidelity 3D geometry generation. The proposed approach adopts a two-stage generation pipeline: a coarse global structure is first synthesized and then refined to produce detailed, high-quality geometry. To support reliable 3D generation, we develop a comprehensive data processing pipeline that includes a novel watertight processing method and high-quality data filtering. This pipeline improves the geometric quality of publicly available 3D datasets by removing low-quality samples, filling holes, and thickening thin structures, while preserving fine-grained geometric details. To enable fine-grained geometry refinement, we decouple spatial localization from geometric detail synthesis in the diffusion process. We achieve this by performing voxel-based refinement at fixed spatial locations, where voxel queries derived from coarse geometry provide explicit positional anchors encoded via RoPE, allowing the diffusion model to focus on synthesizing local geometric details within a reduced, structured solution space. Our model is trained exclusively on publicly available 3D datasets, achieving strong geometric quality despite limited training resources. Extensive evaluations demonstrate that UltraShape 1.0 performs competitively with existing open-source methods in both data processing quality and geometry generation. All code and trained models will be released to support future research.",
    "keywords": [
      "3D Shape Generation",
      "Geometric Refinement",
      "Diffusion Framework",
      "High-Fidelity Geometry",
      "Data Processing"
    ],
    "area": [
      "Generative AI",
      "Deep Learning",
      "Computer Vision"
    ],
    "published_time": "2025-12-24T14:08:38.000Z",
    "download_time": "2025-12-31 12:01:09",
    "extra_info": "{\"url\": \"https://huggingface.co/papers/2512.21185\", \"arxiv_url\": \"https://arxiv.org/abs/2512.21185\", \"thumbnail\": \"https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2512.21185.png\", \"original_title\": \"UltraShape 1.0: High-Fidelity 3D Shape Generation via Scalable Geometric Refinement\"}"
  },
  {
    "id": "2512.22525",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2512.22525",
    "title": "DreamOmni3: Scribble-based Editing and Generation",
    "summary": "Recently unified generation and editing models have achieved remarkable success with their impressive performance. These models rely mainly on text prompts for instruction-based editing and generation, but language often fails to capture users intended edit locations and fine-grained visual details. To this end, we propose two tasks: scribble-based editing and generation, that enables more flexible creation on graphical user interface (GUI) combining user textual, images, and freehand sketches. We introduce DreamOmni3, tackling two challenges: data creation and framework design. Our data synthesis pipeline includes two parts: scribble-based editing and generation. For scribble-based editing, we define four tasks: scribble and instruction-based editing, scribble and multimodal instruction-based editing, image fusion, and doodle editing. Based on DreamOmni2 dataset, we extract editable regions and overlay hand-drawn boxes, circles, doodles or cropped image to construct training data. For scribble-based generation, we define three tasks: scribble and instruction-based generation, scribble and multimodal instruction-based generation, and doodle generation, following similar data creation pipelines. For the framework, instead of using binary masks, which struggle with complex edits involving multiple scribbles, images, and instructions, we propose a joint input scheme that feeds both the original and scribbled source images into the model, using different colors to distinguish regions and simplify processing. By applying the same index and position encodings to both images, the model can precisely localize scribbled regions while maintaining accurate editing. Finally, we establish comprehensive benchmarks for these tasks to promote further research. Experimental results demonstrate that DreamOmni3 achieves outstanding performance, and models and code will be publicly released.",
    "keywords": [
      "Scribble-based Editing",
      "Scribble-based Generation",
      "Unified Generation and Editing",
      "Multimodal Instruction",
      "Graphical User Interface"
    ],
    "area": [
      "Generative AI",
      "Multimodal",
      "Computer Vision"
    ],
    "published_time": "2025-12-27T09:07:12.000Z",
    "download_time": "2025-12-31 12:01:10",
    "extra_info": "{\"url\": \"https://huggingface.co/papers/2512.22525\", \"arxiv_url\": \"https://arxiv.org/abs/2512.22525\", \"thumbnail\": \"https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2512.22525.png\", \"original_title\": \"DreamOmni3: Scribble-based Editing and Generation\"}"
  },
  {
    "id": "2512.23675",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2512.23675",
    "title": "End-to-End Test-Time Training for Long Context",
    "summary": "We formulate long-context language modeling as a problem in continual learning rather than architecture design. Under this formulation, we only use a standard architecture -- a Transformer with sliding-window attention. However, our model continues learning at test time via next-token prediction on the given context, compressing the context it reads into its weights. In addition, we improve the model's initialization for learning at test time via meta-learning at training time. Overall, our method, a form of Test-Time Training (TTT), is End-to-End (E2E) both at test time (via next-token prediction) and training time (via meta-learning), in contrast to previous forms. We conduct extensive experiments with a focus on scaling properties. In particular, for 3B models trained with 164B tokens, our method (TTT-E2E) scales with context length in the same way as Transformer with full attention, while others, such as Mamba 2 and Gated DeltaNet, do not. However, similar to RNNs, TTT-E2E has constant inference latency regardless of context length, making it 2.7 times faster than full attention for 128K context. Our code is publicly available.",
    "keywords": [
      "Test-Time Training",
      "Long Context",
      "Continual Learning",
      "Transformer",
      "Meta-learning"
    ],
    "area": [
      "Natural Language Processing",
      "Deep Learning",
      "Large Language Model"
    ],
    "published_time": "2025-12-29T18:30:14.000Z",
    "download_time": "2025-12-31 12:01:08",
    "extra_info": "{\"url\": \"https://huggingface.co/papers/2512.23675\", \"arxiv_url\": \"https://arxiv.org/abs/2512.23675\", \"thumbnail\": \"https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2512.23675.png\", \"original_title\": \"End-to-End Test-Time Training for Long Context\"}"
  },
  {
    "id": "2512.23165",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2512.23165",
    "title": "Evaluating Parameter Efficient Methods for RLVR",
    "summary": "We systematically evaluate Parameter-Efficient Fine-Tuning (PEFT) methods under the paradigm of Reinforcement Learning with Verifiable Rewards (RLVR). RLVR incentivizes language models to enhance their reasoning capabilities through verifiable feedback; however, while methods like LoRA are commonly used, the optimal PEFT architecture for RLVR remains unidentified. In this work, we conduct the first comprehensive evaluation of over 12 PEFT methodologies across the DeepSeek-R1-Distill families on mathematical reasoning benchmarks. Our empirical results challenge the default adoption of standard LoRA with three main findings. First, we demonstrate that structural variants, such as DoRA, AdaLoRA, and MiSS, consistently outperform LoRA. Second, we uncover a spectral collapse phenomenon in SVD-informed initialization strategies (e.g., PiSSA, MiLoRA), attributing their failure to a fundamental misalignment between principal-component updates and RL optimization. Furthermore, our ablations reveal that extreme parameter reduction (e.g., VeRA, Rank-1) severely bottlenecks reasoning capacity. We further conduct ablation studies and scaling experiments to validate our findings. This work provides a definitive guide for advocating for more exploration for parameter-efficient RL methods.",
    "keywords": [
      "Parameter-Efficient Fine-Tuning",
      "Reinforcement Learning",
      "Large Language Models",
      "Mathematical Reasoning",
      "LoRA"
    ],
    "area": [
      "Large Language Model",
      "Natural Language Processing",
      "Machine Learning"
    ],
    "published_time": "2025-12-29T03:13:08.000Z",
    "download_time": "2025-12-31 12:01:09",
    "extra_info": "{\"url\": \"https://huggingface.co/papers/2512.23165\", \"arxiv_url\": \"https://arxiv.org/abs/2512.23165\", \"thumbnail\": \"https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2512.23165.png\", \"original_title\": \"Evaluating Parameter Efficient Methods for RLVR\"}"
  },
  {
    "id": "2512.21008",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2512.21008",
    "title": "GateBreaker: Gate-Guided Attacks on Mixture-of-Expert LLMs",
    "summary": "Mixture-of-Experts (MoE) architectures have advanced the scaling of Large Language Models (LLMs) by activating only a sparse subset of parameters per input, enabling state-of-the-art performance with reduced computational cost. As these models are increasingly deployed in critical domains, understanding and strengthening their alignment mechanisms is essential to prevent harmful outputs. However, existing LLM safety research has focused almost exclusively on dense architectures, leaving the unique safety properties of MoEs largely unexamined. The modular, sparsely-activated design of MoEs suggests that safety mechanisms may operate differently than in dense models, raising questions about their robustness. In this paper, we present GateBreaker, the first training-free, lightweight, and architecture-agnostic attack framework that compromises the safety alignment of modern MoE LLMs at inference time. GateBreaker operates in three stages: (i) gate-level profiling, which identifies safety experts disproportionately routed on harmful inputs, (ii) expert-level localization, which localizes the safety structure within safety experts, and (iii) targeted safety removal, which disables the identified safety structure to compromise the safety alignment. Our study shows that MoE safety concentrates within a small subset of neurons coordinated by sparse routing. Selective disabling of these neurons, approximately 3% of neurons in the targeted expert layers, significantly increases the averaged attack success rate (ASR) from 7.4% to 64.9% against the eight latest aligned MoE LLMs with limited utility degradation. These safety neurons transfer across models within the same family, raising ASR from 17.9% to 67.7% with one-shot transfer attack. Furthermore, GateBreaker generalizes to five MoE vision language models (VLMs) with 60.9% ASR on unsafe image inputs.",
    "keywords": [
      "Mixture-of-Experts",
      "Large Language Models",
      "Safety Alignment",
      "Inference-time attacks",
      "GateBreaker"
    ],
    "area": [
      "Large Language Model",
      "Deep Learning",
      "Natural Language Processing"
    ],
    "published_time": "2025-12-24T07:13:24.000Z",
    "download_time": "2025-12-31 12:01:10",
    "extra_info": "{\"url\": \"https://huggingface.co/papers/2512.21008\", \"arxiv_url\": \"https://arxiv.co/abs/2512.21008\", \"thumbnail\": \"https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2512.21008.png\", \"original_title\": \"GateBreaker: Gate-Guided Attacks on Mixture-of-Expert LLMs\"}"
  }
]