[
  {
    "id": "hackernews_46424733",
    "source": "Hacker News",
    "url": "https://www.businessinsider.com/meta-ai-generating-bizarre-ads-advantage-plus-2025-10",
    "title": "Meta's ads tools started switching out top-performing ads with AI-generated ones",
    "summary": "Meta's advertising tools have reportedly initiated a process of automatically substituting top-performing ads with AI-generated versions, marking a significant advancement in the platform's integration of artificial intelligence. This shift, particularly within features like Advantage Plus, indicates Meta's push towards greater automation in advertising creative development. While the objective is likely to enhance efficiency and optimize campaign outcomes through algorithmic decision-making, the report also suggests potential for 'bizarre' or unconventional ad outputs, raising questions about quality control and brand consistency. This strategic move highlights the increasing role of generative AI in digital marketing, moving beyond mere ad targeting to actual content creation. It represents a critical evolution in how businesses might leverage Meta's ecosystem, promising streamlined processes but also necessitating a closer examination of AI's impact on creative integrity and user experience. The implications for advertisers include both unprecedented automation capabilities and new considerations for managing AI-driven content.",
    "keywords": [
      "Generative AI",
      "AI in Advertising",
      "Digital Marketing",
      "Ad Automation",
      "Meta Platforms",
      "Advantage Plus"
    ],
    "area": [
      "Artificial Intelligence",
      "Generative AI",
      "Machine Learning"
    ],
    "published_time": "2025-12-29 19:51:47",
    "download_time": "2025-12-29 20:00:35",
    "extra_info": "{\"score\": 10, \"by\": \"zdw\", \"descendants\": 0, \"story_id\": 46424733}"
  },
  {
    "id": "hackernews_46417815",
    "source": "Hacker News",
    "url": "https://github.com/HarryR/z80ai",
    "title": "Show HN: Z80-μLM, a 'Conversational AI' That Fits in 40KB",
    "summary": "Z80-μLM is an innovative character-level language model demonstrating the viability of 'conversational AI' within extreme hardware limitations, specifically a Z80 processor with 64KB RAM. The entire system, encompassing inference, 2-bit quantized weights, and a chat user interface, is confined to a 40KB .COM file executable on CP/M environments or real hardware. This project explores the minimum viable size for a functional language model, proving it can be trained for specific, constrained tasks like a simplified 20 Questions game or maintaining brief, personality-driven conversations. The development process necessitated significant engineering compromises, including the use of trigram hashing for efficiency and typo tolerance, 16-bit integer arithmetic, and meticulous quantization-aware training techniques. This work highlights creative solutions for deploying AI in severely resource-constrained settings, pushing the boundaries of what's possible with minimal computational overhead.",
    "keywords": [
      "Z80",
      "micro-language model",
      "quantization",
      "character-level LM",
      "CP/M",
      "trigram hashing",
      "resource-constrained AI"
    ],
    "area": [
      "Artificial Intelligence",
      "Natural Language Processing",
      "Machine Learning"
    ],
    "published_time": "2025-12-29 05:41:24",
    "download_time": "2025-12-29 20:00:37",
    "extra_info": "{\"score\": 428, \"by\": \"quesomaster9000\", \"descendants\": 97, \"story_id\": 46417815}"
  },
  {
    "id": "hackernews_46422812",
    "source": "Hacker News",
    "url": "https://www.getevidex.com",
    "title": "Show HN: Evidex – AI Clinical Search (RAG over PubMed/OpenAlex and SOAP Notes)",
    "summary": "Evidex is a newly developed AI clinical search engine designed to offer a clean, privacy-first alternative to existing, often expensive and ad-heavy medical search tools like UpToDate. Built by a solo developer to assist resident physicians, Evidex leverages a Real-time Retrieval-Augmented Generation (RAG) pattern. Unlike systems relying on potentially stale pre-indexed vector databases, Evidex employs a Node.js backend orchestrator that performs \"Smart Routing\" on user queries. This smart routing uses regex and keyword analysis to dynamically decide which external APIs to query, including PubMed, Europe PMC, OpenAlex, and ClinicalTrials.gov. The system then executes parallel fetches to these sources at runtime, ensuring access to the most current clinical data for medical professionals.",
    "keywords": [
      "AI Clinical Search",
      "RAG",
      "Real-time RAG",
      "PubMed",
      "OpenAlex",
      "SOAP Notes",
      "ClinicalTrials.gov",
      "Node.js"
    ],
    "area": [
      "Artificial Intelligence",
      "Machine Learning",
      "Natural Language Processing"
    ],
    "published_time": "2025-12-29 17:17:01",
    "download_time": "2025-12-29 20:00:40",
    "extra_info": "{\"score\": 5, \"by\": \"amber_raza\", \"descendants\": 0, \"story_id\": 46422812}"
  },
  {
    "id": "hackernews_46420453",
    "source": "Hacker News",
    "url": "https://balajmarius.com/writings/vibe-coding-a-bookshelf-with-claude-code/",
    "title": "Show HN: Vibe coding a bookshelf with Claude Code",
    "summary": "The Hacker News submission, titled 'Show HN: Vibe coding a bookshelf with Claude Code,' showcases a project that explores a novel approach to software development, termed 'vibe coding,' using an AI code assistant. Specifically, the author demonstrates how Anthropic's Claude Code, a sophisticated large language model tailored for programming tasks, can be integrated into a developer's workflow to facilitate a more intuitive and less structured coding experience. The practical application chosen for this demonstration is the development of a digital bookshelf interface, implying a focus on front-end development, UI/UX implementation, or data display. This initiative underscores the growing potential of AI agents to not only automate repetitive coding tasks but also to act as creative collaborators, providing suggestions, generating code snippets, and assisting in problem-solving in real-time. The project likely aims to illustrate how such AI-driven tools can enhance developer productivity, accelerate the prototyping phase, and potentially lower the barrier to entry for complex coding projects, thereby evolving the paradigm of human-computer interaction in modern software engineering.",
    "keywords": [
      "Claude Code",
      "AI code assistant",
      "Generative AI",
      "Frontend development",
      "Software development",
      "Human-AI collaboration",
      "Large Language Models"
    ],
    "area": [
      "Artificial Intelligence",
      "Large Language Model",
      "AI Agent"
    ],
    "published_time": "2025-12-29 13:22:59",
    "download_time": "2025-12-29 20:00:45",
    "extra_info": "{\"score\": 219, \"by\": \"balajmarius\", \"descendants\": 174, \"story_id\": 46420453}"
  },
  {
    "id": "hackernews_46420289",
    "source": "Hacker News",
    "url": "https://www.theguardian.com/business/2025/dec/29/uk-accounting-remote-exams-ai-cheating-acca",
    "title": "UK accounting body to halt remote exams amid AI cheating",
    "summary": "A prominent UK accounting body, reportedly the Association of Chartered Certified Accountants (ACCA) based on the article's source, has announced its decision to suspend remote examinations, citing growing concerns over the proliferation of AI-powered cheating methods. This decisive action underscores the significant challenges posed by advanced artificial intelligence technologies in maintaining the integrity and fairness of professional qualifications across various sectors. The move reflects a broader struggle faced by educational and certification institutions globally to adapt assessment methodologies in an era where sophisticated AI tools, particularly generative AI, can produce highly convincing responses and potentially bypass traditional remote proctoring mechanisms. By halting remote exams, the accounting body aims to develop more robust and secure examination protocols that can effectively counteract AI-assisted deception before potentially reinstating online options. This critical development highlights an urgent need for innovative solutions in exam security, prompting a fundamental re-evaluation of how professional competencies are assessed in a rapidly technologically evolving landscape, ensuring that qualifications remain credible and reflect genuine knowledge and skill rather than automated assistance. The decision serves as a stark reminder of AI's disruptive potential beyond its intended beneficial applications, compelling institutions to prioritize ethical considerations and secure evaluation practices.",
    "keywords": [
      "AI cheating",
      "Remote exams",
      "Accounting certification",
      "Exam integrity",
      "Educational technology",
      "Artificial Intelligence",
      "Generative AI",
      "Online assessment"
    ],
    "area": [
      "Artificial Intelligence",
      "Generative AI",
      "Natural Language Processing"
    ],
    "published_time": "2025-12-29 13:06:49",
    "download_time": "2025-12-29 20:00:53",
    "extra_info": "{\"score\": 150, \"by\": \"beardyw\", \"descendants\": 149, \"story_id\": 46420289}"
  },
  {
    "id": "hackernews_46420670",
    "source": "Hacker News",
    "url": "https://news.ycombinator.com/item?id=46420670",
    "title": "Show HN: Per-instance TSP Solver with No Pre-training (1.66% gap on d1291)",
    "summary": "This Hacker News 'Show HN' entry introduces a novel per-instance TSP (Traveling Salesperson Problem) solver developed by the author, which operates without the need for extensive pre-training on large datasets, a common requirement in many traditional deep learning approaches. The solver employs Proximal Policy Optimization (PPO) to learn \"on the fly\" for specific problem instances from scratch. It demonstrated a competitive performance, achieving an impressive 1.66% optimality gap on the challenging TSPLIB d1291 instance after approximately 5.6 hours of training on a single A100 GPU. The core innovation of this approach resides in an inductive bias specifically designed around the topological and geometric structures of 'exception edges'—critical connections that extend beyond local scope and significantly influence the solution's difficulty. The agent is guided by insights into micro/macro structures to identify potentially promising edges, with PPO subsequently refining the solution through iterative trial and error. This research offers a compelling exploration into the application of reinforcement learning for solving complex combinatorial optimization problems without reliance on prior large-scale data.",
    "keywords": [
      "TSP Solver",
      "Reinforcement Learning",
      "Proximal Policy Optimization (PPO)",
      "Combinatorial Optimization",
      "Per-instance Learning",
      "Inductive Bias",
      "Deep Learning",
      "TSPLIB"
    ],
    "area": [
      "Artificial Intelligence",
      "Machine Learning",
      "Deep Learning"
    ],
    "published_time": "2025-12-29 13:43:14",
    "download_time": "2025-12-29 20:00:54",
    "extra_info": "{\"score\": 4, \"by\": \"jivaprime\", \"descendants\": 0, \"story_id\": 46420670}"
  },
  {
    "id": "2512.17220",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2512.17220",
    "title": "Mindscape-Aware Retrieval Augmented Generation for Improved Long Context Understanding",
    "summary": "Humans understand long and complex texts by relying on a holistic semantic representation of the content. This global view helps organize prior knowledge, interpret new information, and integrate evidence dispersed across a document, as revealed by the Mindscape-Aware Capability of humans in psychology. Current Retrieval-Augmented Generation (RAG) systems lack such guidance and therefore struggle with long-context tasks. In this paper, we propose Mindscape-Aware RAG (MiA-RAG), the first approach that equips LLM-based RAG systems with explicit global context awareness. MiA-RAG builds a mindscape through hierarchical summarization and conditions both retrieval and generation on this global semantic representation. This enables the retriever to form enriched query embeddings and the generator to reason over retrieved evidence within a coherent global context. We evaluate MiA-RAG across diverse long-context and bilingual benchmarks for evidence-based understanding and global sense-making. It consistently surpasses baselines, and further analysis shows that it aligns local details with a coherent global representation, enabling more human-like long-context retrieval and reasoning.",
    "keywords": [
      "Retrieval Augmented Generation",
      "Long Context Understanding",
      "Large Language Model",
      "Global Context Awareness",
      "Hierarchical Summarization"
    ],
    "area": [
      "Natural Language Processing",
      "Large Language Model",
      "Generative AI"
    ],
    "published_time": "2025-12-19T04:08:29.000Z",
    "download_time": "2025-12-29 12:01:29",
    "extra_info": "{\"url\": \"https://huggingface.co/papers/2512.17220\", \"arxiv_url\": \"https://arxiv.org/abs/2512.17220\", \"thumbnail\": \"https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2512.17220.png\", \"original_title\": \"Mindscape-Aware Retrieval Augmented Generation for Improved Long Context Understanding\"}"
  },
  {
    "id": "2512.17504",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2512.17504",
    "title": "InsertAnywhere: Bridging 4D Scene Geometry and Diffusion Models for Realistic Video Object Insertion",
    "summary": "Recent advances in diffusion-based video generation have opened new possibilities for controllable video editing, yet realistic video object insertion (VOI) remains challenging due to limited 4D scene understanding and inadequate handling of occlusion and lighting effects. We present InsertAnywhere, a new VOI framework that achieves geometrically consistent object placement and appearance-faithful video synthesis. Our method begins with a 4D aware mask generation module that reconstructs the scene geometry and propagates user specified object placement across frames while maintaining temporal coherence and occlusion consistency. Building upon this spatial foundation, we extend a diffusion based video generation model to jointly synthesize the inserted object and its surrounding local variations such as illumination and shading. To enable supervised training, we introduce ROSE++, an illumination aware synthetic dataset constructed by transforming the ROSE object removal dataset into triplets of object removed video, object present video, and a VLM generated reference image. Through extensive experiments, we demonstrate that our framework produces geometrically plausible and visually coherent object insertions across diverse real world scenarios, significantly outperforming existing research and commercial models.",
    "keywords": [
      "Video Object Insertion",
      "Diffusion Models",
      "4D Scene Geometry",
      "Realistic Video Synthesis",
      "Occlusion Consistency"
    ],
    "area": [
      "Computer Vision",
      "Generative AI",
      "Video Understanding"
    ],
    "published_time": "2025-12-19T12:14:36.000Z",
    "download_time": "2025-12-29 12:01:31",
    "extra_info": "{\"url\": \"https://huggingface.co/papers/2512.17504\", \"arxiv_url\": \"https://arxiv.org/abs/2512.17504\", \"thumbnail\": \"https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2512.17504.png\", \"original_title\": \"InsertAnywhere: Bridging 4D Scene Geometry and Diffusion Models for Realistic Video Object Insertion\"}"
  },
  {
    "id": "2512.22047",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2512.22047",
    "title": "MAI-UI Technical Report: Real-World Centric Foundation GUI Agents",
    "summary": "The development of GUI agents could revolutionize the next generation of human-computer interaction. Motivated by this vision, we present MAI-UI, a family of foundation GUI agents spanning the full spectrum of sizes, including 2B, 8B, 32B, and 235B-A22B variants. We identify four key challenges to realistic deployment: the lack of native agent-user interaction, the limits of UI-only operation, the absence of a practical deployment architecture, and brittleness in dynamic environments. MAI-UI addresses these issues with a unified methodology: a self-evolving data pipeline that expands the navigation data to include user interaction and MCP tool calls, a native device-cloud collaboration system routes execution by task state, and an online RL framework with advanced optimizations to scale parallel environments and context length. MAI-UI establishes new state-of-the-art across GUI grounding and mobile navigation. On grounding benchmarks, it reaches 73.5% on ScreenSpot-Pro, 91.3% on MMBench GUI L2, 70.9% on OSWorld-G, and 49.2% on UI-Vision, surpassing Gemini-3-Pro and Seed1.8 on ScreenSpot-Pro. On mobile GUI navigation, it sets a new SOTA of 76.7% on AndroidWorld, surpassing UI-Tars-2, Gemini-2.5-Pro and Seed1.8. On MobileWorld, MAI-UI obtains 41.7% success rate, significantly outperforming end-to-end GUI models and competitive with Gemini-3-Pro based agentic frameworks. Our online RL experiments show significant gains from scaling parallel environments from 32 to 512 (+5.2 points) and increasing environment step budget from 15 to 50 (+4.3 points). Finally, the native device-cloud collaboration system improves on-device performance by 33%, reduces cloud model calls by over 40%, and preserves user privacy.",
    "keywords": [
      "Foundation GUI Agents",
      "Human-Computer Interaction",
      "Online Reinforcement Learning",
      "Device-Cloud Collaboration",
      "Mobile GUI Navigation"
    ],
    "area": [
      "AI Agent",
      "Machine Learning",
      "Deep Learning"
    ],
    "published_time": "2025-12-26T14:51:52.000Z",
    "download_time": "2025-12-29 12:01:31",
    "extra_info": "{\"url\": \"https://huggingface.co/papers/2512.22047\", \"arxiv_url\": \"https://arxiv.org/abs/2512.22047\", \"thumbnail\": \"https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2512.22047.png\", \"original_title\": \"MAI-UI Technical Report: Real-World Centric Foundation GUI Agents\"}"
  },
  {
    "id": "2512.21675",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2512.21675",
    "title": "UniPercept: Towards Unified Perceptual-Level Image Understanding across Aesthetics, Quality, Structure, and Texture",
    "summary": "Multimodal large language models (MLLMs) have achieved remarkable progress in visual understanding tasks such as visual grounding, segmentation, and captioning. However, their ability to perceive perceptual-level image features remains limited. In this work, we present UniPercept-Bench, a unified framework for perceptual-level image understanding across three key domains: Aesthetics, Quality, Structure and Texture. We establish a hierarchical definition system and construct large-scale datasets to evaluate perceptual-level image understanding. Based on this foundation, we develop a strong baseline UniPercept trained via Domain-Adaptive Pre-Training and Task-Aligned RL, enabling robust generalization across both Visual Rating (VR) and Visual Question Answering (VQA) tasks. UniPercept outperforms existing MLLMs on perceptual-level image understanding and can serve as a plug-and-play reward model for text-to-image generation. This work defines Perceptual-Level Image Understanding in the era of MLLMs and, through the introduction of a comprehensive benchmark together with a strong baseline, provides a solid foundation for advancing perceptual-level multimodal image understanding.",
    "keywords": [
      "Perceptual-Level Image Understanding",
      "Multimodal Large Language Models",
      "Visual Question Answering",
      "Visual Rating",
      "Text-to-Image Generation"
    ],
    "area": [
      "Multimodal",
      "Large Language Model",
      "Computer Vision"
    ],
    "published_time": "2025-12-25T13:35:52.000Z",
    "download_time": "2025-12-29 12:01:31",
    "extra_info": "{\"url\": \"https://huggingface.co/papers/2512.21675\", \"arxiv_url\": \"https://arxiv.org/abs/2512.21675\", \"thumbnail\": \"https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2512.21675.png\", \"original_title\": \"UniPercept: Towards Unified Perceptual-Level Image Understanding across Aesthetics, Quality, Structure, and Texture\"}"
  },
  {
    "id": "2512.21919",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2512.21919",
    "title": "SWE-RM: Execution-free Feedback For Software Engineering Agents",
    "summary": "Execution-based feedback like unit testing is widely used in the development of coding agents through test-time scaling (TTS) and reinforcement learning (RL). This paradigm requires scalable and reliable collection of unit test cases to provide accurate feedback, and the resulting feedback is often sparse and cannot effectively distinguish between trajectories that are both successful or both unsuccessful. In contrast, execution-free feedback from reward models can provide more fine-grained signals without depending on unit test cases. Despite this potential, execution-free feedback for realistic software engineering (SWE) agents remains underexplored. Aiming to develop versatile reward models that are effective across TTS and RL, however, we observe that two verifiers with nearly identical TTS performance can nevertheless yield very different results in RL. Intuitively, TTS primarily reflects the model's ability to select the best trajectory, but this ability does not necessarily generalize to RL. To address this limitation, we identify two additional aspects that are crucial for RL training: classification accuracy and calibration. We then conduct comprehensive controlled experiments to investigate how to train a robust reward model that performs well across these metrics. In particular, we analyze the impact of various factors such as training data scale, policy mixtures, and data source composition. Guided by these investigations, we introduce SWE-RM, an accurate and robust reward model adopting a mixture-of-experts architecture with 30B total parameters and 3B activated during inference. SWE-RM substantially improves SWE agents on both TTS and RL performance. For example, it increases the accuracy of Qwen3-Coder-Flash from 51.6% to 62.0%, and Qwen3-Coder-Max from 67.0% to 74.6% on SWE-Bench Verified using TTS, achieving new state-of-the-art performance among open-source models.",
    "keywords": [
      "Software Engineering Agents",
      "Execution-free Feedback",
      "Reward Models",
      "Reinforcement Learning",
      "Test-Time Scaling"
    ],
    "area": [
      "AI Agent",
      "Machine Learning",
      "Large Language Model"
    ],
    "published_time": "2025-12-26T08:26:18.000Z",
    "download_time": "2025-12-29 12:01:30",
    "extra_info": "{\"url\": \"https://huggingface.co/papers/2512.21919\", \"arxiv_url\": \"https://arxiv.org/abs/2512.21919\", \"thumbnail\": \"https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2512.21919.png\", \"original_title\": \"SWE-RM: Execution-free Feedback For Software Engineering Agents\"}"
  },
  {
    "id": "2512.21625",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2512.21625",
    "title": "Rethinking Sample Polarity in Reinforcement Learning with Verifiable Rewards",
    "summary": "Large reasoning models (LRMs) are typically trained using reinforcement learning with verifiable reward (RLVR) to enhance their reasoning abilities. In this paradigm, policies are updated using both positive and negative self-generated rollouts, which correspond to distinct sample polarities. In this paper, we provide a systematic investigation into how these sample polarities affect RLVR training dynamics and behaviors. We find that positive samples sharpen existing correct reasoning patterns, while negative samples encourage exploration of new reasoning paths. We further explore how adjusting the advantage values of positive and negative samples at both the sample level and the token level affects RLVR training. Based on these insights, we propose an Adaptive and Asymmetric token-level Advantage shaping method for Policy Optimization, namely A3PO, that more precisely allocates advantage signals to key tokens across different polarities. Experiments across five reasoning benchmarks demonstrate the effectiveness of our approach.",
    "keywords": [
      "Reinforcement Learning",
      "Verifiable Rewards",
      "Large Reasoning Models",
      "Sample Polarity",
      "Policy Optimization"
    ],
    "area": [
      "Artificial Intelligence",
      "Machine Learning",
      "Large Language Model"
    ],
    "published_time": "2025-12-25T11:15:46.000Z",
    "download_time": "2025-12-29 12:01:29",
    "extra_info": "{\"url\": \"https://huggingface.co/papers/2512.21625\", \"arxiv_url\": \"https://arxiv.org/abs/2512.21625\", \"thumbnail\": \"https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2512.21625.png\", \"original_title\": \"Rethinking Sample Polarity in Reinforcement Learning with Verifiable Rewards\"}"
  }
]