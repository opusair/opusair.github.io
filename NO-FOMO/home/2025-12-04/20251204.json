[
  {
    "id": "hackernews_46145180",
    "source": "Hacker News",
    "url": "https://arxiv.org/abs/2512.04047",
    "title": "Elites could shape mass preferences as AI reduces persuasion costs",
    "summary": "A recent study explores the profound implications of artificial intelligence in potentially reshaping societal preferences by significantly reducing the costs associated with persuasion. The research posits that the advanced capabilities of AI, particularly in sophisticated communication and targeted messaging, could empower 'elites' to exert unprecedented influence over mass opinions and collective decision-making. This phenomenon raises critical concerns regarding democratic processes, information integrity, and the potential for manipulation on a large scale. The paper likely delves into the mechanisms through which AI facilitates this reduction in persuasion costs, such as hyper-personalization, automated content generation, and efficient dissemination strategies. It underscores the urgent need for robust ethical frameworks and regulatory measures to mitigate the risks associated with such powerful technologies and to safeguard against potential abuses that could undermine societal stability and individual autonomy.",
    "keywords": [
      "Artificial Intelligence",
      "Persuasion Technology",
      "Public Opinion",
      "Social Influence",
      "AI Ethics",
      "Information Manipulation"
    ],
    "area": [
      "Artificial Intelligence",
      "Natural Language Processing",
      "AI Agent"
    ],
    "published_time": "2025-12-04 08:38:17",
    "download_time": "2025-12-04 20:01:44",
    "extra_info": "{\"score\": 381, \"by\": \"50kIters\", \"descendants\": 401, \"story_id\": 46145180}"
  },
  {
    "id": "hackernews_46148748",
    "source": "Hacker News",
    "url": "https://arstechnica.com/ai/2025/12/microsoft-slashes-ai-sales-growth-targets-as-customers-resist-unproven-agents/",
    "title": "Microsoft drops AI sales targets in half after salespeople miss their quotas",
    "summary": "Microsoft has reportedly halved its internal sales targets for artificial intelligence products after its sales force consistently failed to meet initial quotas. This significant adjustment suggests a growing resistance or slower-than-anticipated adoption from customers, particularly concerning what the linked article describes as 'unproven agents.' The move highlights potential challenges in the commercialization phase of advanced AI technologies, indicating that despite the widespread hype and substantial investment, translating cutting-edge AI capabilities into immediate, tangible business value for customers remains complex. This situation may prompt Microsoft to re-evaluate its go-to-market strategies for AI solutions, potentially leading to a greater focus on demonstrating clear ROI or refining product offerings to better align with customer needs and readiness. The decision underscores the practical difficulties tech giants face in monetizing nascent yet powerful technologies, pushing companies to adapt their sales expectations to the evolving realities of the enterprise AI market.",
    "keywords": [
      "Microsoft AI",
      "AI sales",
      "Market adoption",
      "Enterprise AI",
      "AI agents",
      "Business strategy"
    ],
    "area": [
      "Artificial Intelligence",
      "AI Agent",
      "Generative AI"
    ],
    "published_time": "2025-12-04 15:31:52",
    "download_time": "2025-12-04 20:01:26",
    "extra_info": "{\"score\": 237, \"by\": \"OptionOfT\", \"descendants\": 181, \"story_id\": 46148748}"
  },
  {
    "id": "hackernews_46149727",
    "source": "Hacker News",
    "url": "https://www.browserbuddy.com/",
    "title": "Launch HN: Browser Buddy (YC W24) – A recommendation system for Internet writing",
    "summary": "Browser Buddy, a new venture from Y Combinator's W24 batch, has launched as a recommendation system designed to help users discover high-quality Internet writing. Developed by Arnav and Jeremy, the platform allows users to interact via chat to find content tailored to their specific interests and aspirations. The creators highlight the challenge of navigating the vast and often fragmented landscape of online content, where valuable insights are dispersed across numerous personal blogs and specialized publications. Browser Buddy aims to address this by curating and surfacing relevant articles and essays, inspired by the founders' personal experiences of discovering influential works online. This system seeks to simplify the discovery process for inspiring and informative writing, ensuring users can easily access content that broadens their perspectives and uncovers new opportunities, akin to how they themselves found inspiration from influential writers like Paul Graham. The platform's interactive chat interface is a key feature, making content discovery more intuitive and personalized.",
    "keywords": [
      "Recommendation Systems",
      "Natural Language Processing",
      "Content Curation",
      "Conversational AI",
      "Personalized Recommendations",
      "Information Retrieval"
    ],
    "area": [
      "Artificial Intelligence",
      "Machine Learning",
      "Natural Language Processing"
    ],
    "published_time": "2025-12-04 16:52:56",
    "download_time": "2025-12-04 20:01:09",
    "extra_info": "{\"score\": 26, \"by\": \"alien0006\", \"descendants\": 20, \"story_id\": 46149727}"
  },
  {
    "id": "hackernews_46150806",
    "source": "Hacker News",
    "url": "https://www.theverge.com/news/837594/crucial-ram-ssd-micron-ai",
    "title": "Crucial shutting down as Micron wants to sell RAM/SSDs to AI companies instead",
    "summary": "Micron Technology, a prominent semiconductor manufacturer, is reportedly discontinuing its Crucial brand, which has historically catered to the consumer market with its range of RAM and SSD products. This strategic realignment signifies Micron's intent to reallocate manufacturing capabilities and commercial focus towards supplying high-performance components directly to artificial intelligence enterprises. The move highlights a prevailing industry trend where the escalating demands of AI infrastructure, particularly for advanced memory and storage solutions, are influencing the operational strategies of major hardware producers. By prioritizing the burgeoning AI sector, Micron aims to capitalize on the increasing need for specialized, high-capacity computing hardware, positioning itself as a key supplier for ongoing AI development and deployment initiatives. This shift underscores the significant financial opportunities and technological imperatives driving the AI industry, prompting a fundamental re-evaluation of Micron's market engagement strategy.",
    "keywords": [
      "Micron Technology",
      "Crucial",
      "RAM",
      "SSDs",
      "Artificial Intelligence Hardware",
      "Semiconductor Industry",
      "Memory Solutions"
    ],
    "area": [
      "Artificial Intelligence",
      "Machine Learning",
      "Others"
    ],
    "published_time": "2025-12-04 18:11:36",
    "download_time": "2025-12-04 20:01:43",
    "extra_info": "{\"score\": 22, \"by\": \"kjhughes\", \"descendants\": 1, \"story_id\": 46150806}"
  },
  {
    "id": "hackernews_46151288",
    "source": "Hacker News",
    "url": "https://www.businessinsider.com/us-to-review-h-1b-applicants-social-media-state-dept-2025-12",
    "title": "US will now review H-1B applicants' social media – require them to make public",
    "summary": "The United States has unveiled a new policy mandating H-1B visa applicants to make their social media profiles publicly accessible for official review. This significant policy alteration highlights a growing governmental emphasis on integrating individuals' digital footprints into the immigration vetting process. While the official communication does not detail the specific methodologies for this review, the sheer volume of data involved with widespread applicant submissions suggests a potential future reliance on advanced technological solutions. Such an approach could involve sophisticated automated social media analysis, leveraging natural language processing for textual content evaluation, and potentially computer vision for assessing images and videos. This development brings forth crucial discussions surrounding digital privacy, the security of personal data, and the ethical considerations of governmental access to online behavior records. It implies a landscape where digital identity and online conduct will increasingly influence visa decisions, potentially driving the adoption of advanced analytical tools to process and interpret extensive social media data.",
    "keywords": [
      "Social Media Analysis",
      "Data Privacy",
      "Digital Identity",
      "Natural Language Processing",
      "Computer Vision",
      "Automated Vetting"
    ],
    "area": [
      "Artificial Intelligence",
      "Natural Language Processing",
      "Computer Vision"
    ],
    "published_time": "2025-12-04 18:48:29",
    "download_time": "2025-12-04 20:01:41",
    "extra_info": "{\"score\": 15, \"by\": \"JKCalhoun\", \"descendants\": 14, \"story_id\": 46151288}"
  },
  {
    "id": "hackernews_46151851",
    "source": "Hacker News",
    "url": "https://www.conspicuouscognition.com/p/lets-not-bring-back-the-gatekeepers",
    "title": "Let's Not Bring Back the Gatekeepers",
    "summary": "The article, \"Let's Not Bring Back the Gatekeepers,\" advocates for maintaining open and decentralized systems in technology and information dissemination, arguing against the resurgence of centralized control or undue influence over critical platforms and content. It likely explores concerns that various entities, whether corporations, governments, or influential groups, could re-establish mechanisms that restrict access, stifle innovation, or shape narratives, thereby limiting freedom and user autonomy. The piece implicitly calls for vigilance against trends that consolidate power, potentially examining historical examples of gatekeeping and drawing parallels to contemporary technological landscapes, including discussions around platform moderation, algorithm control, or the power dynamics within the development and deployment of advanced AI systems. The author's stance emphasizes the importance of open standards, transparent processes, and diverse participation to ensure that the internet and emerging technologies continue to foster innovation and equitable access without the imposition of restrictive intermediaries. This perspective highlights the ongoing debate about balancing freedom with governance in the digital age.",
    "keywords": [
      "Decentralization",
      "Platform Control",
      "Open Internet",
      "Technological Autonomy",
      "Information Access",
      "Digital Governance"
    ],
    "area": [
      "Artificial Intelligence",
      "AI Agent",
      "Natural Language Processing"
    ],
    "published_time": "2025-12-04 19:38:48",
    "download_time": "2025-12-04 20:01:56",
    "extra_info": "{\"score\": 3, \"by\": \"paulpauper\", \"descendants\": 0, \"story_id\": 46151851}"
  },
  {
    "id": "next-ai-draw-io",
    "source": "GitHub",
    "url": "https://github.com/DayuanJiang/next-ai-draw-io",
    "title": "Next AI Draw.io",
    "summary": "Next AI Draw.io is an innovative Next.js web application that seamlessly integrates AI capabilities with the popular draw.io diagramming platform. It empowers users to create, modify, and enhance complex visual representations, including specialized AWS, GCP, and Azure architecture diagrams, directly through natural language commands. Core functionalities encompass LLM-powered diagram generation from textual prompts, intelligent replication and enhancement of diagrams from uploaded images, and robust version control to track and restore diagram history. The application features an interactive chat interface for real-time AI-driven refinement and supports dynamic animated connectors for improved visualization. Leveraging Next.js, Vercel AI SDK, and react-drawio, it offers extensive multi-provider AI compatibility, supporting major platforms like AWS Bedrock, OpenAI, and Anthropic, making it a powerful and versatile tool for intelligent and efficient diagramming workflows.",
    "keywords": [
      "AI-Powered Diagram",
      "Large Language Model",
      "Diagram Generation",
      "Next.js",
      "draw.io",
      "Architecture Diagrams",
      "Natural Language Processing"
    ],
    "area": [
      "Artificial Intelligence",
      "Large Language Model",
      "Generative AI"
    ],
    "published_time": "2025-12-04T16:30:02Z",
    "download_time": "2024-05-16 14:02:44",
    "extra_info": null
  },
  {
    "id": "codex",
    "source": "GitHub",
    "url": "https://github.com/openai/codex",
    "title": "Codex CLI",
    "summary": "Codex CLI is a powerful coding agent developed by OpenAI, designed to operate locally on a user's computer. It facilitates coding tasks through a command-line interface, offering seamless integration with various development workflows. Users can install Codex globally via `npm` or `Homebrew`, and get started with a simple `codex` command. The tool supports authentication through existing ChatGPT plans (Plus, Pro, Team, Edu, Enterprise) or via an OpenAI API key for usage-based billing, with clear migration paths for existing API key users. Key features include support for the Model Context Protocol (MCP), extensive configuration options stored in `~/.codex/config.toml`, and a robust Execpolicy system for defining command execution rules. Codex CLI also offers automation capabilities through a dedicated GitHub Action and a TypeScript SDK, alongside a non-interactive `codex exec` mode for advanced use cases. It aims to empower developers with an intelligent local assistant for enhancing productivity and streamlining coding processes.",
    "keywords": [
      "AI Agent",
      "Coding Assistant",
      "CLI Tool",
      "OpenAI",
      "ChatGPT Integration",
      "Software Development",
      "Code Automation"
    ],
    "area": [
      "Artificial Intelligence",
      "AI Agent",
      "Natural Language Processing"
    ],
    "published_time": "2025-12-04T20:00:18Z",
    "download_time": "2024-05-15 12:30:00",
    "extra_info": null
  },
  {
    "id": "2511.21631",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2511.21631",
    "title": "Qwen3-VL Technical Report",
    "summary": "We introduce Qwen3-VL, the most capable vision-language model in the Qwen series to date, achieving superior performance across a broad range of multimodal benchmarks. It natively supports interleaved contexts of up to 256K tokens, seamlessly integrating text, images, and video. The model family includes both dense (2B/4B/8B/32B) and mixture-of-experts (30B-A3B/235B-A22B) variants to accommodate diverse latency-quality trade-offs. Qwen3-VL delivers three core pillars: (i) markedly stronger pure-text understanding, surpassing comparable text-only backbones in several cases; (ii) robust long-context comprehension with a native 256K-token window for both text and interleaved multimodal inputs, enabling faithful retention, retrieval, and cross-referencing across long documents and videos; and (iii) advanced multimodal reasoning across single-image, multi-image, and video tasks, demonstrating leading performance on comprehensive evaluations such as MMMU and visual-math benchmarks (e.g., MathVista and MathVision). Architecturally, we introduce three key upgrades: (i) an enhanced interleaved-MRoPE for stronger spatial-temporal modeling across images and video; (ii) DeepStack integration, which effectively leverages multi-level ViT features to tighten vision-language alignment; and (iii) text-based time alignment for video, evolving from T-RoPE to explicit textual timestamp alignment for more precise temporal grounding. Under comparable token budgets and latency constraints, Qwen3-VL achieves superior performance in both dense and Mixture-of-Experts (MoE) architectures. We envision Qwen3-VL serving as a foundational engine for image-grounded reasoning, agentic decision-making, and multimodal code intelligence in real-world workflows.",
    "keywords": [
      "Qwen3-VL",
      "vision-language model",
      "multimodal benchmarks",
      "long-context comprehension",
      "Mixture-of-Experts"
    ],
    "area": [
      "Multimodal",
      "Large Language Model",
      "Deep Learning"
    ],
    "published_time": "2025-11-26T17:59:08.000Z",
    "download_time": "2025-12-04 12:02:08",
    "extra_info": "{\"url\": \"https://huggingface.co/papers/2511.21631\", \"arxiv_url\": \"https://arxiv.org/abs/2511.21631\", \"thumbnail\": \"https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2511.21631.png\", \"original_title\": \"Qwen3-VL Technical Report\"}"
  },
  {
    "id": "2512.03442",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2512.03442",
    "title": "PretrainZero: Reinforcement Active Pretraining",
    "summary": "Mimicking human behavior to actively learning from general experience and achieve artificial general intelligence has always been a human dream. Recent reinforcement learning (RL) based large-thinking models demonstrate impressive expert-level abilities, i.e., software and math, but still rely heavily on verifiable rewards in specific domains, placing a significant bottleneck to extend the performance boundary of general reasoning capabilities. In this work, we propose PretrainZero, a reinforcement active learning framework built on the pretraining corpus to extend RL from domain-specific post-training to general pretraining. PretrainZero features the following characteristics: 1) Active pretraining: inspired by the active learning ability of humans, PretrainZero learns a unified reasoning policy to actively identify reasonable and informative contents from pretraining corpus, and reason to predict these contents by RL. 2) Self-supervised learning: without any verifiable labels, pretrained reward models, or supervised fine-tuning, we directly pretrain reasoners from 3 to 30B base models on the general Wikipedia corpus using RL, significantly breaking the verification data-wall for general reasoning. 3) Verification scaling: by tackling increasingly challenging masked spans, PretrainZero substantially enhances the general reasoning abilities of pretrained base models. In reinforcement pretraining, PretrainZero improves Qwen3-4B-Base for 8.43, 5.96 and 10.60 on MMLU-Pro, SuperGPQA and math average benchmarks. In post-training, the pretrained models can also serve as reasoning foundation models for downstream RLVR tasks.",
    "keywords": [
      "Reinforcement Learning",
      "Active Pretraining",
      "Self-supervised Learning",
      "General Reasoning",
      "Artificial General Intelligence"
    ],
    "area": [
      "Artificial Intelligence",
      "Machine Learning",
      "Large Language Model"
    ],
    "published_time": "2025-12-03T04:51:32.000Z",
    "download_time": "2025-12-04 12:02:08",
    "extra_info": "{\"url\": \"https://huggingface.co/papers/2512.03442\", \"arxiv_url\": \"https://arxiv.org/abs/2512.03442\", \"thumbnail\": \"https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2512.03442.png\", \"original_title\": \"PretrainZero: Reinforcement Active Pretraining\"}"
  },
  {
    "id": "2512.04069",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2512.04069",
    "title": "SpaceTools: Tool-Augmented Spatial Reasoning via Double Interactive RL",
    "summary": "Vision Language Models (VLMs) demonstrate strong qualitative visual understanding, but struggle with metrically precise spatial reasoning required for embodied applications. The agentic paradigm promises that VLMs can use a wide variety of tools that could augment these capabilities, such as depth estimators, segmentation models, and pose estimators. Yet it remains an open challenge how to realize this vision without solely relying on handcrafted prompting strategies or enforcing fixed, predefined tool pipelines that limit VLMs' ability to discover optimal tool-use patterns. Reinforcement Learning could overcome this gap, but has so far been limited to reasoning with a single visual tool due to the large search space in multi-tool reasoning. We introduce Double Interactive Reinforcement Learning (DIRL), a two-phase training framework where VLMs learn to coordinate multiple tools through interactive exploration and feedback. In the teaching phase, we combine demonstrations from a single tool specialist trained via interactive RL with traces from a frontier model using all tools. In the exploration phase, the model further refines multi-tool coordination through continued RL. Our model, SpaceTools, with tool-augmented spatial reasoning ability, achieves state-of-the-art performance on spatial understanding benchmarks (RoboSpatial-Home, BLINK, BOP-ASK) and demonstrates reliable real-world manipulation using a 7-DOF robot as a tool. DIRL provides substantial improvements over the vanilla SFT (+12% on RoboSpatial) and RL (+16% on RoboSpatial) baselines. Project page: https://spacetools.github.io/.",
    "keywords": [
      "Vision Language Models",
      "Spatial Reasoning",
      "Reinforcement Learning",
      "Tool Use",
      "AI Agent"
    ],
    "area": [
      "Multimodal",
      "AI Agent",
      "Robotics"
    ],
    "published_time": "2025-12-03T18:50:04.000Z",
    "download_time": "2025-12-04 12:02:10",
    "extra_info": "{\"url\": \"https://huggingface.co/papers/2512.04069\", \"arxiv_url\": \"https://arxiv.org/abs/2512.04069\", \"thumbnail\": \"https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2512.04069.png\", \"original_title\": \"SpaceTools: Tool-Augmented Spatial Reasoning via Double Interactive RL\"}"
  },
  {
    "id": "2512.04040",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2512.04040",
    "title": "RELIC: Interactive Video World Model with Long-Horizon Memory",
    "summary": "A truly interactive world model requires three key ingredients: real-time long-horizon streaming, consistent spatial memory, and precise user control. However, most existing approaches address only one of these aspects in isolation, as achieving all three simultaneously is highly challenging-for example, long-term memory mechanisms often degrade real-time performance. In this work, we present RELIC, a unified framework that tackles these three challenges altogether. Given a single image and a text description, RELIC enables memory-aware, long-duration exploration of arbitrary scenes in real time. Built upon recent autoregressive video-diffusion distillation techniques, our model represents long-horizon memory using highly compressed historical latent tokens encoded with both relative actions and absolute camera poses within the KV cache. This compact, camera-aware memory structure supports implicit 3D-consistent content retrieval and enforces long-term coherence with minimal computational overhead. In parallel, we fine-tune a bidirectional teacher video model to generate sequences beyond its original 5-second training horizon, and transform it into a causal student generator using a new memory-efficient self-forcing paradigm that enables full-context distillation over long-duration teacher as well as long student self-rollouts. Implemented as a 14B-parameter model and trained on a curated Unreal Engine-rendered dataset, RELIC achieves real-time generation at 16 FPS while demonstrating more accurate action following, more stable long-horizon streaming, and more robust spatial-memory retrieval compared with prior work. These capabilities establish RELIC as a strong foundation for the next generation of interactive world modeling.",
    "keywords": [
      "Interactive World Model",
      "Long-Horizon Memory",
      "Video Diffusion",
      "Real-time Generation",
      "Spatial Memory"
    ],
    "area": [
      "Generative AI",
      "Computer Vision",
      "Multimodal"
    ],
    "published_time": "2025-12-03T18:29:20.000Z",
    "download_time": "2025-12-04 12:02:10",
    "extra_info": "{\"url\": \"https://huggingface.co/papers/2512.04040\", \"arxiv_url\": \"https://arxiv.org/abs/2512.04040\", \"thumbnail\": \"https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2512.04040.png\", \"original_title\": \"RELIC: Interactive Video World Model with Long-Horizon Memory\"}"
  },
  {
    "id": "2512.03534",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2512.03534",
    "title": "Rethinking Prompt Design for Inference-time Scaling in Text-to-Visual Generation",
    "summary": "Achieving precise alignment between user intent and generated visuals remains a central challenge in text-to-visual generation, as a single attempt often fails to produce the desired output. To handle this, prior approaches mainly scale the visual generation process (e.g., increasing sampling steps or seeds), but this quickly leads to a quality plateau. This limitation arises because the prompt, crucial for guiding generation, is kept fixed. To address this, we propose Prompt Redesign for Inference-time Scaling, coined PRIS, a framework that adaptively revises the prompt during inference in response to the scaled visual generations. The core idea of PRIS is to review the generated visuals, identify recurring failure patterns across visuals, and redesign the prompt accordingly before regenerating the visuals with the revised prompt. To provide precise alignment feedback for prompt revision, we introduce a new verifier, element-level factual correction, which evaluates the alignment between prompt attributes and generated visuals at a fine-grained level, achieving more accurate and interpretable assessments than holistic measures. Extensive experiments on both text-to-image and text-to-video benchmarks demonstrate the effectiveness of our approach, including a 15% gain on VBench 2.0. These results highlight that jointly scaling prompts and visuals is key to fully leveraging scaling laws at inference-time. Visualizations are available at the website: https://subin-kim-cv.github.io/PRIS.",
    "keywords": [
      "Prompt Design",
      "Text-to-Visual Generation",
      "Inference-time Scaling",
      "Adaptive Prompting",
      "Factual Correction"
    ],
    "area": [
      "Generative AI",
      "Computer Vision",
      "Multimodal"
    ],
    "published_time": "2025-12-03T07:54:05.000Z",
    "download_time": "2025-12-04 12:02:08",
    "extra_info": "{\"url\": \"https://huggingface.co/papers/2512.03534\", \"arxiv_url\": \"https://arxiv.org/abs/2512.03534\", \"thumbnail\": \"https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2512.03534.png\", \"original_title\": \"Rethinking Prompt Design for Inference-time Scaling in Text-to-Visual Generation\"}"
  },
  {
    "id": "2511.20494",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2511.20494",
    "title": "Adversarial Confusion Attack: Disrupting Multimodal Large Language Models",
    "summary": "We introduce the Adversarial Confusion Attack, a new class of threats against multimodal large language models (MLLMs). Unlike jailbreaks or targeted misclassification, the goal is to induce systematic disruption that makes the model generate incoherent or confidently incorrect outputs. Practical applications include embedding such adversarial images into websites to prevent MLLM-powered AI Agents from operating reliably. The proposed attack maximizes next-token entropy using a small ensemble of open-source MLLMs. In the white-box setting, we show that a single adversarial image can disrupt all models in the ensemble, both in the full-image and Adversarial CAPTCHA settings. Despite relying on a basic adversarial technique (PGD), the attack generates perturbations that transfer to both unseen open-source (e.g., Qwen3-VL) and proprietary (e.g., GPT-5.1) models.",
    "keywords": [
      "Adversarial Attack",
      "Multimodal Large Language Models",
      "AI Agents",
      "Model Disruption",
      "Transferability"
    ],
    "area": [
      "Artificial Intelligence",
      "Multimodal",
      "Large Language Model"
    ],
    "published_time": "2025-11-25T17:00:31.000Z",
    "download_time": "2025-12-04 12:02:07",
    "extra_info": "{\"url\": \"https://huggingface.co/papers/2511.20494\", \"arxiv_url\": \"https://arxiv.org/abs/2511.20494\", \"thumbnail\": \"https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2511.20494.png\", \"original_title\": \"Adversarial Confusion Attack: Disrupting Multimodal Large Language Models\"}"
  }
]