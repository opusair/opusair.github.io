[
  {
    "id": "twitter_AndrewYNg_1930277912030392356",
    "source": "Twitter",
    "url": "https://twitter.com/AndrewYNg/status/1930277912030392356",
    "title": "AndrewYNg_DSPy智能体应用优化新课程发布",
    "summary": "Andrew Ng宣布推出全新短课程，聚焦于DSPy框架在构建和优化智能体应用中的实践。DSPy是一个强大的开源工具，旨在自动化生成式AI应用的提示词调优，尤其适用于复杂智能体AI工作流。该课程由deeplearning.ai与Databricks合作推出，并由DSPy联合负责人ChenMoneyQ主讲。它能帮助AI开发者摆脱耗时的手动提示词调优，通过自动化优化提升模型性能，并能快速适应新的大型语言模型，确保系统表现。课程内容涵盖DSPy的签名编程模型、MLflow调试与DSPy优化器。",
    "keywords": [
      "DSPy",
      "智能体",
      "提示词优化",
      "生成式AI",
      "开源框架",
      "在线课程"
    ],
    "area": [
      "人工智能",
      "智能体",
      "大模型"
    ],
    "published_time": "2025-06-04T14:58:11.000Z",
    "download_time": "2025-06-04 21:53:02",
    "visual_resource": [
      "screenshot/twitter/AndrewYNg_1930277912030392356.png"
    ],
    "extra_info": "{\"username\": \"AndrewYNg\", \"tweet_id\": \"1930277912030392356\"}"
  },
  {
    "id": "twitter_natolambert_1930266554241016038",
    "source": "Twitter",
    "url": "https://twitter.com/natolambert/status/1930266554241016038",
    "title": "natolambert_AI模型进步源于艰苦工作与规划，未来模型需具备多项核心能力",
    "summary": "Nathan Lambert指出，AI模型的显著进步并非自然发生，而是源于艰苦卓绝的工作，特别是数据创建和前瞻性规划。他强调，规划能力将是推动AI发展实现下一个量级增长的关键。针对未来模型，Lambert提出了四项核心能力：解决独立问题的“技能”、评估问题难度的“校准”、选择高层计划的“策略”以及将策略分解的“抽象”。他认为，当前学术研究侧重于技能，而忽视了规划，但未来的AI模型将更注重规划性、战略性及任务分解能力，以应对复杂现实世界应用。",
    "keywords": [
      "人工智能",
      "模型发展",
      "规划能力",
      "数据创建",
      "智能体",
      "研究进展"
    ],
    "area": [
      "人工智能",
      "大模型",
      "智能体"
    ],
    "published_time": "2025-06-04T14:13:03.000Z",
    "download_time": "2025-06-04 21:59:38",
    "visual_resource": [
      "screenshot/twitter/natolambert_1930266554241016038.png"
    ],
    "extra_info": "{\"username\": \"natolambert\", \"tweet_id\": \"1930266554241016038\"}"
  },
  {
    "id": "twitter_jonathanrichens_1930221408199516657",
    "source": "Twitter",
    "url": "https://twitter.com/jonathanrichens/status/1930221408199516657",
    "title": "jonathanrichens_ICML2025论文探讨世界模型与智能体关系",
    "summary": "乔恩·里奇斯（Jon Richens）发布推文，宣布其团队在ICML 2025上发表的最新论文，深入探讨了实现人类水平智能体是否必须依赖世界模型的问题。该研究从第一性原理出发，得出了一个令人惊讶的结论：智能体本身即是世界模型。这篇论文挑战了传统观念，为智能体设计和人工智能发展提供了新的视角和理论基础，预示着未来智能体研究可能走向新的方向。",
    "keywords": [
      "世界模型",
      "智能体",
      "ICML2025",
      "人工智能",
      "机器学习",
      "研究进展"
    ],
    "area": [
      "人工智能",
      "智能体",
      "研究进展"
    ],
    "published_time": "2025-06-04T11:13:40.000Z",
    "download_time": "2025-06-04 21:56:39",
    "visual_resource": [
      "screenshot/twitter/jonathanrichens_1930221408199516657.png"
    ],
    "extra_info": "{\"username\": \"jonathanrichens\", \"tweet_id\": \"1930221408199516657\"}"
  },
  {
    "id": "BbwlPVWjcvz8wZ1FmVqfMw",
    "source": "wechat",
    "url": "https://mp.weixin.qq.com/s/BbwlPVWjcvz8wZ1FmVqfMw",
    "title": "RMoA残差提取Mixture-of-Agents，让Agent发现新东西，并自适应停止「ACL2025」",
    "summary": "华东师范大学、美团等机构联合提出RMoA（Residual Mixture-of-Agents）框架，旨在解决传统MoA高成本与性能瓶颈。RMoA引入残差学习理念，通过多样性选择、残差提取与聚合智能体及自适应终止机制，使智能体专注于发现并贡献独特新信息。该框架在多个基准测试中显著提升性能并大幅降低计算成本，其强调成本控制与认知多样性，并在实际场景中验证了高效性与实用性，为AI系统发展提供了新思路。",
    "keywords": [
      "RMoA",
      "Mixture-of-Agents",
      "残差学习",
      "智能体",
      "成本控制",
      "自适应终止",
      "多样性选择"
    ],
    "area": [
      "智能体",
      "大模型",
      "生成式AI"
    ],
    "published_time": "2025-06-04T20:13:18.000Z",
    "download_time": "2025-06-06T09:11:04.161379",
    "visual_resource": [
      "screenshot/20250604/wechat/wechat_image_BbwlPVWjcvz8wZ1FmVqfMw.png"
    ],
    "extra_info": null
  },
  {
    "id": "3y2NkmHMEHUxkLetjOBg_g",
    "source": "wechat",
    "url": "https://mp.weixin.qq.com/s/3y2NkmHMEHUxkLetjOBg_g",
    "title": "人物｜王鹤：北大90后教授，12亿资本押宝的银河通用创始人，拒绝模仿特斯拉，闯出中国具身智能新范式",
    "summary": "90后北大教授、银河通用创始人王鹤，正开创具身智能新范式。他拒绝模仿特斯拉人形机器人，转而聚焦轮式底盘与机械臂的实用性，强调“边研发边落地”的商业策略。王鹤在斯坦福期间首创NOCS模型，提升机器人抓取泛化能力；回国后，其公司18个月内融资超12亿，并推出全球首个基于合成数据预训练的具身大模型GraspVLA，大幅提升研发效率与泛化性。Galbot机器人已与美团等合作，展现出强大的商业化潜力，推动中国具身智能从实验室走向市场。",
    "keywords": [
      "王鹤",
      "银河通用",
      "具身智能",
      "NOCS模型",
      "机器人",
      "合成数据",
      "具身大模型"
    ],
    "area": [
      "机器人",
      "智能体",
      "大模型"
    ],
    "published_time": "2025-06-04T13:04:29.000Z",
    "download_time": "2025-06-06T09:10:50.059991",
    "visual_resource": [
      "screenshot/20250604/wechat/wechat_image_3y2NkmHMEHUxkLetjOBg_g.png"
    ],
    "extra_info": null
  },
  {
    "id": "2RyYMfG-6ckj5PjJk0xXTg",
    "source": "wechat",
    "url": "https://mp.weixin.qq.com/s/2RyYMfG-6ckj5PjJk0xXTg",
    "title": "10步优化超越强化学习，仅需1条未标注数据！后训练强势破局",
    "summary": "新智元报道指出，当前大模型研究正聚焦解决复杂推理任务。传统后训练方法如强化学习（RL）虽能提升性能，但高度依赖大规模标注数据和复杂奖励函数，且计算开销大。Ubiquant研究团队提出突破性无监督方法“单样本熵最小化”（One-shot EM），仅需一条未标注数据和约10步优化，便能在数学推理任务上达到甚至超越RL效果。One-shot EM通过最小化模型预测分布的熵，增强模型自信度，其Logits分布向右偏移，与RL的左偏移形成对比。该方法高效、数据需求极低，尤其适用于未充分RL调优的基础模型及资源有限场景，为大模型后训练提供了低成本替代方案。研究同时指出EM可能导致“过度自信”和训练不稳定性，未来需关注其泛化能力及与现有技术的融合。",
    "keywords": [
      "大模型",
      "后训练",
      "熵最小化",
      "强化学习",
      "无监督学习",
      "数学推理"
    ],
    "area": [
      "大模型",
      "深度学习",
      "自然语言处理"
    ],
    "published_time": "2025-06-04T06:38:25.000Z",
    "download_time": "2025-06-06T09:10:47.167175",
    "visual_resource": [
      "screenshot/wechat/wechat_image_2RyYMfG-6ckj5PjJk0xXTg.png"
    ],
    "extra_info": null
  },
  {
    "id": "bV-6P4uuAvK9n9CoyfTeHw",
    "source": "wechat",
    "url": "https://mp.weixin.qq.com/s/bV-6P4uuAvK9n9CoyfTeHw",
    "title": "昇腾+鲲鹏联手上大招！华为爆改MoE训练，吞吐再飙升20%，内存省70%",
    "summary": "华为通过昇腾与鲲鹏算力深度协同，在MoE模型训练方面取得重大突破。针对MoE训练面临的算子计算效率低、NPU内存不足等挑战，华为提出“瘦身术”、“均衡术”、“搬运术”三大算子优化策略，并创新性地实现了Host-Device协同的算子下发优化及Selective R/S精准内存手术。这些技术使得MoE训练吞吐量再提升20%，内存占用降低70%，显著提升了大规模MoE模型训练效率与资源利用率，为AI大模型发展提供了高效解决方案。",
    "keywords": [
      "MoE",
      "华为",
      "昇腾",
      "鲲鹏",
      "算子优化",
      "内存优化",
      "大模型训练",
      "吞吐量"
    ],
    "area": [
      "大模型",
      "深度学习",
      "人工智能"
    ],
    "published_time": "2025-06-04T06:38:25.000Z",
    "download_time": "2025-06-06T09:10:42.401881",
    "visual_resource": [
      "screenshot/20250604/wechat/wechat_image_bV-6P4uuAvK9n9CoyfTeHw.png"
    ],
    "extra_info": null
  },
  {
    "id": "DAoNui-_u0IlBjHl16wn-g",
    "source": "wechat",
    "url": "https://mp.weixin.qq.com/s/DAoNui-_u0IlBjHl16wn-g",
    "title": "最新发现！每参数3.6比特，语言模型最多能记住这么多",
    "summary": "一项由Meta、DeepMind、康奈尔大学和英伟达联合发布的研究揭示，语言模型的记忆容量约为每参数3.6比特。研究团队提出新方法，区分模型对训练数据的“非预期记忆”与对潜在模式的“泛化”理解，发现模型在达到记忆极限后会停止记忆并转向泛化，出现“顿悟”（grokking）现象。这意味着语言模型并非无限记忆，其容量与参数量呈线性关系。该发现不仅量化了GPT系列模型的记忆极限，还为理解模型能力、评估风险提供了新视角，并对模型训练、安全、可靠性及蒸馏、量化等领域的研究具有重要启发意义。",
    "keywords": [
      "语言模型",
      "记忆容量",
      "泛化",
      "非预期记忆",
      "参数",
      "信息论",
      "grokking",
      "scalinglaw"
    ],
    "area": [
      "自然语言处理",
      "大模型",
      "机器学习"
    ],
    "published_time": "2025-06-04T04:42:28.000Z",
    "download_time": "2025-06-06T09:10:45.409431",
    "visual_resource": [
      "screenshot/20250604/wechat/wechat_image_DAoNui-_u0IlBjHl16wn-g.png"
    ],
    "extra_info": null
  },
  {
    "id": "I7si03-bVw_Uw3JXBD6VRw",
    "source": "wechat",
    "url": "https://mp.weixin.qq.com/s/I7si03-bVw_Uw3JXBD6VRw",
    "title": "重磅开源！首个全异步强化学习训练系统来了，SOTA推理大模型RL训练提速2.77倍",
    "summary": "清华大学与蚂蚁技术研究院联合开源了全异步强化学习训练系统AReaL-boba²，旨在解决传统同步RL训练效率低、门槛高的问题。该系统通过完全解耦模型生成与训练，实现了训练速度最高2.77倍的提升，并大幅优化GPU资源利用率。AReaL-boba²原生支持多轮智能体强化学习，并基于Qwen3系列模型在LiveCodeBench等代码任务基准上取得了SOTA性能。系统提供了详细教程和文档，支持深度定制，并开源了代码、数据集及模型权重，旨在让用户便捷高效地训练高性能推理模型，拥抱Agentic RL浪潮。其核心技术包括数据陈旧度控制和解耦近端策略优化目标，确保了异步训练下的收敛性能和模型效果。",
    "keywords": [
      "强化学习",
      "异步训练",
      "大模型",
      "代码生成",
      "智能体",
      "SOTA",
      "AReaL-boba²"
    ],
    "area": [
      "机器学习",
      "大模型",
      "智能体"
    ],
    "published_time": "2025-06-04T04:42:28.000Z",
    "download_time": "2025-06-06T09:10:45.025255",
    "visual_resource": [
      "screenshot/20250604/wechat/wechat_image_I7si03-bVw_Uw3JXBD6VRw.png"
    ],
    "extra_info": null
  },
  {
    "id": "agent-zero",
    "source": "GitHub",
    "url": "https://github.com/frdel/agent-zero",
    "title": "Agent Zero",
    "summary": "Agent Zero是一个动态、可定制的个人智能体框架，能随用户使用而学习成长。它将计算机作为工具，通过多智能体协作完成通用任务，并支持代码执行、自定义工具和实时交互。该框架高度透明且完全可配置，适用于开发、数据分析、内容创作等多种场景。",
    "keywords": [
      "智能体框架",
      "多智能体协作",
      "自动化",
      "代码执行",
      "个性化",
      "可定制",
      "Docker",
      "自然语言处理"
    ],
    "area": [
      "人工智能",
      "智能体",
      "大模型"
    ],
    "published_time": "2025-05-27T11:24:30Z",
    "download_time": "2024-05-27 12:00:00",
    "visual_resource": [
      "https://github.com/frdel/agent-zero/raw/main/docs/res/showcase-thumb.png",
      "https://github.com/frdel/agent-zero/raw/main/docs/res/ui-screen-2.png",
      "https://github.com/frdel/agent-zero/raw/main/docs/res/physics.png"
    ],
    "extra_info": null
  },
  {
    "id": "ardupilot",
    "source": "GitHub",
    "url": "https://github.com/ArduPilot/ardupilot",
    "title": "ArduPilot Project",
    "summary": "ArduPilot是领先的开源自动驾驶仪软件，自2010年起由专业团队开发。它功能全面、可靠，能够控制包括无人机、多旋翼、直升机、漫游车、船只乃至潜艇在内的多种飞行器和地面/水下车辆系统，并持续扩展支持新型载具。",
    "keywords": [
      "自动驾驶仪",
      "开源软件",
      "飞行控制",
      "无人机",
      "机器人",
      "嵌入式系统",
      "自主系统"
    ],
    "area": [
      "机器人",
      "智能体",
      "人工智能"
    ],
    "published_time": "2025-06-05 23:43:50+00:00",
    "download_time": "2024-05-15 10:00:00",
    "visual_resource": [
      "screenshot/github/ardupilot.png"
    ],
    "extra_info": null
  },
  {
    "id": "cognee",
    "source": "GitHub",
    "url": "https://github.com/topoteretes/cognee",
    "title": "cognee - Memory for AI Agents in 5 lines of code",
    "summary": "Cognee是一个为AI智能体构建动态记忆的框架，通过可扩展的ECL（提取、认知、加载）管道替代传统RAG系统。它能够互联并检索多模态数据，支持将数据高效加载至图数据库和向量数据库，并可处理30多种数据源，显著降低开发成本和复杂性。",
    "keywords": [
      "AI智能体",
      "记忆系统",
      "RAG替代",
      "知识图谱",
      "向量数据库",
      "自然语言处理",
      "数据处理"
    ],
    "area": [
      "智能体",
      "人工智能",
      "自然语言处理"
    ],
    "published_time": "2025-06-05T16:16:51Z",
    "download_time": "2024-05-20 10:00:00",
    "visual_resource": [
      "https://raw.githubusercontent.com/topoteretes/cognee/refs/heads/main/assets/cognee_benefits.png",
      "https://raw.githubusercontent.com/topoteretes/cognee/main/assets/cognee-ui-2.webp",
      "https://raw.githubusercontent.com/topoteretes/cognee/main/assets/cognee_diagram.png"
    ],
    "extra_info": null
  },
  {
    "id": "mcp-agent",
    "source": "GitHub",
    "url": "https://github.com/lastmile-ai/mcp-agent",
    "title": "mcp-agent",
    "summary": "mcp-agent是一个基于模型上下文协议（MCP）的代理构建框架。它简化了MCP服务器连接管理，并实现了Anthropic和OpenAI的多种高效智能体模式，如并行、路由、评估优化和集群模式。该框架支持可组合的工作流、人机交互及持久化执行，旨在帮助开发者轻松构建可互操作、可控且生产就绪的AI代理应用。",
    "keywords": [
      "智能体",
      "模型上下文协议",
      "AI框架",
      "多智能体",
      "工作流",
      "大模型",
      "Python"
    ],
    "area": [
      "人工智能",
      "大模型",
      "智能体"
    ],
    "published_time": "2025-06-05T16:58:52Z",
    "download_time": "2024-07-08 07:30:00",
    "visual_resource": [
      "screenshot/github/mcp-agent.png"
    ],
    "extra_info": null
  },
  {
    "id": "ruby-sdk",
    "source": "GitHub",
    "url": "https://github.com/modelcontextprotocol/ruby-sdk",
    "title": "MCP Ruby SDK",
    "summary": "MCP Ruby SDK是Model Context Protocol的官方Ruby开发工具包，旨在简化MCP服务器和客户端的构建。它实现了JSON-RPC 2.0消息处理，支持工具、提示和资源的注册与调用，为LLM应用提供核心协议交互能力。该SDK可用于Rails控制器或命令行应用，提供灵活的配置和强大的扩展性，是开发基于MCP协议的智能体和AI应用的理想选择。",
    "keywords": [
      "Ruby开发",
      "Model Context Protocol",
      "JSON-RPC",
      "LLM应用",
      "智能体",
      "协议",
      "服务器",
      "客户端"
    ],
    "area": [
      "人工智能",
      "大模型",
      "智能体"
    ],
    "published_time": "2025-06-05T14:03:31Z",
    "download_time": "2024-05-16 10:30:00",
    "visual_resource": [
      "screenshot/github/ruby-sdk.png"
    ],
    "extra_info": null
  },
  {
    "id": "2506.03143",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2506.03143",
    "title": "GUI-Actor：面向GUI智能体的无坐标视觉定位",
    "summary": "构建VLM驱动的GUI智能体的主要挑战之一是视觉定位，即根据视觉内容和文本计划，定位用于执行操作的适当屏幕区域。大多数现有工作将其表述为基于文本的坐标生成任务。然而，这些方法存在一些局限性：空间语义对齐弱、无法处理模糊的监督目标，以及屏幕坐标的密集性与Vision Transformers等模型提取的视觉特征的粗粒度（补丁级别）之间的不匹配。在本文中，我们提出了GUI-Actor，一种基于VLM的无坐标GUI定位方法。GUI-Actor的核心是引入了一个基于注意力的动作头，它学习将一个专用的<ACTOR> token与所有相关的视觉补丁token对齐，使模型能够在一次前向传播中提出一个或多个动作区域。与此相符，我们进一步设计了一个定位验证器，用于评估并从为动作执行提出的候选区域中选择最合理的动作区域。大量实验表明，GUI-Actor在多个GUI动作定位基准测试中优于先前的最先进方法，并且对未见的屏幕分辨率和布局具有更好的泛化能力。值得注意的是，GUI-Actor-7B在ScreenSpot-Pro上甚至超越了UI-TARS-72B（38.1），在使用Qwen2-VL和Qwen2.5-VL作为骨干网络时分别达到了40.7和44.6的分数。此外，通过引入验证器，我们发现仅微调新引入的动作头（对于7B模型约1亿参数），同时保持VLM骨干网络冻结，足以达到与先前最先进模型相当的性能，这突出表明GUI-Actor可以在不损害其通用能力的情况下，赋予底层VLM有效的定位能力。",
    "keywords": [
      "GUI智能体",
      "视觉定位",
      "VLM",
      "无坐标",
      "注意力机制"
    ],
    "area": [
      "人工智能",
      "多模态",
      "智能体"
    ],
    "published_time": "2025-06-03T17:59:08.000Z",
    "download_time": "2025-06-05 18:11:19",
    "visual_resource": [
      "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2506.03143.png"
    ],
    "extra_info": null
  },
  {
    "id": "2506.00123",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2506.00123",
    "title": "视觉具身大脑：让多模态大语言模型在空间中看、思考和控制",
    "summary": "多模态大语言模型（MLLMs）的显著进展，使其在扩展到腿式机器人等物理实体方面引起了越来越多的关注。这通常要求MLLMs不仅要掌握多模态理解能力，还要整合视觉空间推理和物理交互能力。然而，现有方法由于其根本差异，难以统一这些能力。在本文中，我们提出了视觉具身大脑（VeBrain），一个用于真实世界中感知、推理和控制的统一框架。VeBrain将机器人控制重构为2D视觉空间中常见的基于文本的MLLM任务，从而统一了不同任务的目标和映射空间。随后，提出了一种新颖的机器人适配器，用于将MLLMs的文本控制信号转换为真实机器人的运动策略。从数据角度来看，我们进一步引入了VeBrain-600k，这是一个高质量的指令数据集，涵盖了VeBrain的各种能力。在VeBrain-600k中，我们花费数百小时收集、整理和标注数据，并采用多模态思维链（CoT）将不同能力混合到单个对话中。在13个多模态基准和5个空间智能基准上的大量实验表明，VeBrain的性能优于现有MLLMs，如Qwen2.5-VL。当部署到腿式机器人和机械臂时，VeBrain与现有方法相比，展现出强大的适应性、灵活性和组合能力。例如，与Qwen2.5-VL相比，VeBrain不仅在MMVet上取得了5.6%的显著提升，而且在腿式机器人任务中也取得了平均50%的卓越增益。",
    "keywords": [
      "多模态大语言模型",
      "机器人",
      "具身智能",
      "视觉空间推理",
      "控制"
    ],
    "area": [
      "人工智能",
      "机器人",
      "多模态"
    ],
    "published_time": "2025-05-30T18:00:34.000Z",
    "download_time": "2025-06-05 18:11:20",
    "visual_resource": [
      "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2506.00123.png"
    ],
    "extra_info": null
  },
  {
    "id": "2505.24726",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2505.24726",
    "title": "反思、重试、奖励：通过强化学习实现大型语言模型的自我提升",
    "summary": "我们探索了一种通过自我反思和强化学习来提升大型语言模型性能的方法。通过激励模型在回答错误时生成更好的自我反思，我们证明了即使在无法生成合成数据且仅有二元反馈的情况下，模型解决复杂、可验证任务的能力也能得到增强。我们的框架分两个阶段运行：首先，当模型未能完成给定任务时，它会生成一段自我反思评论，分析其之前的尝试；其次，模型在结合自我反思的语境下再次尝试该任务。如果后续尝试成功，则在自我反思阶段生成的token将获得奖励。我们的实验结果表明，在各种模型架构上都取得了显著的性能提升，其中数学方程书写任务的提升高达34.7%，函数调用任务的提升高达18.1%。值得注意的是，较小的微调模型（15亿至70亿参数）甚至超越了同系列中大10倍的模型。因此，我们这种新颖的范式为开发更有用、更可靠、能在有限外部反馈下自我改进的语言模型提供了一条令人兴奋的途径。",
    "keywords": [
      "大型语言模型",
      "强化学习",
      "自我反思",
      "自我提升",
      "性能优化"
    ],
    "area": [
      "大模型",
      "自然语言处理",
      "机器学习"
    ],
    "published_time": "2025-05-30T15:49:42.000Z",
    "download_time": "2025-06-05 18:11:17",
    "visual_resource": [
      "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.24726.png"
    ],
    "extra_info": null
  },
  {
    "id": "2506.02387",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2506.02387",
    "title": "VS-Bench：评估多智能体环境中VLM的战略推理与决策能力",
    "summary": "视觉语言模型（VLM）的最新进展已将其能力扩展到交互式智能体任务，然而现有基准测试仍局限于单智能体或纯文本环境。相比之下，现实世界场景通常涉及多个智能体在丰富的视觉和语言上下文中进行交互，这在多模态观察和战略交互方面都带来了挑战。为了弥补这一差距，我们引入了视觉战略基准（VS-Bench），这是一个用于评估多智能体环境中VLM战略推理和决策能力的多模态基准。VS-Bench包含八个基于视觉的环境，涵盖合作、竞争和混合动机交互，旨在评估智能体预测他人未来行动并优化长期目标的能力。我们考虑了两个互补的评估维度，包括通过下一行动预测准确性进行的战略推理离线评估，以及通过标准化回合回报进行的决策在线评估。对十四个领先VLM进行的广泛实验表明，当前模型与最佳性能之间存在显著差距，其中最佳模型达到了47.8%的预测准确率和24.3%的标准化回报。我们进一步对VLM智能体的多模态观察、测试时扩展、社会行为和失败案例进行了深入分析。通过标准化评估并突出现有模型的局限性，我们设想VS-Bench将成为未来战略多模态智能体研究的基础。代码和数据可在https://vs-bench.github.io获取。",
    "keywords": [
      "VS-Bench",
      "视觉语言模型",
      "多智能体",
      "战略推理",
      "多模态"
    ],
    "area": [
      "多模态",
      "智能体",
      "人工智能"
    ],
    "published_time": "2025-06-03T02:57:38.000Z",
    "download_time": "2025-06-05 18:11:17",
    "visual_resource": [
      "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2506.02387.png"
    ],
    "extra_info": null
  },
  {
    "id": "2506.02397",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2506.02397",
    "title": "OThink-R1：内在快/慢思维模式切换以缓解过度推理",
    "summary": "近期先进的大型推理模型（LRMs）利用扩展的思维链（CoT）推理来解决复杂任务，取得了最先进的性能。尽管它们取得了成功，但我们发现了一个关键问题：LRMs解决的大部分简单任务也可以由非推理型LLM使用显著更少的token来解决，这表明复杂的推理并非总是必需的。为了解决这个问题，我们系统地分析了LRMs的推理轨迹，并提出了一种利用已识别范式和LLM-Judge的方法，将这些轨迹分类为冗余推理或必要推理。我们引入了OThink-R1，这是一种在保留逻辑有效性的同时剪除冗余推理步骤的方法。OThink-R1动态地对简单问题采用非思考模式（快思维），而对复杂问题则采用深思熟虑的思考模式（慢思维）。在数学和问答任务上的实验表明，OThink-R1平均减少了近23%的推理冗余，同时不损害准确性，为高效推理模型提供了实用指导。代码可在https://github.com/AgenticIR-Lab/OThink-R1获取。",
    "keywords": [
      "大型推理模型",
      "思维链",
      "快慢思维",
      "过度推理",
      "推理效率"
    ],
    "area": [
      "人工智能",
      "大模型",
      "自然语言处理"
    ],
    "published_time": "2025-06-03T03:31:30.000Z",
    "download_time": "2025-06-05 18:11:15",
    "visual_resource": [
      "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2506.02397.png"
    ],
    "extra_info": null
  },
  {
    "id": "2506.01716",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2506.01716",
    "title": "自挑战语言模型智能体",
    "summary": "大型语言模型正迅速成为能够使用工具的智能体的基础。然而，训练此类智能体极具挑战性，因为它需要人工创建和标注多样化的任务、工具和评估标准。本文提出了一种自挑战框架，用于训练智能体处理其自身生成的高质量任务。智能体首先扮演挑战者的角色，在与给定工具交互后生成一个任务。这些任务以一种新颖的通用问题类别——“代码即任务”（Code-as-Task）的形式呈现，其定义包括指令、验证函数以及作为测试的解决方案和失败案例，从而仅筛选出高质量任务。随后，智能体扮演执行者的角色，利用评估反馈作为奖励，通过强化学习在这些任务上进行训练。在两个现有的多轮工具使用智能体基准测试M3ToolEval和TauBench上的评估表明，尽管仅使用自生成训练数据，自挑战框架在Llama-3.1-8B-Instruct上实现了超过两倍的性能提升。",
    "keywords": [
      "语言模型智能体",
      "自挑战框架",
      "Code-as-Task",
      "强化学习",
      "工具使用"
    ],
    "area": [
      "人工智能",
      "大模型",
      "智能体"
    ],
    "published_time": "2025-06-02T14:23:33.000Z",
    "download_time": "2025-06-05 18:11:14",
    "visual_resource": [
      "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2506.01716.png"
    ],
    "extra_info": null
  }
]