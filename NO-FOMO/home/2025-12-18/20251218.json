[
  {
    "id": "hackernews_46315414",
    "source": "Hacker News",
    "url": "https://claude.com/blog/organization-skills-and-directory",
    "title": "Agent Skills is now an open standard",
    "summary": "The announcement that 'Agent Skills is now an open standard' signifies a pivotal advancement in the development and deployment of artificial intelligence agents. This initiative focuses on establishing a common, publicly accessible specification for defining and integrating the diverse capabilities, or 'skills,' that AI agents can possess. By creating an open standard, the objective is to significantly enhance interoperability, foster collaborative development, and drive innovation across the broader AI agent ecosystem. This standardization effort promises to benefit developers and organizations by providing a unified framework for designing, implementing, and sharing agent functionalities, thereby accelerating the creation of more sophisticated and adaptable AI systems. The move is crucial for improving the modularity and reusability of agent components, enabling agents to more effectively acquire, manage, and execute a wide array of tasks. Such a standard could lead to a more organized 'organization skills and directory,' facilitating the discovery and seamless integration of agent capabilities across various platforms and applications, ultimately streamlining development and reducing fragmentation in the AI agent landscape.",
    "keywords": [
      "AI Agent",
      "Open Standard",
      "Agent Skills",
      "Interoperability",
      "AI Development",
      "Standardization"
    ],
    "area": [
      "AI Agent",
      "Artificial Intelligence",
      "Machine Learning"
    ],
    "published_time": "2025-12-18 17:04:32",
    "download_time": "2025-12-18 20:00:38",
    "extra_info": "{\"score\": 157, \"by\": \"adocomplete\", \"descendants\": 100, \"story_id\": 46315414}"
  },
  {
    "id": "hackernews_46316367",
    "source": "Hacker News",
    "url": "https://openai.com/index/introducing-gpt-5-2-codex/",
    "title": "GPT-5.2-Codex",
    "summary": "OpenAI has officially announced the introduction of GPT-5.2-Codex, representing a notable evolution in their suite of large language models. This latest version is specifically developed to significantly enhance capabilities in code generation, building upon the robust foundation established by earlier models. GPT-5.2-Codex is anticipated to deliver superior performance in comprehending intricate programming paradigms, producing highly accurate and optimized code across a diverse range of programming languages, and providing comprehensive assistance to developers for tasks such as debugging, refactoring, and general code optimization. This launch underscores OpenAI's ongoing dedication to advancing artificial intelligence within the realm of software engineering, with the objective of streamlining development workflows, accelerating innovation, and substantially increasing productivity for both professional engineers and AI researchers. The model's advanced ability to interpret natural language prompts and translate them into functional code is expected to revolutionize how software is developed, potentially lowering barriers to entry for new programmers and enabling more complex projects to be undertaken with greater efficiency. Further technical specifications, architectural details, and benchmark performance comparisons are eagerly awaited, solidifying GPT-5.2-Codex's position as a pivotal technology for the future of AI-driven software development.",
    "keywords": [
      "Large Language Model",
      "Code Generation",
      "Artificial Intelligence",
      "Software Development",
      "AI Development",
      "OpenAI",
      "Programming"
    ],
    "area": [
      "Large Language Model",
      "Artificial Intelligence",
      "Generative AI"
    ],
    "published_time": "2025-12-18 18:14:48",
    "download_time": "2025-12-18 20:00:38",
    "extra_info": "{\"score\": 151, \"by\": \"meetpateltech\", \"descendants\": 108, \"story_id\": 46316367}"
  },
  {
    "id": "hackernews_46316533",
    "source": "Hacker News",
    "url": "https://blog.google/technology/developers/functiongemma/",
    "title": "FunctionGemma 270M Model",
    "summary": "Google has unveiled FunctionGemma 270M, a new lightweight and open-source model specifically engineered for robust function calling capabilities. This compact model, featuring 270 million parameters, is designed to enable AI systems to seamlessly interact with external tools, APIs, and services. FunctionGemma 270M addresses the growing need for efficient and cost-effective AI solutions that can extend their functionalities beyond their training data by executing specific functions or accessing real-world information. Its small footprint makes it particularly suitable for deployment in resource-constrained environments, including edge devices and applications where latency and computational overhead are critical considerations. Developers can leverage FunctionGemma 270M to build more sophisticated and versatile AI agents, integrate dynamic tool-use into their applications, and enhance the interactivity of AI-powered systems. This release signifies a strategic move towards democratizing advanced AI capabilities, making powerful function-calling features more accessible to a broader range of developers and use cases.",
    "keywords": [
      "FunctionGemma",
      "Large Language Model",
      "Function Calling",
      "Open Source",
      "AI Agent",
      "Efficiency",
      "Tool Use"
    ],
    "area": [
      "Artificial Intelligence",
      "Large Language Model",
      "AI Agent"
    ],
    "published_time": "2025-12-18 18:26:52",
    "download_time": "2025-12-18 20:00:34",
    "extra_info": "{\"score\": 27, \"by\": \"mariobm\", \"descendants\": 11, \"story_id\": 46316533}"
  },
  {
    "id": "hackernews_46316907",
    "source": "Hacker News",
    "url": "https://www.japantimes.co.jp/business/2025/12/18/tech/china-west-ai-chips/",
    "title": "How China built its ‘Manhattan Project’ to rival the West in AI chips",
    "summary": "The article, \"How China built its ‘Manhattan Project’ to rival the West in AI chips,\" details China's comprehensive and ambitious national strategy to achieve self-sufficiency and global leadership in artificial intelligence hardware. Likening the initiative to the historical \"Manhattan Project,\" the report underscores a highly centralized and well-funded endeavor aimed at accelerating domestic innovation in AI chip design, development, and manufacturing. This strategic push is a direct response to increasing geopolitical tensions and Western export controls, highlighting China's imperative to reduce its reliance on foreign technology and establish a robust, independent supply chain. The project involves substantial state investment, collaboration between academia and industry, and a concerted effort to cultivate top-tier engineering talent within the country. By focusing on advanced semiconductor technologies, China aims to develop cutting-edge AI processors that can power its burgeoning AI industry across various sectors, from data centers to autonomous systems, ultimately challenging the technological dominance of the West and securing its long-term strategic and economic advantages in the global AI race.",
    "keywords": [
      "AI Chips",
      "Semiconductor Technology",
      "National Strategy",
      "Technological Sovereignty",
      "Artificial Intelligence",
      "Hardware Development",
      "Geopolitics",
      "Innovation"
    ],
    "area": [
      "Artificial Intelligence",
      "Machine Learning",
      "Deep Learning"
    ],
    "published_time": "2025-12-18 18:55:34",
    "download_time": "2025-12-18 20:00:37",
    "extra_info": "{\"score\": 15, \"by\": \"artninja1988\", \"descendants\": 4, \"story_id\": 46316907}"
  },
  {
    "id": "hackernews_46313930",
    "source": "Hacker News",
    "url": "https://news.ycombinator.com/item?id=46313930",
    "title": "Launch HN: Pulse (YC S24) – Production-grade unstructured document extraction",
    "summary": "Pulse, a new platform launched by co-founders Sid and Ritvik (YC S24), introduces a production-grade document extraction system designed to generate highly accurate, LLM-ready text from unstructured documents. This innovative system employs a hybrid methodology, integrating advanced Vision Language Models (VLMs) with robust Optical Character Recognition (OCR) technology. The primary objective of Pulse is to address the inherent challenges in current data ingestion processes, particularly where existing foundation models and VLMs, despite their ability to produce plausible text, fall short in delivering the requisite accuracy for critical applications. The co-founders emphasize that plausibility is insufficient for reliable OCR and data extraction, positioning Pulse as a solution focused on precision and reliability. The platform is engineered to handle complex and tricky document cases, ensuring data integrity for subsequent Large Language Model applications and other downstream AI processes, thereby providing a more dependable solution for enterprise-level document processing.",
    "keywords": [
      "Document Extraction",
      "LLM-ready text",
      "Vision Language Models",
      "OCR",
      "Data Ingestion",
      "Unstructured Data",
      "Hybrid Models"
    ],
    "area": [
      "Multimodal",
      "Natural Language Processing",
      "Artificial Intelligence"
    ],
    "published_time": "2025-12-18 15:35:52",
    "download_time": "2025-12-18 20:00:46",
    "extra_info": "{\"score\": 30, \"by\": \"sidmanchkanti21\", \"descendants\": 30, \"story_id\": 46313930}"
  },
  {
    "id": "hackernews_46312159",
    "source": "Hacker News",
    "url": "https://www.coderabbit.ai/blog/state-of-ai-vs-human-code-generation-report",
    "title": "AI helps ship faster but it produces 1.7× more bugs",
    "summary": "A recent report analyzing the state of AI versus human code generation highlights a significant paradox in modern software development. While the integration of artificial intelligence tools demonstrably accelerates the shipping process, leading to faster project delivery, it also correlates with a substantial increase in the incidence of bugs. Specifically, the findings indicate that software projects leveraging AI for code generation produce 1.7 times more defects compared to those developed exclusively by human programmers. This outcome underscores a critical challenge for the industry: how to effectively balance the undeniable productivity gains offered by AI with the necessity of maintaining robust code quality and minimizing post-release issues. The report suggests that while AI streamlines development workflows, further advancements or improved implementation strategies are needed to mitigate the elevated bug count associated with current AI-assisted coding practices.",
    "keywords": [
      "AI Code Generation",
      "Software Development",
      "Code Quality",
      "Developer Productivity",
      "Bugs",
      "AI in Software Engineering",
      "Generative AI"
    ],
    "area": [
      "Artificial Intelligence",
      "Large Language Model",
      "Generative AI"
    ],
    "published_time": "2025-12-18 13:06:51",
    "download_time": "2025-12-18 20:01:09",
    "extra_info": "{\"score\": 183, \"by\": \"birdculture\", \"descendants\": 146, \"story_id\": 46312159}"
  },
  {
    "id": "2512.15431",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2512.15431",
    "title": "Step-GUI Technical Report",
    "summary": "Recent advances in multimodal large language models unlock unprecedented opportunities for GUI automation. However, a fundamental challenge remains: how to efficiently acquire high-quality training data while maintaining annotation reliability? We introduce a self-evolving training pipeline powered by the Calibrated Step Reward System, which converts model-generated trajectories into reliable training signals through trajectory-level calibration, achieving >90% annotation accuracy with 10-100x lower cost. Leveraging this pipeline, we introduce Step-GUI, a family of models (4B/8B) that achieves state-of-the-art GUI performance (8B: 80.2% AndroidWorld, 48.5% OSWorld, 62.6% ScreenShot-Pro) while maintaining robust general capabilities. As GUI agent capabilities improve, practical deployment demands standardized interfaces across heterogeneous devices while protecting user privacy. To this end, we propose GUI-MCP, the first Model Context Protocol for GUI automation with hierarchical architecture that combines low-level atomic operations and high-level task delegation to local specialist models, enabling high-privacy execution where sensitive data stays on-device. Finally, to assess whether agents can handle authentic everyday usage, we introduce AndroidDaily, a benchmark grounded in real-world mobile usage patterns with 3146 static actions and 235 end-to-end tasks across high-frequency daily scenarios (8B: static 89.91%, end-to-end 52.50%). Our work advances the development of practical GUI agents and demonstrates strong potential for real-world deployment in everyday digital interactions.",
    "keywords": [
      "GUI Automation",
      "Multimodal Large Language Models",
      "AI Agents",
      "Training Pipeline",
      "GUI Benchmarking"
    ],
    "area": [
      "AI Agent",
      "Multimodal",
      "Large Language Model"
    ],
    "published_time": "2025-12-17T13:26:30.000Z",
    "download_time": "2025-12-18 12:01:40",
    "extra_info": "{\"url\": \"https://huggingface.co/papers/2512.15431\", \"arxiv_url\": \"https://arxiv.org/abs/2512.15431\", \"thumbnail\": \"https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2512.15431.png\", \"original_title\": \"Step-GUI Technical Report\"}"
  },
  {
    "id": "2512.15687",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2512.15687",
    "title": "Can LLMs Guide Their Own Exploration? Gradient-Guided Reinforcement Learning for LLM Reasoning",
    "summary": "Reinforcement learning has become essential for strengthening the reasoning abilities of large language models, yet current exploration mechanisms remain fundamentally misaligned with how these models actually learn. Entropy bonuses and external semantic comparators encourage surface level variation but offer no guarantee that sampled trajectories differ in the update directions that shape optimization. We propose G2RL, a gradient guided reinforcement learning framework in which exploration is driven not by external heuristics but by the model own first order update geometry. For each response, G2RL constructs a sequence level feature from the model final layer sensitivity, obtainable at negligible cost from a standard forward pass, and measures how each trajectory would reshape the policy by comparing these features within a sampled group. Trajectories that introduce novel gradient directions receive a bounded multiplicative reward scaler, while redundant or off manifold updates are deemphasized, yielding a self referential exploration signal that is naturally aligned with PPO style stability and KL control. Across math and general reasoning benchmarks (MATH500, AMC, AIME24, AIME25, GPQA, MMLUpro) on Qwen3 base 1.7B and 4B models, G2RL consistently improves pass@1, maj@16, and pass@k over entropy based GRPO and external embedding methods. Analyzing the induced geometry, we find that G2RL expands exploration into substantially more orthogonal and often opposing gradient directions while maintaining semantic coherence, revealing that a policy own update space provides a far more faithful and effective basis for guiding exploration in large language model reinforcement learning.",
    "keywords": [
      "Large Language Models",
      "Reinforcement Learning",
      "Gradient-Guided Exploration",
      "LLM Reasoning",
      "G2RL"
    ],
    "area": [
      "Large Language Model",
      "Machine Learning",
      "Deep Learning"
    ],
    "published_time": "2025-12-17T18:44:45.000Z",
    "download_time": "2025-12-18 12:01:39",
    "extra_info": "{\"url\": \"https://huggingface.co/papers/2512.15687\", \"arxiv_url\": \"https://arxiv.org/abs/2512.15687\", \"thumbnail\": \"https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2512.15687.png\", \"original_title\": \"Can LLMs Guide Their Own Exploration? Gradient-Guided Reinforcement Learning for LLM Reasoning\"}"
  },
  {
    "id": "2512.13874",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2512.13874",
    "title": "SAGE: Training Smart Any-Horizon Agents for Long Video Reasoning with Reinforcement Learning",
    "summary": "Humans naturally adapt their approach to video consumption, either skimming long videos or watching short ones fully, based on the task. Current state-of-the-art video reasoning models, however, process numerous frames in a single turn, mimicking full video consumption and demanding extensive resources. This work addresses the challenge of developing performant any-horizon video reasoning systems. We introduce SAGE, an agent system capable of multi-turn reasoning for long videos while efficiently handling simpler problems in a single turn. To train SAGE-MM, the core orchestrator of SAGE, we propose an easy synthetic data generation pipeline utilizing Gemini-2.5-Flash. Additionally, we develop an effective Reinforcement Learning post-training recipe crucial for imbuing SAGE-MM with any-horizon reasoning capabilities. We also curate SAGE-Bench, a benchmark with an average duration exceeding 700 seconds, specifically designed for evaluating video reasoning in real-world entertainment contexts. Empirical validation demonstrates the effectiveness of our system, data, and RL recipe, yielding notable improvements of up to 6.1% on open-ended video reasoning tasks and an impressive 8.2% improvement on videos longer than 10 minutes.",
    "keywords": [
      "Long Video Reasoning",
      "Reinforcement Learning",
      "Any-Horizon Agents",
      "Multi-turn Reasoning",
      "Video Understanding"
    ],
    "area": [
      "AI Agent",
      "Machine Learning",
      "Video Understanding"
    ],
    "published_time": "2025-12-15T20:14:19.000Z",
    "download_time": "2025-12-18 12:01:40",
    "extra_info": "{\"url\": \"https://huggingface.co/papers/2512.13874\", \"arxiv_url\": \"https://arxiv.org/abs/2512.13874\", \"thumbnail\": \"https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2512.13874.png\", \"original_title\": \"SAGE: Training Smart Any-Horizon Agents for Long Video Reasoning with Reinforcement Learning\"}"
  },
  {
    "id": "2512.15176",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2512.15176",
    "title": "DEER: Draft with Diffusion, Verify with Autoregressive Models",
    "summary": "Efficiency, as a critical practical challenge for LLM-driven agentic and reasoning systems, is increasingly constrained by the inherent latency of autoregressive (AR) decoding. Speculative decoding mitigates this cost through a draft-verify scheme, yet existing approaches rely on AR draft models (a.k.a., drafters), which introduce two fundamental issues: (1) step-wise uncertainty accumulation leads to a progressive collapse of trust between the target model and the drafter, and (2) inherently sequential decoding of AR drafters. Together, these factors cause limited speedups. In this paper, we show that a diffusion large language model (dLLM) drafters can naturally overcome these issues through its fundamentally different probabilistic modeling and efficient parallel decoding strategy. Building on this insight, we introduce DEER, an efficient speculative decoding framework that drafts with diffusion and verifies with AR models. To enable high-quality drafting, DEER employs a two-stage training pipeline to align the dLLM-based drafters with the target AR model, and further adopts single-step decoding to generate long draft segments. Experiments show DEER reaches draft acceptance lengths of up to 32 tokens, far surpassing the 10 tokens achieved by EAGLE-3. Moreover, on HumanEval with Qwen3-30B-A3B, DEER attains a 5.54x speedup, while EAGLE-3 achieves only 2.41x. Code, model, demo, etc, will be available at https://czc726.github.io/DEER/",
    "keywords": [
      "Speculative Decoding",
      "Diffusion Models",
      "Autoregressive Models",
      "LLM Efficiency",
      "Parallel Decoding"
    ],
    "area": [
      "Large Language Model",
      "Natural Language Processing",
      "Generative AI"
    ],
    "published_time": "2025-12-17T08:19:04.000Z",
    "download_time": "2025-12-18 12:01:40",
    "extra_info": "{\"url\": \"https://huggingface.co/papers/2512.15176\", \"arxiv_url\": \"https://arxiv.org/abs/2512.15176\", \"thumbnail\": \"https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2512.15176.png\", \"original_title\": \"DEER: Draft with Diffusion, Verify with Autoregressive Models\"}"
  },
  {
    "id": "2512.15713",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2512.15713",
    "title": "DiffusionVL: Translating Any Autoregressive Models into Diffusion Vision Language Models",
    "summary": "In recent multimodal research, the diffusion paradigm has emerged as a promising alternative to the autoregressive paradigm (AR), owing to its unique decoding advantages. However, due to the capability limitations of the base diffusion language model, the performance of the diffusion vision language model (dVLM) still lags significantly behind that of mainstream models. This leads to a simple yet fundamental question: Is it possible to construct dVLMs based on existing powerful AR models? In response, we propose DiffusionVL, a dVLM family that could be translated from any powerful AR models. Through simple fine-tuning, we successfully adapt AR pre-trained models into the diffusion paradigm. This approach yields two key observations: (1) The paradigm shift from AR-based multimodal models to diffusion is remarkably effective. (2) Direct conversion of an AR language model to a dVLM is also feasible, achieving performance competitive with LLaVA-style visual-instruction-tuning. Further, we introduce a block-decoding design into dVLMs that supports arbitrary-length generation and KV cache reuse, achieving a significant inference speedup. We conduct a large number of experiments. Despite training with less than 5% of the data required by prior methods, DiffusionVL achieves a comprehensive performance improvement-a 34.4% gain on the MMMU-Pro (vision) bench and 37.5% gain on the MME (Cog.) bench-alongside a 2x inference speedup. The model and code are released at https://github.com/hustvl/DiffusionVL.",
    "keywords": [
      "Diffusion Models",
      "Vision Language Models",
      "Autoregressive Models",
      "Multimodal Learning",
      "Fine-tuning"
    ],
    "area": [
      "Multimodal",
      "Deep Learning",
      "Generative AI"
    ],
    "published_time": "2025-12-17T18:59:55.000Z",
    "download_time": "2025-12-18 12:01:41",
    "extra_info": "{\"url\": \"https://huggingface.co/papers/2512.15713\", \"arxiv_url\": \"https://arxiv.org/abs/2512.15713\", \"thumbnail\": \"https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2512.15713.png\", \"original_title\": \"DiffusionVL: Translating Any Autoregressive Models into Diffusion Vision Language Models\"}"
  },
  {
    "id": "2512.15702",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2512.15702",
    "title": "End-to-End Training for Autoregressive Video Diffusion via Self-Resampling",
    "summary": "Autoregressive video diffusion models hold promise for world simulation but are vulnerable to exposure bias arising from the train-test mismatch. While recent works address this via post-training, they typically rely on a bidirectional teacher model or online discriminator. To achieve an end-to-end solution, we introduce Resampling Forcing, a teacher-free framework that enables training autoregressive video models from scratch and at scale. Central to our approach is a self-resampling scheme that simulates inference-time model errors on history frames during training. Conditioned on these degraded histories, a sparse causal mask enforces temporal causality while enabling parallel training with frame-level diffusion loss. To facilitate efficient long-horizon generation, we further introduce history routing, a parameter-free mechanism that dynamically retrieves the top-k most relevant history frames for each query. Experiments demonstrate that our approach achieves performance comparable to distillation-based baselines while exhibiting superior temporal consistency on longer videos owing to native-length training.",
    "keywords": [
      "Autoregressive Video Diffusion",
      "Self-Resampling",
      "Exposure Bias",
      "Video Generation",
      "Temporal Consistency"
    ],
    "area": [
      "Generative AI",
      "Computer Vision",
      "Deep Learning"
    ],
    "published_time": "2025-12-17T18:53:29.000Z",
    "download_time": "2025-12-18 12:01:39",
    "extra_info": "{\"url\": \"https://huggingface.co/papers/2512.15702\", \"arxiv_url\": \"https://arxiv.org/abs/2512.15702\", \"thumbnail\": \"https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2512.15702.png\", \"original_title\": \"End-to-End Training for Autoregressive Video Diffusion via Self-Resampling\"}"
  }
]