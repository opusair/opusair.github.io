[
  {
    "id": "twitter_gdb_1934747328457658554",
    "source": "Twitter",
    "url": "https://x.com/gdb/status/1934747328457658554",
    "title_en": "gdb_Joshua Ma Joins OpenAI Codex Team, Focusing on Agentic Software Engineers",
    "summary_en": "Joshua Ma announced he has joined OpenAI's Codex team, focusing on developing \"agentic software engineers,\" a goal he anticipates achieving within 18 months. He expressed his desire not to miss out on this technological wave. The OpenAI Codex team is rapidly expanding in San Francisco and actively recruiting full-stack engineers and product managers. This move signifies OpenAI's significant strategic deployment in automated software development and AI agent fields.",
    "keywords_en": [
      "OpenAI",
      "Codex",
      "Agentic Software Engineers",
      "Joshua Ma",
      "AI Agent",
      "Hiring"
    ],
    "area_en": [
      "Artificial Intelligence",
      "AI Agent",
      "Tech News"
    ],
    "published_time": "2025-06-16T22:58:03.000Z",
    "download_time": "2025-06-17 05:24:57",
    "visual_resource": [
      "screenshot/twitter/gdb_1934747328457658554.png"
    ],
    "extra_info": "{\"username\": \"gdb\", \"tweet_id\": \"1934747328457658554\"}"
  },
  {
    "id": "twitter_MiniMax__AI_1934637031193514237",
    "source": "Twitter",
    "url": "https://twitter.com/MiniMax__AI/status/1934637031193514237",
    "title_en": "MiniMax__AI_Open-sources MiniMax-M1 LLM, Setting New Long-Context Reasoning Standards",
    "summary_en": "MiniMax officially announced the open-sourcing of its latest large language model, MiniMax-M1, which sets new standards in long-context reasoning. MiniMax-M1 features the world's longest context window, supporting 1M-token input and 80k-token output, and demonstrates state-of-the-art agentic use among open-source models. Furthermore, its reinforcement learning training was achieved with remarkable efficiency, costing only $534,700.",
    "keywords_en": [
      "MiniMax",
      "MiniMax-M1",
      "LLM",
      "Open Source",
      "Long Context",
      "AI Agent"
    ],
    "area_en": [
      "Large Language Model",
      "Open Source",
      "AI Agent"
    ],
    "published_time": "2025-06-16T15:39:46.000Z",
    "download_time": "2025-06-17 08:27:47",
    "visual_resource": [
      "screenshot/twitter/MiniMax__AI_1934637031193514237.png"
    ],
    "extra_info": "{\"username\": \"MiniMax__AI\", \"tweet_id\": \"1934637031193514237\"}"
  },
  {
    "id": "twitter_Google_1934691625974002109",
    "source": "Twitter",
    "url": "https://x.com/Google/status/1934691625974002109",
    "title_en": "Google_Veo 3 Global Rollout",
    "summary_en": "Google has announced the global rollout of its AI video generation model, Veo 3. This latest version is now accessible to AI Pro and Ultra subscribers across more than 70 markets, signifying a major step forward for Google in the generative AI video domain and broadening its AI service reach and user base.",
    "keywords_en": [
      "Google",
      "Veo 3",
      "AI video",
      "Product launch",
      "Generative AI",
      "Global rollout"
    ],
    "area_en": [
      "Generative AI",
      "Product Launch",
      "Video Understanding"
    ],
    "published_time": "2025-06-16T19:16:43.000Z",
    "download_time": "2025-06-17 05:18:04",
    "visual_resource": [
      "screenshot/twitter/Google_1934691625974002109.png"
    ],
    "extra_info": "{\"username\": \"Google\", \"tweet_id\": \"1934691625974002109\"}"
  },
  {
    "id": "twitter_scaling01_1934746243286319435",
    "source": "Twitter",
    "url": "https://twitter.com/scaling01/status/1934746243286319435",
    "title_en": "scaling01_Moonshot AI Kimi-Dev Model Excels on SWE-bench",
    "summary_en": "The tweet highlights that Moonshot AI has quietly released its new coding model, Kimi-Dev 72B. This model achieved a verified 60.4% on the SWE-bench benchmark and is released under an MIT License. Kimi-Dev is RL-trained to patch real repositories, with rewards only given if the full test suite passes, demonstrating its robust capabilities in code generation and repair.",
    "keywords_en": [
      "Kimi-Dev",
      "Moonshot AI",
      "Coding Model",
      "SWE-bench",
      "Reinforcement Learning",
      "Open Source"
    ],
    "area_en": [
      "Large Language Model",
      "Open Source",
      "Tech News"
    ],
    "published_time": "2025-06-16T22:53:44.000Z",
    "download_time": "2025-06-18 02:48:13",
    "visual_resource": [
      "screenshot/twitter/scaling01_1934746243286319435.png"
    ],
    "extra_info": "{\"username\": \"scaling01\", \"tweet_id\": \"1934746243286319435\"}"
  },
  {
    "id": "twitter_karpathy_1934651657444528277",
    "source": "Twitter",
    "url": "https://twitter.com/karpathy/status/1934651657444528277",
    "title_en": "karpathy_Caution on LLM Agent Prompt Injection Attacks and Security Risks",
    "summary_en": "Andrej Karpathy reposted a warning about prompt injection attacks faced by LLM agents, likening them to early computer viruses and noting the lack of robust defense mechanisms. He expresses concern over the \"wild west\" security landscape of LLM agents in personal computing. Simon Willison adds that AI agents combining private data access, untrusted content exposure, and external communication pose a \"Lethal Trifecta\" risk, potentially leading to data theft.",
    "keywords_en": [
      "Prompt Injection",
      "LLM Agents",
      "Cybersecurity",
      "Data Security",
      "Artificial Intelligence"
    ],
    "area_en": [
      "Large Language Model",
      "AI Agent",
      "Industry News"
    ],
    "published_time": "2025-06-16T16:37:53.000Z",
    "download_time": "2025-06-17 08:28:01",
    "visual_resource": [
      "screenshot/twitter/karpathy_1934651657444528277.png"
    ],
    "extra_info": "{\"username\": \"karpathy\", \"tweet_id\": \"1934651657444528277\"}"
  },
  {
    "id": "twitter_sedielem_1934730362476712043",
    "source": "Twitter",
    "url": "https://twitter.com/sedielem/status/1934730362476712043",
    "title_en": "sedielem_Diffusion Duality: New Connection Between Continuous and Discrete Diffusion Models",
    "summary_en": "Sander Dieleman highlighted \"The Diffusion Duality\" paper by Subham Sahoo et al., accepted at ICML 2025. This work reveals a profound connection between continuous and discrete diffusion models, enabling the transfer of advanced techniques like consistency distillation to discrete settings. By exploiting underlying Gaussian diffusion, the paper achieves few-step generation in discrete diffusion language models, outperforming autoregressive models on three out of seven zero-shot likelihood benchmarks, demonstrating significant potential in language generation.",
    "keywords_en": [
      "Diffusion Models",
      "Language Models",
      "Generative AI",
      "Consistency Distillation",
      "ICML 2025",
      "Diffusion Duality"
    ],
    "area_en": [
      "Machine Learning",
      "Natural Language Processing",
      "Research Progress"
    ],
    "published_time": "2025-06-16T21:50:38.000Z",
    "download_time": "2025-06-18 02:48:38",
    "visual_resource": [
      "screenshot/twitter/sedielem_1934730362476712043.png"
    ],
    "extra_info": "{\"username\": \"sedielem\", \"tweet_id\": \"1934730362476712043\"}"
  },
  {
    "id": "eRUwonRTO-A07ukWXxPE5g",
    "source": "wechat",
    "url": "https://mp.weixin.qq.com/s/eRUwonRTO-A07ukWXxPE5g",
    "title_en": "Google's Future AI Roadmap Revealed: Abandoning Attention Mechanism? Transformer Has Fatal Flaws!",
    "summary_en": "Google Product Lead Logan Kilpatrick recently unveiled the company's future AI roadmap, primarily focusing on the evolution of the Gemini model. This ambitious plan emphasizes Gemini's progression towards full multimodal capabilities, encompassing image, audio, and video generation, while gradually transforming into a sophisticated AI agent with robust tool-calling and systematic reasoning abilities. A significant highlight is Google's active exploration of \"infinite context\" solutions, which suggests a potential departure from the current attention mechanism within the Transformer architecture to overcome its inherent limitations. Furthermore, Google intends to introduce more compact models and is committed to re-positioning AI Studio as a comprehensive developer platform. This strategic direction underscores Google's resurgence as a leading force in the competitive AI landscape, signaling a paradigm shift from reactive AI systems to proactive, intelligent services. The company's integrated approach, combining foundational research with practical product development, aims to deliver groundbreaking advancements and meet the exploding demand from the developer ecosystem.",
    "keywords_en": [
      "Google AI",
      "Gemini",
      "Attention Mechanism",
      "Infinite Context",
      "AI Agent",
      "Multimodal"
    ],
    "area_en": [
      "Large Language Model",
      "Multimodal",
      "AI Agent"
    ],
    "published_time": "2025-06-16T16:02:11.000Z",
    "download_time": "2025-06-17T13:31:03.007372",
    "visual_resource": [
      "screenshot/wechat/wechat_image_eRUwonRTO-A07ukWXxPE5g.png"
    ],
    "extra_info": null
  },
  {
    "id": "DnuXC8WwCBwulmQRsu1WGw",
    "source": "wechat",
    "url": "https://mp.weixin.qq.com/s/DnuXC8WwCBwulmQRsu1WGw",
    "title_en": "AI-Powered Live Streaming E-commerce Tool: High-Fidelity Product Demonstration Videos from Single Person and Product Images",
    "summary_en": "ByteDance has introduced DreamActor-H1, an innovative AI framework based on the Diffusion Transformer, capable of generating high-fidelity, realistic human-product demonstration videos from just a single person image and a single product image. This novel technology leverages injected human-product reference information and masked cross-attention mechanisms to effectively preserve human identity and intricate product details, while also producing physically plausible demonstration movements. Trained on extensive, multi-level augmented datasets, DreamActor-H1 surpasses existing state-of-the-art methods in maintaining human-product identity integrity and generating realistic actions. Its core advantage lies in its ability to create personalized e-commerce advertisements and interactive media, offering significant potential to revolutionize live streaming e-commerce, enhance user engagement, and boost marketing efficiency by automating video content creation.",
    "keywords_en": [
      "DreamActor-H1",
      "Live Streaming E-commerce",
      "Video Generation",
      "Diffusion Transformer",
      "E-commerce",
      "AI Application"
    ],
    "area_en": [
      "Generative AI",
      "Computer Vision",
      "Large Language Model"
    ],
    "published_time": "2025-06-16T23:45:48.000Z",
    "download_time": "2025-06-17T13:31:02.874566",
    "visual_resource": [
      "screenshot/wechat/wechat_image_DnuXC8WwCBwulmQRsu1WGw.png"
    ],
    "extra_info": null
  },
  {
    "id": "mqdknnDnEFjCH-vlxfm-Gw",
    "source": "wechat",
    "url": "https://mp.weixin.qq.com/s/mqdknnDnEFjCH-vlxfm-Gw",
    "title_en": "Midjourney Enters Video Generation Market, Image Model V7 Continues to Update",
    "summary_en": "Leading image generation platform Midjourney has officially made its foray into the video generation domain, with initial demonstrations of its video model revealing impressive capabilities in motion fluidity, physical realism, and intricate detail rendering. The model particularly excels in handling complex multi-character actions and producing highly realistic textures. Despite these advancements, a notable limitation is the current absence of audio functionality, which places it at a disadvantage when compared to rivals such as Veo 3. Simultaneously, Midjourney's acclaimed image model, V7, is receiving continuous enhancements. Recent updates include the introduction of \"Draft Mode,\" enabling intuitive voice and dialogue-based control, alongside significant acceleration features. These improvements have substantially boosted both generation speed and overall image quality, with a particular emphasis on the hyper-realistic rendering of hand textures. Midjourney is proactively engaging with its user base, soliciting feedback to further refine and optimize its cutting-edge video and image generation technologies, thereby solidifying its position as a key innovator in the rapidly evolving generative AI landscape.",
    "keywords_en": [
      "Midjourney",
      "Video Generation",
      "Image Generation",
      "V7",
      "Generative AI"
    ],
    "area_en": [
      "Generative AI",
      "Computer Vision",
      "Artificial Intelligence"
    ],
    "published_time": "2025-06-16T16:02:11.000Z",
    "download_time": "2025-06-17T13:31:07.525759",
    "visual_resource": [
      "screenshot/wechat/wechat_image_mqdknnDnEFjCH-vlxfm-Gw.png"
    ],
    "extra_info": null
  },
  {
    "id": "kk92qix7JnNnbnTtFg9Y9A",
    "source": "wechat",
    "url": "https://mp.weixin.qq.com/s/kk92qix7JnNnbnTtFg9Y9A",
    "title_en": "Scaling Law Validated for the First Time in Autonomous Driving! XPeng's CVPR Speech Details: AI's Intelligent Emergence After Processing 600 Million Seconds of Video",
    "summary_en": "At CVPR 2025, XPeng Motors announced a significant breakthrough, validating the Scaling Law for the first time in autonomous driving VLA (Vision-Language-Action) models. The article elaborates on XPeng's proprietary \"world base model\" solution, which leverages a large language model as its backbone, boasting 72 billion parameters. This model is trained with massive amounts of driving data and advanced reinforcement learning techniques, deployed in the cloud. To overcome edge computing limitations, XPeng employs knowledge distillation to transfer the powerful capabilities of the cloud-based large model to smaller, vehicle-side models. This approach enables seamless driving experiences without reliance on rule-based code, demonstrating a superior global understanding and decision-making ability that transcends traditional L2/L4 systems. This innovation not only addresses the long-standing critique of end-to-end systems merely imitating human behavior but also heralds a new era of convergence between autonomous driving and embodied AI. XPeng is actively redefining the automotive industry from the perspective of an \"AI company.\"",
    "keywords_en": [
      "Scaling Law",
      "Autonomous Driving",
      "XPeng Motors",
      "Base Model",
      "Knowledge Distillation",
      "Intelligent Emergence"
    ],
    "area_en": [
      "Large Language Model",
      "AI Agent",
      "Robotics"
    ],
    "published_time": "2025-06-16T04:50:28.000Z",
    "download_time": "2025-06-17T13:31:30.429894",
    "visual_resource": [
      "screenshot/wechat/wechat_image_kk92qix7JnNnbnTtFg9Y9A.png"
    ],
    "extra_info": null
  },
  {
    "id": "5onSvM_uHxrRxcO9FCGlIg",
    "source": "wechat",
    "url": "https://mp.weixin.qq.com/s/5onSvM_uHxrRxcO9FCGlIg",
    "title_en": "New Breakthrough in Web Agents! Tencent AI Lab Proposes New Framework Introducing Co-evolving World Models",
    "summary_en": "Tencent AI Lab has introduced the WebEvolver framework, which leverages co-evolving world models to overcome the performance stagnation of existing Large Language Model (LLM)-based web agents, achieving a 10% performance improvement in real web environments. This framework defines the world model as a \"virtual web engine,\" capable of generating diverse synthetic training trajectories and performing multi-step lookahead reasoning. This significantly enhances the agent's ability to interact with unseen websites and improves training effectiveness. The research highlights the world model's capabilities in knowledge transfer and diverse trajectory generation, asserting that even minor \"hallucinations\" do not diminish its core value as a \"virtual server\" and \"imagination engine.\" WebEvolver provides a new paradigm for building continuously evolving general web agents, offering guidance for future environment-free reinforcement learning.",
    "keywords_en": [
      "Web Agent",
      "World Model",
      "Co-evolution",
      "Large Language Model",
      "WebEvolver",
      "Self-evolving"
    ],
    "area_en": [
      "AI Agent",
      "Large Language Model",
      "Artificial Intelligence"
    ],
    "published_time": "2025-06-16T04:50:28.000Z",
    "download_time": "2025-06-17T13:31:01.984905",
    "visual_resource": [
      "screenshot/wechat/wechat_image_5onSvM_uHxrRxcO9FCGlIg.png"
    ],
    "extra_info": null
  },
  {
    "id": "Dwe1Nmw9lydl_8O8wAYI3g",
    "source": "wechat",
    "url": "https://mp.weixin.qq.com/s/Dwe1Nmw9lydl_8O8wAYI3g",
    "title_en": "He Successfully Joined OpenAI with Just One Blog Post! Core Technology May Be Used for GPT-5 Training",
    "summary_en": "Keller Jordan successfully joined OpenAI by sharing his Muon optimizer research via a blog and GitHub, challenging traditional AI research paradigms. Muon, an innovative optimizer for neural network hidden layers, significantly boosts the training efficiency of models like NanoGPT and large Transformers, potentially influencing GPT-5 development. This case highlights that in the rapidly evolving AI landscape, open collaboration, rapid iteration, and demonstrable real-world impact are becoming key metrics for research value, superseding traditional paper publication. Top institutions like OpenAI increasingly prioritize practical potential and skills over academic credentials or publication volume. This signals a shift in AI talent acquisition and research models towards a greater emphasis on practical contributions and community engagement. Jordan's experience, including Muon's ability to reduce 1.5B Transformer training time by 25% compared to AdamW, exemplifies this new approach where real-world adoption and reproducibility are paramount.",
    "keywords_en": [
      "Muon optimizer",
      "OpenAI",
      "AI research paradigm",
      "blog",
      "model training",
      "deep learning"
    ],
    "area_en": [
      "Machine Learning",
      "Deep Learning",
      "Large Language Model"
    ],
    "published_time": "2025-06-16T04:49:52.000Z",
    "download_time": "2025-06-17T13:31:17.813368",
    "visual_resource": [
      "screenshot/wechat/wechat_image_Dwe1Nmw9lydl_8O8wAYI3g.png"
    ],
    "extra_info": null
  },
  {
    "id": "anthropic-cookbook",
    "source": "GitHub",
    "url": "https://github.com/anthropics/anthropic-cookbook",
    "title_en": "Anthropic Cookbook",
    "summary_en": "The Anthropic Cookbook is a collection of code and guides designed for developers building applications with Claude. It offers readily integratable code snippets covering areas such as text classification, Retrieval Augmented Generation (RAG), summarization, tool use, multimodal capabilities, and advanced techniques. The project aims to assist developers in leveraging the Claude API, providing Python examples and concepts adaptable to other programming languages, thereby enhancing the efficiency of AI application development.",
    "keywords_en": [
      "Claude",
      "LLM Applications",
      "Code Examples",
      "API Development",
      "Natural Language Processing",
      "Multimodal",
      "AI Agent",
      "Retrieval Augmented Generation"
    ],
    "area_en": [
      "Artificial Intelligence",
      "Large Language Model",
      "Natural Language Processing"
    ],
    "published_time": "2025-06-13T19:28:20Z",
    "download_time": "2024-05-16 10:00:00",
    "visual_resource": [
      "screenshot/github/anthropic-cookbook.png"
    ],
    "extra_info": null
  },
  {
    "id": "prompt-eng-interactive-tutorial",
    "source": "GitHub",
    "url": "https://github.com/anthropics/prompt-eng-interactive-tutorial",
    "title_en": "Welcome to Anthropic's Prompt Engineering Interactive Tutorial",
    "summary_en": "Anthropic's interactive prompt engineering tutorial systematically guides users on how to construct optimal and effective prompts for the Claude AI model. This comprehensive course is structured into nine detailed chapters, each accompanied by practical exercises, designed to provide a step-by-step understanding. Key topics include mastering basic prompt structures, identifying and resolving common failure modes using '80/20' techniques, understanding Claude's specific strengths and weaknesses, and building robust prompts from scratch for diverse real-world applications. The tutorial strongly emphasizes hands-on practice, featuring an \"Example Playground\" area where users can freely experiment with examples and observe the impact of prompt changes on Claude's responses. Furthermore, it introduces the different Claude 3 modelsâ€”Haiku, Sonnet, and Opusâ€”highlighting their varying intelligence levels. This practical guide is an invaluable resource for anyone looking to significantly enhance their proficiency in leveraging large language models for advanced AI applications.",
    "keywords_en": [
      "Prompt Engineering",
      "Large Language Model",
      "Claude AI",
      "AI Model Optimization",
      "Interactive Tutorial",
      "Natural Language Processing"
    ],
    "area_en": [
      "Large Language Model",
      "Natural Language Processing",
      "Generative AI"
    ],
    "published_time": "2024-04-08T03:17:07Z",
    "download_time": "2024-05-15 10:00:00",
    "visual_resource": [
      "screenshot/github/prompt-eng-interactive-tutorial.png"
    ],
    "extra_info": null
  },
  {
    "id": "awesome-llm-apps",
    "source": "GitHub",
    "url": "https://github.com/Shubhamsaboo/awesome-llm-apps",
    "title_en": "ðŸŒŸ Awesome LLM Apps",
    "summary_en": "The GitHub repository \"Awesome LLM Apps\" is a curated collection of Large Language Model (LLM) applications, incorporating various technologies such as Retrieval Augmented Generation (RAG), AI Agents, Multi-agent Teams, MCP (Multimodal Control Policy), and Voice Agents. It showcases practical applications built using models from OpenAI, Anthropic, Google, as well as open-source models like DeepSeek, Qwen, and Llama. This project aims to help developers explore the application potential of LLMs across different domains and foster the growth of the open-source LLM application ecosystem.",
    "keywords_en": [
      "Large Language Model",
      "AI Agent",
      "Retrieval Augmented Generation",
      "Multi-agent System",
      "Voice AI",
      "LLM Applications",
      "Open Source Models",
      "Model Fine-tuning"
    ],
    "area_en": [
      "Artificial Intelligence",
      "Large Language Model",
      "AI Agent"
    ],
    "published_time": "2025-06-15T16:08:42Z",
    "download_time": "2024-07-29 10:00:00",
    "visual_resource": [
      "https://github.com/Shubhamsaboo/awesome-llm-apps/raw/main/docs/banner/unwind_black.png",
      "https://api.star-history.com/svg?repos=Shubhamsaboo/awesome-llm-apps&type=Date"
    ],
    "extra_info": null
  },
  {
    "id": "lerobot",
    "source": "GitHub",
    "url": "https://github.com/huggingface/lerobot",
    "title_en": "LeRobot: State-of-the-art AI for real-world robotics",
    "summary_en": "LeRobot is a cutting-edge PyTorch robotics library developed by Hugging Face, aiming to significantly lower the barrier to entry for real-world robotics development. Its core mission is to facilitate the widespread sharing of high-quality datasets and advanced pretrained models within the robotics community. The library primarily focuses on state-of-the-art AI methodologies, including imitation learning and reinforcement learning, which have demonstrated strong transferability to physical robotic systems. LeRobot currently offers a comprehensive suite of resources, such as pre-trained models, extensive datasets derived from human demonstrations, and robust simulation environments, allowing users to commence development even without immediate access to physical hardware. Furthermore, it actively supports the construction of cost-effective robotic platforms like the SO-101 and LeKiwi, with ambitious plans to integrate support for an even broader range of affordable and capable real-world robots in the near future, thereby accelerating the deployment of AI in practical robotic applications.",
    "keywords_en": [
      "Robotics",
      "PyTorch",
      "Imitation Learning",
      "Reinforcement Learning",
      "Pretrained Models",
      "Datasets",
      "Simulation Environments",
      "Artificial Intelligence"
    ],
    "area_en": [
      "Robotics",
      "Machine Learning",
      "Deep Learning"
    ],
    "published_time": "2025-06-15T09:47:48Z",
    "download_time": "2024-05-07 07:00:00",
    "visual_resource": [
      "https://raw.githubusercontent.com/huggingface/lerobot/main/media/gym/aloha_act.gif",
      "https://raw.githubusercontent.com/huggingface/lerobot/main/media/gym/pusht_diffusion.gif"
    ],
    "extra_info": null
  },
  {
    "id": "prompt-optimizer",
    "source": "GitHub",
    "url": "https://github.com/linshenkx/prompt-optimizer",
    "title_en": "Prompt Optimizer",
    "summary_en": "Prompt Optimizer is a powerful AI prompt optimization tool designed to enhance AI output quality. It offers both a web application and a Chrome extension. Key features include intelligent one-click optimization, real-time comparison testing between original and optimized prompts, and integration with mainstream AI models like OpenAI, Gemini, and DeepSeek. The tool ensures data security and user privacy through pure client-side processing and local encrypted storage. Users can flexibly configure advanced LLM parameters and easily deploy it via Vercel or Docker, effectively addressing cross-domain issues. It is an ideal choice for optimizing AI interaction experiences.",
    "keywords_en": [
      "Prompt Optimization",
      "AI Tools",
      "Large Language Models",
      "Chrome Extension",
      "Client-side Application",
      "API Configuration",
      "Cross-domain Solution"
    ],
    "area_en": [
      "Artificial Intelligence",
      "Large Language Model",
      "Generative AI"
    ],
    "published_time": "2025-06-15T14:12:42Z",
    "download_time": "2024-07-30 10:00:00",
    "visual_resource": [
      "screenshot/github/prompt-optimizer.png"
    ],
    "extra_info": null
  },
  {
    "id": "learn-agentic-ai",
    "source": "GitHub",
    "url": "https://github.com/panaversity/learn-agentic-ai",
    "title_en": "Learn Agentic AI using Dapr Agentic Cloud Ascent (DACA) Design Pattern: From Start to Scale",
    "summary_en": "This GitHub repository introduces the Dapr Agentic Cloud Ascent (DACA) design pattern, aiming to address the challenge of building and scaling AI agent systems to handle ten million concurrent agents. It delves into the application of Dapr, Kubernetes, and the OpenAI Agents SDK in achieving large-scale, high-concurrency agent systems, emphasizing DACA's advantages in cloud-native, cost-effective, and resilient deployments. The project offers a comprehensive curriculum, including AI-201, AI-202, and AI-301 courses, covering topics from foundational theories to planet-scale distributed AI agent development. This framework, combining OpenAI Agents SDK, Model Context Protocol (MCP), and Agent2Agent (A2A) protocol, provides developers with a robust approach for constructing complex, scalable multi-agent systems, specifically tailored for training Agentic AI engineers and fostering related startups.",
    "keywords_en": [
      "Agentic AI",
      "Dapr",
      "Kubernetes",
      "OpenAI Agents SDK",
      "Distributed Systems",
      "Scalability",
      "Cloud-Native",
      "Multi-Agent"
    ],
    "area_en": [
      "Artificial Intelligence",
      "AI Agent",
      "Large Language Model"
    ],
    "published_time": "2025-06-16T22:08:33Z",
    "download_time": "2024-05-15 10:30:00",
    "visual_resource": [
      "https://github.com/panaversity/learn-agentic-ai/raw/main/img/cover.png",
      "https://github.com/panaversity/learn-agentic-ai/raw/main/img/ascent.png",
      "https://github.com/panaversity/learn-agentic-ai/raw/main/img/architecture1.png"
    ],
    "extra_info": null
  },
  {
    "id": "2506.11930",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2506.11930",
    "title_en": "Feedback Friction: LLMs Struggle to Fully Incorporate External Feedback",
    "summary_en": "Recent studies have shown LLMs possess some ability to improve their\nresponses when given external feedback. However, it remains unclear how\neffectively and thoroughly these models can incorporate extrinsic feedback. In\nan ideal scenario, if LLMs receive near-perfect and complete feedback, we would\nexpect them to fully integrate the feedback and change their incorrect answers\nto correct ones. In this paper, we systematically investigate LLMs' ability to\nincorporate feedback by designing a controlled experimental environment. For\neach problem, a solver model attempts a solution, then a feedback generator\nwith access to near-complete ground-truth answers produces targeted feedback,\nafter which the solver tries again. We evaluate this pipeline across a diverse\nrange of tasks, including math reasoning, knowledge reasoning, scientific\nreasoning, and general multi-domain evaluations with state-of-the-art language\nmodels including Claude 3.7 (with and without extended thinking). Surprisingly,\neven under these near-ideal conditions, solver models consistently show\nresistance to feedback, a limitation that we term FEEDBACK FRICTION. To\nmitigate this limitation, we experiment with sampling-based strategies like\nprogressive temperature increases and explicit rejection of previously\nattempted incorrect answers, which yield improvements but still fail to help\nmodels achieve target performance. We also perform a rigorous exploration of\npotential causes of FEEDBACK FRICTION, ruling out factors such as model\noverconfidence and data familiarity. We hope that highlighting this issue in\nLLMs and ruling out several apparent causes will help future research in\nself-improvement.",
    "keywords_en": [
      "Large Language Models",
      "Feedback Friction",
      "External Feedback",
      "Feedback Incorporation",
      "Self-improvement"
    ],
    "area_en": [
      "Large Language Model",
      "Natural Language Processing",
      "Artificial Intelligence"
    ],
    "published_time": "2025-06-13T16:31:51.000Z",
    "download_time": "2025-06-16 22:31:46",
    "visual_resource": [
      "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2506.11930.png"
    ],
    "extra_info": "{\"url\": \"https://huggingface.co/papers/2506.11930\", \"arxiv_url\": \"https://arxiv.org/abs/2506.11930\"}"
  },
  {
    "id": "2506.11924",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2506.11924",
    "title_en": "Aligned Novel View Image and Geometry Synthesis via Cross-modal\n  Attention Instillation",
    "summary_en": "We introduce a diffusion-based framework that performs aligned novel view\nimage and geometry generation via a warping-and-inpainting methodology. Unlike\nprior methods that require dense posed images or pose-embedded generative\nmodels limited to in-domain views, our method leverages off-the-shelf geometry\npredictors to predict partial geometries viewed from reference images, and\nformulates novel-view synthesis as an inpainting task for both image and\ngeometry. To ensure accurate alignment between generated images and geometry,\nwe propose cross-modal attention distillation, where attention maps from the\nimage diffusion branch are injected into a parallel geometry diffusion branch\nduring both training and inference. This multi-task approach achieves\nsynergistic effects, facilitating geometrically robust image synthesis as well\nas well-defined geometry prediction. We further introduce proximity-based mesh\nconditioning to integrate depth and normal cues, interpolating between point\ncloud and filtering erroneously predicted geometry from influencing the\ngeneration process. Empirically, our method achieves high-fidelity\nextrapolative view synthesis on both image and geometry across a range of\nunseen scenes, delivers competitive reconstruction quality under interpolation\nsettings, and produces geometrically aligned colored point clouds for\ncomprehensive 3D completion. Project page is available at\nhttps://cvlab-kaist.github.io/MoAI.",
    "keywords_en": [
      "Novel View Synthesis",
      "Geometry Generation",
      "Diffusion Model",
      "Cross-modal Attention",
      "3D Completion"
    ],
    "area_en": [
      "Computer Vision",
      "Deep Learning",
      "Generative AI"
    ],
    "published_time": "2025-06-13T16:19:00.000Z",
    "download_time": "2025-06-16 22:31:42",
    "visual_resource": [
      "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2506.11924.png"
    ],
    "extra_info": "{\"url\": \"https://huggingface.co/papers/2506.11924\", \"arxiv_url\": \"https://arxiv.org/abs/2506.11924\"}"
  },
  {
    "id": "2506.11886",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2506.11886",
    "title_en": "Beyond Homogeneous Attention: Memory-Efficient LLMs via\n  Fourier-Approximated KV Cache",
    "summary_en": "Large Language Models struggle with memory demands from the growing Key-Value\n(KV) cache as context lengths increase. Existing compression methods homogenize\nhead dimensions or rely on attention-guided token pruning, often sacrificing\naccuracy or introducing computational overhead. We propose FourierAttention, a\ntraining-free framework that exploits the heterogeneous roles of transformer\nhead dimensions: lower dimensions prioritize local context, while upper ones\ncapture long-range dependencies. By projecting the long-context-insensitive\ndimensions onto orthogonal Fourier bases, FourierAttention approximates their\ntemporal evolution with fixed-length spectral coefficients. Evaluations on\nLLaMA models show that FourierAttention achieves the best long-context accuracy\non LongBench and Needle-In-A-Haystack (NIAH). Besides, a custom Triton kernel,\nFlashFourierAttention, is designed to optimize memory via streamlined\nread-write operations, enabling efficient deployment without performance\ncompromise.",
    "keywords_en": [
      "Large Language Models",
      "KV Cache",
      "Fourier Approximation",
      "Memory Efficiency",
      "Long Context"
    ],
    "area_en": [
      "Large Language Model",
      "Natural Language Processing",
      "Deep Learning"
    ],
    "published_time": "2025-06-13T15:35:54.000Z",
    "download_time": "2025-06-16 22:31:41",
    "visual_resource": [
      "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2506.11886.png"
    ],
    "extra_info": "{\"url\": \"https://huggingface.co/papers/2506.11886\", \"arxiv_url\": \"https://arxiv.org/abs/2506.11886\"}"
  },
  {
    "id": "2506.11702",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2506.11702",
    "title_en": "Configurable Preference Tuning with Rubric-Guided Synthetic Data",
    "summary_en": "Models of human feedback for AI alignment, such as those underpinning Direct\nPreference Optimization (DPO), often bake in a singular, static set of\npreferences, limiting adaptability. This paper challenges the assumption of\nmonolithic preferences by introducing Configurable Preference Tuning (CPT), a\nnovel framework for endowing language models with the ability to dynamically\nadjust their behavior based on explicit, human-interpretable directives. CPT\nleverages synthetically generated preference data, conditioned on system\nprompts derived from structured, fine-grained rubrics that define desired\nattributes like writing style. By fine-tuning with these rubric-guided\npreferences, the LLM learns to modulate its outputs at inference time in\nresponse to the system prompt, without retraining. This approach not only\noffers fine-grained control but also provides a mechanism for modeling more\nnuanced and context-dependent human feedback. Several experimental artifacts,\nsuch as training code, generated datasets and fine-tuned models are released at\nhttps://github.com/vicgalle/configurable-preference-tuning",
    "keywords_en": [
      "Configurable Preference Tuning",
      "Synthetic Data",
      "Rubric-Guided",
      "Language Models",
      "AI Alignment"
    ],
    "area_en": [
      "Natural Language Processing",
      "Large Language Model",
      "Generative AI"
    ],
    "published_time": "2025-06-13T12:17:38.000Z",
    "download_time": "2025-06-16 22:31:42",
    "visual_resource": [
      "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2506.11702.png"
    ],
    "extra_info": "{\"url\": \"https://huggingface.co/papers/2506.11702\", \"arxiv_url\": \"https://arxiv.org/abs/2506.11702\"}"
  },
  {
    "id": "2506.09600",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2506.09600",
    "title_en": "Effective Red-Teaming of Policy-Adherent Agents",
    "summary_en": "Task-oriented LLM-based agents are increasingly used in domains with strict\npolicies, such as refund eligibility or cancellation rules. The challenge lies\nin ensuring that the agent consistently adheres to these rules and policies,\nappropriately refusing any request that would violate them, while still\nmaintaining a helpful and natural interaction. This calls for the development\nof tailored design and evaluation methodologies to ensure agent resilience\nagainst malicious user behavior. We propose a novel threat model that focuses\non adversarial users aiming to exploit policy-adherent agents for personal\nbenefit. To address this, we present CRAFT, a multi-agent red-teaming system\nthat leverages policy-aware persuasive strategies to undermine a\npolicy-adherent agent in a customer-service scenario, outperforming\nconventional jailbreak methods such as DAN prompts, emotional manipulation, and\ncoercive. Building upon the existing tau-bench benchmark, we introduce\ntau-break, a complementary benchmark designed to rigorously assess the agent's\nrobustness against manipulative user behavior. Finally, we evaluate several\nstraightforward yet effective defense strategies. While these measures provide\nsome protection, they fall short, highlighting the need for stronger,\nresearch-driven safeguards to protect policy-adherent agents from adversarial\nattacks",
    "keywords_en": [
      "AI Agents",
      "Red-Teaming",
      "Policy Adherence",
      "Robustness",
      "Adversarial Attacks"
    ],
    "area_en": [
      "Artificial Intelligence",
      "Large Language Model",
      "AI Agent"
    ],
    "published_time": "2025-06-11T10:59:47.000Z",
    "download_time": "2025-06-16 22:31:40",
    "visual_resource": [
      "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2506.09600.png"
    ],
    "extra_info": "{\"url\": \"https://huggingface.co/papers/2506.09600\", \"arxiv_url\": \"https://arxiv.org/abs/2506.09600\"}"
  },
  {
    "id": "2506.07464",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2506.07464",
    "title_en": "DeepVideo-R1: Video Reinforcement Fine-Tuning via Difficulty-aware\n  Regressive GRPO",
    "summary_en": "Recent works have demonstrated the effectiveness of reinforcement learning\n(RL)-based post-training in enhancing the reasoning capabilities of large\nlanguage models (LLMs). In particular, Group Relative Policy Optimization\n(GRPO) has shown impressive success by employing a PPO-style reinforcement\nalgorithm with group-based normalized rewards. However, the application of GRPO\nto Video Large Language Models (Video LLMs) has been less studied. In this\npaper, we explore GRPO for video LLMs and identify two primary issues that\nimpede its effective learning: (1) reliance on safeguards, and (2) the\nvanishing advantage problem. To mitigate these challenges, we propose\nDeepVideo-R1, a video large language model trained with our proposed Reg-GRPO\n(Regressive GRPO) and difficulty-aware data augmentation strategy. Reg-GRPO\nreformulates the GRPO objective as a regression task, directly predicting the\nadvantage in GRPO. This design eliminates the need for safeguards like clipping\nand min functions, thereby facilitating more direct policy guidance by aligning\nthe model with the advantage values. We also design the difficulty-aware data\naugmentation strategy that dynamically augments training samples at solvable\ndifficulty levels, fostering diverse and informative reward signals. Our\ncomprehensive experiments show that DeepVideo-R1 significantly improves video\nreasoning performance across multiple video reasoning benchmarks.",
    "keywords_en": [
      "Video LLMs",
      "Reinforcement Learning",
      "GRPO",
      "Regressive GRPO",
      "Difficulty-aware"
    ],
    "area_en": [
      "Video Understanding",
      "Large Language Model",
      "Machine Learning"
    ],
    "published_time": "2025-06-09T06:15:54.000Z",
    "download_time": "2025-06-16 22:31:42",
    "visual_resource": [
      "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2506.07464.png"
    ],
    "extra_info": "{\"url\": \"https://huggingface.co/papers/2506.07464\", \"arxiv_url\": \"https://arxiv.org/abs/2506.07464\"}"
  }
]