[
  {
    "id": "hackernews_47032876",
    "source": "Hacker News",
    "url": "https://qwen.ai/blog?id=qwen3.5",
    "title": "Qwen3.5: Towards Native Multimodal Agents",
    "summary": "Qwen3.5 marks a notable advancement in artificial intelligence, primarily focusing on the development of native multimodal agents. This iteration of the Qwen model series is engineered to deeply integrate and process diverse data types, including textual, visual, and potentially auditory information, within a unified and coherent framework. The core innovation of Qwen3.5 lies in its enhanced capability to function as an intelligent agent, adept at understanding intricate user requests, performing complex reasoning across multiple modalities, and executing multi-step tasks autonomously. By emphasizing \"native\" multimodal capabilities, Qwen3.5 aims to move beyond modular approaches, fostering more integrated and robust AI behaviors. This development is pivotal for creating more sophisticated and versatile AI systems that can interact with the world in a human-like manner, significantly expanding the scope of AI applications beyond traditional large language models to encompass a broader spectrum of real-world interactive and problem-solving scenarios.",
    "keywords": [
      "Qwen3.5",
      "Multimodal AI",
      "AI Agent",
      "Large Language Model",
      "Multimodal Learning",
      "Generative AI"
    ],
    "area": [
      "Multimodal",
      "AI Agent",
      "Large Language Model"
    ],
    "published_time": "2026-02-16 09:32:21",
    "download_time": "2026-02-16 20:00:35",
    "extra_info": "{\"score\": 306, \"by\": \"danielhanchen\", \"descendants\": 138, \"story_id\": 47032876}"
  },
  {
    "id": "hackernews_47037501",
    "source": "Hacker News",
    "url": "https://webmachinelearning.github.io/webmcp/",
    "title": "WebMCP Proposal",
    "summary": "The Web Machine Learning Community Proposal (WebMCP) presents a comprehensive framework for standardizing the integration of machine learning functionalities directly within web browsers. Developed under the auspices of the Web Machine Learning Community Group, this proposal aims to establish consistent APIs and best practices, thereby empowering developers to deploy and execute artificial intelligence models on the client side. A primary goal is to leverage on-device inference, enhancing both performance and user privacy by processing data locally. The proposal specifically addresses key technical areas, including the utilization of underlying hardware acceleration technologies like WebGPU and WebNN, alongside robust mechanisms to ensure data privacy. By standardizing these essential capabilities, WebMCP intends to cultivate a more accessible, efficient, and secure ecosystem for machine learning on the web, reducing dependence on server-side computations and unlocking novel opportunities for interactive, privacy-centric AI applications. This initiative is pivotal for advancing the frontier of web application development to effectively manage sophisticated AI tasks.",
    "keywords": [
      "Web Machine Learning",
      "Web Standards",
      "On-device AI",
      "Browser-based ML",
      "WebGPU",
      "WebNN",
      "Client-side AI",
      "Privacy-preserving Machine Learning"
    ],
    "area": [
      "Machine Learning",
      "Artificial Intelligence",
      "Others"
    ],
    "published_time": "2026-02-16 17:08:20",
    "download_time": "2026-02-16 20:00:35",
    "extra_info": "{\"score\": 80, \"by\": \"Alifatisk\", \"descendants\": 42, \"story_id\": 47037501}"
  },
  {
    "id": "hackernews_47033622",
    "source": "Hacker News",
    "url": "https://www.theregister.com/2026/02/16/anthropic_claude_ai_edits/",
    "title": "Anthropic tries to hide Claude's AI actions. Devs hate it",
    "summary": "Anthropic, a prominent AI research company, is reportedly facing significant backlash from the developer community over allegations that it is actively attempting to obscure the underlying actions and decision-making processes of its advanced large language model, Claude. This perceived lack of transparency is drawing considerable ire, as developers emphasize the critical need for insight into an AI's operational logic for effective debugging, robust integration into complex systems, and ensuring ethical compliance. The developer community argues that withholding visibility into Claude's internal workings hampers their ability to innovate, build trustworthy applications, and understand potential biases or limitations. Many are calling for Anthropic to adopt more open and transparent development practices, highlighting that opacity could erode trust, slow down adoption, and create unforeseen challenges in deploying AI responsibly. This incident underscores a growing tension between proprietary AI development and the community's demand for greater interpretability and control over powerful AI agents.",
    "keywords": [
      "AI transparency",
      "Anthropic",
      "Claude AI",
      "developer frustration",
      "AI ethics",
      "model interpretability",
      "AI governance",
      "developer relations"
    ],
    "area": [
      "Artificial Intelligence",
      "Large Language Model",
      "AI Agent"
    ],
    "published_time": "2026-02-16 11:06:28",
    "download_time": "2026-02-16 20:00:54",
    "extra_info": "{\"score\": 305, \"by\": \"beardyw\", \"descendants\": 187, \"story_id\": 47033622}"
  },
  {
    "id": "hackernews_47034087",
    "source": "Hacker News",
    "url": "https://arxiv.org/abs/2602.11988",
    "title": "Evaluating AGENTS.md: are they helpful for coding agents?",
    "summary": "A recent study investigates the utility and effectiveness of AGENTS.md specifications in the development and performance of AI coding agents. The research evaluates whether adhering to these markdown-based guidelines can significantly enhance the operational capabilities, design consistency, and overall helpfulness of agents designed for software development tasks. By examining various coding agent implementations and their adherence to AGENTS.md, the study aims to identify best practices and potential shortcomings of the specification standard. Preliminary findings suggest that while AGENTS.md provides a structured framework for defining agent behaviors and interactions, its practical impact on agent efficiency and error reduction in complex coding scenarios warrants further investigation. The evaluation highlights areas where AGENTS.md can be refined to better serve the evolving landscape of AI-driven software engineering, offering insights for both developers and standard-setters in the agent community.",
    "keywords": [
      "AI Agents",
      "Coding Agents",
      "Agent Evaluation",
      "AGENTS.md",
      "Software Engineering",
      "Large Language Models",
      "Agent Development"
    ],
    "area": [
      "AI Agent",
      "Artificial Intelligence",
      "Large Language Model"
    ],
    "published_time": "2026-02-16 12:15:39",
    "download_time": "2026-02-16 20:01:04",
    "extra_info": "{\"score\": 17, \"by\": \"mustaphah\", \"descendants\": 5, \"story_id\": 47034087}"
  },
  {
    "id": "hackernews_47034192",
    "source": "Hacker News",
    "url": "https://mashable.com/article/ai-hard-drive-hdd-shortages-western-digital-sold-out",
    "title": "Thanks a lot, AI: Hard drives are sold out for the year, says WD",
    "summary": "The surging demand for data storage solutions, primarily driven by the rapid expansion of artificial intelligence development and deployment, has reportedly led to significant supply chain constraints for hard disk drives (HDDs). This increased consumption by AI-related infrastructure, including large data centers and specialized training environments, is causing a notable impact on hardware availability. Western Digital, a prominent global manufacturer of storage devices, has publicly confirmed that its hard drive inventory is fully allocated for the remainder of the current year. This situation underscores the immense pressure that accelerated AI innovation is exerting on the technology supply chain, potentially affecting various industries reliant on substantial storage capacity. The necessity for vast amounts of storage for training data, model parameters, and operational logs within the rapidly expanding AI sector, particularly for large language models, is a direct contributor to this global shortage, indicating a broader challenge for foundational hardware infrastructure to keep pace with AI industry demands.",
    "keywords": [
      "AI Demand",
      "Hard Drives",
      "Western Digital",
      "Storage Shortage",
      "Supply Chain",
      "Data Centers",
      "Hardware"
    ],
    "area": [
      "Artificial Intelligence",
      "Large Language Model",
      "Others"
    ],
    "published_time": "2026-02-16 12:28:31",
    "download_time": "2026-02-16 20:01:09",
    "extra_info": "{\"score\": 306, \"by\": \"dClauzel\", \"descendants\": 255, \"story_id\": 47034192}"
  },
  {
    "id": "hackernews_47038318",
    "source": "Hacker News",
    "url": "https://jkap.io/token-anxiety-or-a-slot-machine-by-any-other-name/",
    "title": "\"token anxiety\"; or, a slot machine by any other name",
    "summary": "The article, titled \"token anxiety\"; or, a slot machine by any other name, explores the psychological and practical implications of interacting with Large Language Models (LLMs), drawing a critical parallel to the experience of playing a slot machine. It delves into the concept of \"token anxiety,\" a phenomenon where users or developers experience apprehension due to the unpredictable consumption of computational tokens during LLM inference. This unpredictability directly impacts financial costs and resource allocation, creating a user experience akin to gambling. The piece likely examines how the generative process of LLMs, where outputs are revealed without prior certainty of cost or quality, fosters a variable reinforcement schedule. It critically analyzes the current design paradigms of LLM interfaces, suggesting they may inadvertently induce behaviors associated with gambling due to the inherent uncertainty and financial stakes. The author probably advocates for enhanced transparency in token usage, more predictable pricing models, and innovative interaction designs to mitigate user anxiety and provide greater control over LLM interactions.",
    "keywords": [
      "Tokenization",
      "Large Language Models",
      "User Experience",
      "AI Ethics",
      "Generative AI",
      "Human-Computer Interaction",
      "Cost Management"
    ],
    "area": [
      "Artificial Intelligence",
      "Large Language Model",
      "Natural Language Processing"
    ],
    "published_time": "2026-02-16 18:23:36",
    "download_time": "2026-02-16 20:00:35",
    "extra_info": "{\"score\": 17, \"by\": \"presbyterian\", \"descendants\": 3, \"story_id\": 47038318}"
  },
  {
    "id": "2602.10388",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2602.10388",
    "title": "Less is Enough: Synthesizing Diverse Data in Feature Space of LLMs",
    "summary": "The diversity of post-training data is critical for effective downstream performance in large language models (LLMs). Many existing approaches to constructing post-training data quantify diversity using text-based metrics that capture linguistic variation, but such metrics provide only weak signals for the task-relevant features that determine downstream performance. In this work, we introduce Feature Activation Coverage (FAC) which measures data diversity in an interpretable feature space. Building upon this metric, we further propose a diversity-driven data synthesis framework, named FAC Synthesis, that first uses a sparse autoencoder to identify missing features from a seed dataset, and then generates synthetic samples that explicitly reflect these features. Experiments show that our approach consistently improves both data diversity and downstream performance on various tasks, including instruction following, toxicity detection, reward modeling, and behavior steering. Interestingly, we identify a shared, interpretable feature space across model families (i.e., LLaMA, Mistral, and Qwen), enabling cross-model knowledge transfer. Our work provides a solid and practical methodology for exploring data-centric optimization of LLMs.",
    "keywords": [
      "LLMs",
      "Data Diversity",
      "Feature Space",
      "Data Synthesis",
      "Feature Activation Coverage"
    ],
    "area": [
      "Large Language Model",
      "Machine Learning",
      "Generative AI"
    ],
    "published_time": "2026-02-11T00:23:13.000Z",
    "download_time": "2026-02-16 12:01:24",
    "extra_info": "{\"url\": \"https://huggingface.co/papers/2602.10388\", \"arxiv_url\": \"https://arxiv.org/abs/2602.10388\", \"thumbnail\": \"https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2602.10388.png\", \"original_title\": \"Less is Enough: Synthesizing Diverse Data in Feature Space of LLMs\"}"
  },
  {
    "id": "2602.12984",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2602.12984",
    "title": "SciAgentGym: Benchmarking Multi-Step Scientific Tool-use in LLM Agents",
    "summary": "Scientific reasoning inherently demands integrating sophisticated toolkits to navigate domain-specific knowledge. Yet, current benchmarks largely overlook agents' ability to orchestrate tools for such rigorous workflows. To bridge this gap, we introduce SciAgentGym, a scalable interactive environment featuring 1,780 domain-specific tools across four natural science disciplines, supported by a robust execution infrastructure. Complementing this, we present SciAgentBench, a tiered evaluation suite designed to stress-test agentic capabilities from elementary actions to long-horizon workflows. Our evaluation identifies a critical bottleneck: state-of-the-art models struggle with complex scientific tool-use. Even for a leading model like GPT-5, success rates drop sharply from 60.6% to 30.9% as interaction horizons extend, primarily due to failures in multi-step workflow execution. To address this, we propose SciForge, a data synthesis method that models the tool action space as a dependency graph to generate logic-aware training trajectories. By fine-tuning on these trajectories, our SciAgent-8B outperforms the significantly larger Qwen3-VL-235B-Instruct while exhibiting positive cross-domain transfer of scientific tool-use capabilities. These results underscore the promising potential of next-generation autonomous scientific agents.",
    "keywords": [
      "LLM Agents",
      "Scientific Tool-use",
      "Benchmarks",
      "Data Synthesis",
      "Scientific Agents"
    ],
    "area": [
      "AI Agent",
      "Large Language Model",
      "Artificial Intelligence"
    ],
    "published_time": "2026-02-13T14:58:18.000Z",
    "download_time": "2026-02-16 12:01:24",
    "extra_info": "{\"url\": \"https://huggingface.co/papers/2602.12984\", \"arxiv_url\": \"https://arxiv.org/abs/2602.12984\", \"thumbnail\": \"https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2602.12984.png\", \"original_title\": \"SciAgentGym: Benchmarking Multi-Step Scientific Tool-use in LLM Agents\"}"
  },
  {
    "id": "2602.12684",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2602.12684",
    "title": "Xiaomi-Robotics-0: An Open-Sourced Vision-Language-Action Model with Real-Time Execution",
    "summary": "In this report, we introduce Xiaomi-Robotics-0, an advanced vision-language-action (VLA) model optimized for high performance and fast and smooth real-time execution. The key to our method lies in a carefully designed training recipe and deployment strategy. Xiaomi-Robotics-0 is first pre-trained on large-scale cross-embodiment robot trajectories and vision-language data, endowing it with broad and generalizable action-generation capabilities while avoiding catastrophic forgetting of the visual-semantic knowledge of the underlying pre-trained VLM. During post-training, we propose several techniques for training the VLA model for asynchronous execution to address the inference latency during real-robot rollouts. During deployment, we carefully align the timesteps of consecutive predicted action chunks to ensure continuous and seamless real-time rollouts. We evaluate Xiaomi-Robotics-0 extensively in simulation benchmarks and on two challenging real-robot tasks that require precise and dexterous bimanual manipulation. Results show that our method achieves state-of-the-art performance across all simulation benchmarks. Moreover, Xiaomi-Robotics-0 can roll out fast and smoothly on real robots using a consumer-grade GPU, achieving high success rates and throughput on both real-robot tasks. To facilitate future research, code and model checkpoints are open-sourced at https://xiaomi-robotics-0.github.io",
    "keywords": [
      "Vision-Language-Action Model",
      "Real-Time Execution",
      "Robotics",
      "Robot Learning",
      "Bimanual Manipulation"
    ],
    "area": [
      "Robotics",
      "Multimodal",
      "Deep Learning"
    ],
    "published_time": "2026-02-13T07:30:43.000Z",
    "download_time": "2026-02-16 12:01:25",
    "extra_info": "{\"url\": \"https://huggingface.co/papers/2602.12684\", \"arxiv_url\": \"https://arxiv.org/abs/2602.12684\", \"thumbnail\": \"https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2602.12684.png\", \"original_title\": \"Xiaomi-Robotics-0: An Open-Sourced Vision-Language-Action Model with Real-Time Execution\"}"
  },
  {
    "id": "2602.12829",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2602.12829",
    "title": "FLAC: Maximum Entropy RL via Kinetic Energy Regularized Bridge Matching",
    "summary": "Iterative generative policies, such as diffusion models and flow matching, offer superior expressivity for continuous control but complicate Maximum Entropy Reinforcement Learning because their action log-densities are not directly accessible. To address this, we propose Field Least-Energy Actor-Critic (FLAC), a likelihood-free framework that regulates policy stochasticity by penalizing the kinetic energy of the velocity field. Our key insight is to formulate policy optimization as a Generalized Schrödinger Bridge (GSB) problem relative to a high-entropy reference process (e.g., uniform). Under this view, the maximum-entropy principle emerges naturally as staying close to a high-entropy reference while optimizing return, without requiring explicit action densities. In this framework, kinetic energy serves as a physically grounded proxy for divergence from the reference: minimizing path-space energy bounds the deviation of the induced terminal action distribution. Building on this view, we derive an energy-regularized policy iteration scheme and a practical off-policy algorithm that automatically tunes the kinetic energy via a Lagrangian dual mechanism. Empirically, FLAC achieves superior or comparable performance on high-dimensional benchmarks relative to strong baselines, while avoiding explicit density estimation.",
    "keywords": [
      "Maximum Entropy RL",
      "Kinetic Energy Regularization",
      "Generative Policies",
      "Schrödinger Bridge",
      "Off-policy Learning"
    ],
    "area": [
      "Machine Learning",
      "Deep Learning",
      "Generative AI"
    ],
    "published_time": "2026-02-13T11:32:10.000Z",
    "download_time": "2026-02-16 12:01:24",
    "extra_info": "{\"url\": \"https://huggingface.co/papers/2602.12829\", \"arxiv_url\": \"https://arxiv.org/abs/2602.12829\", \"thumbnail\": \"https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2602.12829.png\", \"original_title\": \"FLAC: Maximum Entropy RL via Kinetic Energy Regularized Bridge Matching\"}"
  },
  {
    "id": "2602.11757",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2602.11757",
    "title": "Code2Worlds: Empowering Coding LLMs for 4D World Generation",
    "summary": "Achieving spatial intelligence requires moving beyond visual plausibility to build world simulators grounded in physical laws. While coding LLMs have advanced static 3D scene generation, extending this paradigm to 4D dynamics remains a critical frontier. This task presents two fundamental challenges: multi-scale context entanglement, where monolithic generation fails to balance local object structures with global environmental layouts; and a semantic-physical execution gap, where open-loop code generation leads to physical hallucinations lacking dynamic fidelity. We introduce Code2Worlds, a framework that formulates 4D generation as language-to-simulation code generation. First, we propose a dual-stream architecture that disentangles retrieval-augmented object generation from hierarchical environmental orchestration. Second, to ensure dynamic fidelity, we establish a physics-aware closed-loop mechanism in which a PostProcess Agent scripts dynamics, coupled with a VLM-Motion Critic that performs self-reflection to iteratively refine simulation code. Evaluations on the Code4D benchmark show Code2Worlds outperforms baselines with a 41% SGS gain and 49% higher Richness, while uniquely generating physics-aware dynamics absent in prior static methods. Code: https://github.com/AIGeeksGroup/Code2Worlds. Website: https://aigeeksgroup.github.io/Code2Worlds.",
    "keywords": [
      "4D World Generation",
      "Coding LLMs",
      "Physics-aware Dynamics",
      "Language-to-Simulation",
      "AI Agent"
    ],
    "area": [
      "Generative AI",
      "Large Language Model",
      "AI Agent"
    ],
    "published_time": "2026-02-12T09:34:28.000Z",
    "download_time": "2026-02-16 12:01:26",
    "extra_info": "{\"url\": \"https://huggingface.co/papers/2602.11757\", \"arxiv_url\": \"https://arxiv.org/abs/2602.11757\", \"thumbnail\": \"https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2602.11757.png\", \"original_title\": \"Code2Worlds: Empowering Coding LLMs for 4D World Generation\"}"
  },
  {
    "id": "2602.04163",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2602.04163",
    "title": "BPDQ: Bit-Plane Decomposition Quantization on a Variable Grid for Large Language Models",
    "summary": "Large language model (LLM) inference is often bounded by memory footprint and memory bandwidth in resource-constrained deployments, making quantization a fundamental technique for efficient serving. While post-training quantization (PTQ) maintains high fidelity at 4-bit, it deteriorates at 2-3 bits. Fundamentally, existing methods enforce a shape-invariant quantization grid (e.g., the fixed uniform intervals of UINT2) for each group, severely restricting the feasible set for error minimization. To address this, we propose Bit-Plane Decomposition Quantization (BPDQ), which constructs a variable quantization grid via bit-planes and scalar coefficients, and iteratively refines them using approximate second-order information while progressively compensating quantization errors to minimize output discrepancy. In the 2-bit regime, BPDQ enables serving Qwen2.5-72B on a single RTX 3090 with 83.85% GSM8K accuracy (vs. 90.83% at 16-bit). Moreover, we provide theoretical analysis showing that the variable grid expands the feasible set, and that the quantization process consistently aligns with the optimization objective in Hessian-induced geometry. Code: github.com/KingdalfGoodman/BPDQ.",
    "keywords": [
      "Large Language Models",
      "Quantization",
      "Bit-Plane Decomposition Quantization",
      "Variable Grid",
      "Post-Training Quantization"
    ],
    "area": [
      "Large Language Model",
      "Deep Learning",
      "Artificial Intelligence"
    ],
    "published_time": "2026-02-04T02:54:37.000Z",
    "download_time": "2026-02-16 12:01:24",
    "extra_info": "{\"url\": \"https://huggingface.co/papers/2602.04163\", \"arxiv_url\": \"https://arxiv.org/abs/2602.04163\", \"thumbnail\": \"https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2602.04163.png\", \"original_title\": \"BPDQ: Bit-Plane Decomposition Quantization on a Variable Grid for Large Language Models\"}"
  }
]