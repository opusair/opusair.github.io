[
  {
    "id": "hackernews_47050488",
    "source": "Hacker News",
    "url": "https://www.anthropic.com/news/claude-sonnet-4-6",
    "title": "Claude Sonnet 4.6",
    "summary": "Anthropic has unveiled Claude Sonnet 4.6, the latest iteration in its advanced line of large language models, signaling a significant leap forward in AI capabilities. This release builds upon the robust architecture and performance of previous Sonnet versions, aiming to deliver enhanced efficiency and sophistication for a wide array of applications. The official announcement directs users to a comprehensive system card, provided in PDF format, which typically outlines the model's technical specifications, improved functionalities, and the safety measures implemented during its development. Furthermore, a promotional video has been released to offer a dynamic overview of Claude Sonnet 4.6's new features and potential use cases. As with its predecessors, Sonnet 4.6 is anticipated to excel in complex reasoning, nuanced content generation, and interactive conversational tasks, aligning with Anthropic's commitment to developing powerful and responsible AI. This launch reinforces the company's dedication to innovation in the field of artificial intelligence, providing more capable and trustworthy AI tools for diverse user needs.",
    "keywords": [
      "Claude Sonnet 4.6",
      "Large Language Model",
      "Anthropic",
      "AI Model",
      "System Card",
      "AI Research",
      "Generative AI",
      "AI Safety"
    ],
    "area": [
      "Artificial Intelligence",
      "Large Language Model",
      "Generative AI"
    ],
    "published_time": "2026-02-17 17:48:52",
    "download_time": "2026-02-17 20:00:36",
    "extra_info": "{\"score\": 409, \"by\": \"adocomplete\", \"descendants\": 340, \"story_id\": 47050488}"
  },
  {
    "id": "hackernews_47049776",
    "source": "Hacker News",
    "url": "https://sonarly.com/",
    "title": "Launch HN: Sonarly (YC W26) â€“ AI agent to triage and fix your production alerts",
    "summary": "Sonarly, an AI agent from YC W26, has been launched to revolutionize production alert management and significantly reduce incident resolution times for engineering teams. The platform seamlessly integrates with popular observability tools like Sentry and Datadog, alongside various user feedback channels, to provide an autonomous AI engineer capable of triaging and resolving production issues. Sonarly's key functionality includes intelligently grouping duplicate alerts to minimize noise and performing detailed root cause analysis, thereby saving critical time for on-call engineers. This automated approach is designed to substantially decrease the Mean Time To Resolution (MTTR). The co-founders developed Sonarly based on their firsthand experience with the overwhelming volume of bugs and alerts encountered while running a B2C edtech application, highlighting the platform's practical foundation in solving real-world operational challenges in fast-paced development environments.",
    "keywords": [
      "AI agent",
      "Production alerts",
      "Observability tools",
      "Root cause analysis",
      "MTTR",
      "Incident management",
      "Sentry",
      "Datadog"
    ],
    "area": [
      "Artificial Intelligence",
      "AI Agent",
      "Machine Learning"
    ],
    "published_time": "2026-02-17 17:03:09",
    "download_time": "2026-02-17 20:00:43",
    "extra_info": "{\"score\": 15, \"by\": \"Dimittri\", \"descendants\": 1, \"story_id\": 47049776}"
  },
  {
    "id": "hackernews_47049088",
    "source": "Hacker News",
    "url": "https://www.theregister.com/2026/02/16/semantic_ablation_ai_writing/",
    "title": "Semantic ablation: Why AI writing is generic and boring",
    "summary": "The article introduces the concept of 'semantic ablation' to explain why AI-generated text often appears generic and lacks originality. Semantic ablation refers to the process where large language models, in their attempt to generalize from vast datasets, effectively 'average out' unique expressions and nuanced meanings, leading to bland and predictable outputs. This phenomenon suggests that while AI excels at synthesizing common patterns, it struggles to generate truly novel or distinct content, as its training inherently prioritizes statistical probability over semantic richness and individual style. The discussion highlights a fundamental limitation in current generative AI approaches, pointing to the need for models to develop a deeper understanding beyond surface-level textual patterns to produce more engaging and creative writing.",
    "keywords": [
      "Semantic Ablation",
      "AI Writing",
      "Generative AI",
      "Natural Language Generation",
      "Large Language Models",
      "Text Generation",
      "AI Limitations"
    ],
    "area": [
      "Artificial Intelligence",
      "Natural Language Processing",
      "Generative AI"
    ],
    "published_time": "2026-02-17 16:12:29",
    "download_time": "2026-02-17 20:00:46",
    "extra_info": "{\"score\": 159, \"by\": \"benji8000\", \"descendants\": 139, \"story_id\": 47049088}"
  },
  {
    "id": "hackernews_47049227",
    "source": "Hacker News",
    "url": "https://mage-bench.com/",
    "title": "Show HN: I taught LLMs to play Magic: The Gathering against each other",
    "summary": "A developer has successfully implemented a system enabling Large Language Models (LLMs) to engage in competitive play of Magic: The Gathering against each other. This innovative project integrates proprietary MCP (Magic Card Parser) tools with the widely recognized open-source XMage codebase, providing a robust platform for LLM interaction within the complex card game's rules and mechanics. While the current iteration is acknowledged to be 'pretty buggy,' the developer confirms its operational status and emphasizes considerable scope for performance enhancements through continuous tooling improvements. The evaluation system presently shows artificially deflated ratings for high-cost, frontier LLMs; this anomaly is a deliberate consequence of prioritizing the refinement of system bugs using more economical models before extensive testing with advanced LLMs commences. This endeavor represents a notable step in exploring the capabilities of AI, particularly LLMs, in mastering intricate strategic games and decision-making environments, paving the way for further research into AI agents' adaptability and strategic prowess.",
    "keywords": [
      "Large Language Models",
      "Magic: The Gathering",
      "AI Agents",
      "Game AI",
      "XMage",
      "MCP tools"
    ],
    "area": [
      "Artificial Intelligence",
      "Large Language Model",
      "AI Agent"
    ],
    "published_time": "2026-02-17 16:22:49",
    "download_time": "2026-02-17 20:00:50",
    "extra_info": "{\"score\": 59, \"by\": \"GregorStocks\", \"descendants\": 49, \"story_id\": 47049227}"
  },
  {
    "id": "hackernews_47048731",
    "source": "Hacker News",
    "url": "https://github.com/christopherkarani/Wax",
    "title": "Sub-Millisecond RAG on Apple Silicon. No Server. No API. One File",
    "summary": "This project highlights a significant advancement in the deployment and efficiency of Retrieval Augmented Generation (RAG) systems, specifically tailored for Apple Silicon architectures. It demonstrates the unprecedented capability to perform RAG operations in sub-millisecond times, directly on a local device, without relying on external servers or API calls. This entire functionality is encapsulated within a single, self-contained file. This local-first approach to RAG offers substantial benefits in terms of enhanced privacy, superior cost-effectiveness, and real-time performance, by adeptly leveraging the dedicated neural engines and unified memory architecture intrinsic to Apple's M-series processors. The innovation fundamentally democratizes access to powerful generative AI functionalities, enabling developers and end-users to run sophisticated AI applications directly on their personal devices. By emphasizing self-contained execution, the project significantly reduces operational overhead and diminishes dependency on cloud infrastructure for typical RAG workflows, thereby making advanced AI more accessible, efficient, and practical for edge computing scenarios and the development of robust personal AI assistants.",
    "keywords": [
      "Retrieval Augmented Generation",
      "RAG",
      "Apple Silicon",
      "Local Inference",
      "Generative AI",
      "Edge Computing",
      "AI Efficiency"
    ],
    "area": [
      "Artificial Intelligence",
      "Large Language Model",
      "Natural Language Processing"
    ],
    "published_time": "2026-02-17 15:43:37",
    "download_time": "2026-02-17 20:01:01",
    "extra_info": "{\"score\": 35, \"by\": \"ckarani\", \"descendants\": 10, \"story_id\": 47048731}"
  },
  {
    "id": "hackernews_47051958",
    "source": "Hacker News",
    "url": "https://www.nytimes.com/2026/02/17/world/asia/new-zealand-court-ai-apology.html",
    "title": "In Arson Case, a Judge Wrestles with A.I.-Assisted Apology Letters",
    "summary": "A pivotal legal case in New Zealand has brought to the forefront the intricate challenges posed by artificial intelligence within the judicial system, specifically concerning AI-assisted apology letters. In an arson case, a judge found themselves wrestling with the implications of submissions that appeared to have been drafted using generative AI tools. This unprecedented situation compelled the court to critically examine the authenticity, sincerity, and legal validity of such technologically mediated communications. The incident underscores a significant and rapidly emerging global challenge for legal frameworks: how to judiciously integrate AI technologies while upholding the integrity of justice and maintaining the human element of remorse and accountability. It ignites broader discussions on the ethical considerations of employing AI for personal statements in legal contexts, emphasizing the urgent need for comprehensive guidelines, and probing the potential impact on judicial impartiality. Courts worldwide are increasingly confronted with the necessity to establish clear standards regarding AI's role in evidentiary procedures and procedural fairness, as this case exemplifies the judiciary's ongoing effort to navigate the evolving landscape of AI.",
    "keywords": [
      "Artificial Intelligence",
      "Generative AI",
      "Legal Tech",
      "AI Ethics",
      "Judicial System",
      "Natural Language Processing",
      "Court Proceedings"
    ],
    "area": [
      "Artificial Intelligence",
      "Natural Language Processing",
      "Generative AI"
    ],
    "published_time": "2026-02-17 19:31:58",
    "download_time": "2026-02-17 20:01:07",
    "extra_info": "{\"score\": 5, \"by\": \"docdeek\", \"descendants\": 1, \"story_id\": 47051958}"
  },
  {
    "id": "2602.14721",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2602.14721",
    "title": "WebWorld: A Large-Scale World Model for Web Agent Training",
    "summary": "Web agents require massive trajectories to generalize, yet real-world training is constrained by network latency, rate limits, and safety risks. We introduce WebWorld series, the first open-web simulator trained at scale. While existing simulators are restricted to closed environments with thousands of trajectories, WebWorld leverages a scalable data pipeline to train on 1M+ open-web interactions, supporting reasoning, multi-format data, and long-horizon simulations of 30+ steps. For intrinsic evaluation, we introduce WebWorld-Bench with dual metrics spanning nine dimensions, where WebWorld achieves simulation performance comparable to Gemini-3-Pro. For extrinsic evaluation, Qwen3-14B trained on WebWorld-synthesized trajectories improves by +9.2% on WebArena, reaching performance comparable to GPT-4o. WebWorld enables effective inference-time search, outperforming GPT-5 as a world model. Beyond web simulation, WebWorld exhibits cross-domain generalization to code, GUI, and game environments, providing a replicable recipe for world model construction.",
    "keywords": [
      "WebWorld",
      "Web Agent",
      "World Model",
      "Web Simulator",
      "Large-Scale Training"
    ],
    "area": [
      "AI Agent",
      "Large Language Model",
      "Artificial Intelligence"
    ],
    "published_time": "2026-02-16T13:06:49.000Z",
    "download_time": "2026-02-17 12:01:37",
    "extra_info": "{\"url\": \"https://huggingface.co/papers/2602.14721\", \"arxiv_url\": \"https://arxiv.org/abs/2602.14721\", \"thumbnail\": \"https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2602.14721.png\", \"original_title\": \"WebWorld: A Large-Scale World Model for Web Agent Training\"}"
  },
  {
    "id": "2602.13367",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2602.13367",
    "title": "Nanbeige4.1-3B: A Small General Model that Reasons, Aligns, and Acts",
    "summary": "We present Nanbeige4.1-3B, a unified generalist language model that simultaneously achieves strong agentic behavior, code generation, and general reasoning with only 3B parameters. To the best of our knowledge, it is the first open-source small language model (SLM) to achieve such versatility in a single model. To improve reasoning and preference alignment, we combine point-wise and pair-wise reward modeling, ensuring high-quality, human-aligned responses. For code generation, we design complexity-aware rewards in Reinforcement Learning, optimizing both correctness and efficiency. In deep search, we perform complex data synthesis and incorporate turn-level supervision during training. This enables stable long-horizon tool interactions, allowing Nanbeige4.1-3B to reliably execute up to 600 tool-call turns for complex problem-solving. Extensive experimental results show that Nanbeige4.1-3B significantly outperforms prior models of similar scale, such as Nanbeige4-3B-2511 and Qwen3-4B, even achieving superior performance compared to much larger models, such as Qwen3-30B-A3B. Our results demonstrate that small models can achieve both broad competence and strong specialization simultaneously, redefining the potential of 3B parameter models.",
    "keywords": [
      "Small Language Model",
      "Agentic Behavior",
      "Code Generation",
      "General Reasoning",
      "Reinforcement Learning"
    ],
    "area": [
      "Large Language Model",
      "AI Agent",
      "Natural Language Processing"
    ],
    "published_time": "2026-02-13T13:10:46.000Z",
    "download_time": "2026-02-17 12:01:38",
    "extra_info": "{\"url\": \"https://huggingface.co/papers/2602.13367\", \"arxiv_url\": \"https://arxiv.org/abs/2602.13367\", \"thumbnail\": \"https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2602.13367.png\", \"original_title\": \"Nanbeige4.1-3B: A Small General Model that Reasons, Aligns, and Acts\"}"
  },
  {
    "id": "2602.13949",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2602.13949",
    "title": "Experiential Reinforcement Learning",
    "summary": "Reinforcement learning has become the central approach for language models (LMs) to learn from environmental reward or feedback. In practice, the environmental feedback is usually sparse and delayed. Learning from such signals is challenging, as LMs must implicitly infer how observed failures should translate into behavioral changes for future iterations. We introduce Experiential Reinforcement Learning (ERL), a training paradigm that embeds an explicit experience-reflection-consolidation loop into the reinforcement learning process. Given a task, the model generates an initial attempt, receives environmental feedback, and produces a reflection that guides a refined second attempt, whose success is reinforced and internalized into the base policy. This process converts feedback into structured behavioral revision, improving exploration and stabilizing optimization while preserving gains at deployment without additional inference cost. Across sparse-reward control environments and agentic reasoning benchmarks, ERL consistently improves learning efficiency and final performance over strong reinforcement learning baselines, achieving gains of up to +81% in complex multi-step environments and up to +11% in tool-using reasoning tasks. These results suggest that integrating explicit self-reflection into policy training provides a practical mechanism for transforming feedback into durable behavioral improvement.",
    "keywords": [
      "Reinforcement Learning",
      "Language Models",
      "Self-Reflection",
      "Agentic Reasoning",
      "Learning Efficiency"
    ],
    "area": [
      "Machine Learning",
      "Natural Language Processing",
      "AI Agent"
    ],
    "published_time": "2026-02-15T01:23:48.000Z",
    "download_time": "2026-02-17 12:01:37",
    "extra_info": "{\"url\": \"https://huggingface.co/papers/2602.13949\", \"arxiv_url\": \"https://arxiv.org/abs/2602.13949\", \"thumbnail\": \"https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2602.13949.png\", \"original_title\": \"Experiential Reinforcement Learning\"}"
  },
  {
    "id": "2602.14689",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2602.14689",
    "title": "Exposing the Systematic Vulnerability of Open-Weight Models to Prefill Attacks",
    "summary": "As the capabilities of large language models continue to advance, so does their potential for misuse. While closed-source models typically rely on external defenses, open-weight models must primarily depend on internal safeguards to mitigate harmful behavior. Prior red-teaming research has largely focused on input-based jailbreaking and parameter-level manipulations. However, open-weight models also natively support prefilling, which allows an attacker to predefine initial response tokens before generation begins. Despite its potential, this attack vector has received little systematic attention. We present the largest empirical study to date of prefill attacks, evaluating over 20 existing and novel strategies across multiple model families and state-of-the-art open-weight models. Our results show that prefill attacks are consistently effective against all major contemporary open-weight models, revealing a critical and previously underexplored vulnerability with significant implications for deployment. While certain large reasoning models exhibit some robustness against generic prefilling, they remain vulnerable to tailored, model-specific strategies. Our findings underscore the urgent need for model developers to prioritize defenses against prefill attacks in open-weight LLMs.",
    "keywords": [
      "Open-Weight Models",
      "Prefill Attacks",
      "Large Language Models",
      "Vulnerability",
      "Red-Teaming"
    ],
    "area": [
      "Large Language Model",
      "Generative AI",
      "Natural Language Processing"
    ],
    "published_time": "2026-02-16T12:24:21.000Z",
    "download_time": "2026-02-17 12:01:38",
    "extra_info": "{\"url\": \"https://huggingface.co/papers/2602.14689\", \"arxiv_url\": \"https://arxiv.org/abs/2602.14689\", \"thumbnail\": \"https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2602.14689.png\", \"original_title\": \"Exposing the Systematic Vulnerability of Open-Weight Models to Prefill Attacks\"}"
  },
  {
    "id": "2602.15031",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2602.15031",
    "title": "EditCtrl: Disentangled Local and Global Control for Real-Time Generative Video Editing",
    "summary": "High-fidelity generative video editing has seen significant quality improvements by leveraging pre-trained video foundation models. However, their computational cost is a major bottleneck, as they are often designed to inefficiently process the full video context regardless of the inpainting mask's size, even for sparse, localized edits. In this paper, we introduce EditCtrl, an efficient video inpainting control framework that focuses computation only where it is needed. Our approach features a novel local video context module that operates solely on masked tokens, yielding a computational cost proportional to the edit size. This local-first generation is then guided by a lightweight temporal global context embedder that ensures video-wide context consistency with minimal overhead. Not only is EditCtrl 10 times more compute efficient than state-of-the-art generative editing methods, it even improves editing quality compared to methods designed with full-attention. Finally, we showcase how EditCtrl unlocks new capabilities, including multi-region editing with text prompts and autoregressive content propagation.",
    "keywords": [
      "Generative Video Editing",
      "Video Inpainting",
      "Computational Efficiency",
      "Local Global Control",
      "Video Foundation Models"
    ],
    "area": [
      "Generative AI",
      "Computer Vision",
      "Deep Learning"
    ],
    "published_time": "2026-02-16T18:59:58.000Z",
    "download_time": "2026-02-17 12:01:35",
    "extra_info": "{\"url\": \"https://huggingface.co/papers/2602.15031\", \"arxiv_url\": \"https://arxiv.org/abs/2602.15031\", \"thumbnail\": \"https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2602.15031.png\", \"original_title\": \"EditCtrl: Disentangled Local and Global Control for Real-Time Generative Video Editing\"}"
  },
  {
    "id": "2602.14941",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2602.14941",
    "title": "AnchorWeave: World-Consistent Video Generation with Retrieved Local Spatial Memories",
    "summary": "Maintaining spatial world consistency over long horizons remains a central challenge for camera-controllable video generation. Existing memory-based approaches often condition generation on globally reconstructed 3D scenes by rendering anchor videos from the reconstructed geometry in the history. However, reconstructing a global 3D scene from multiple views inevitably introduces cross-view misalignment, as pose and depth estimation errors cause the same surfaces to be reconstructed at slightly different 3D locations across views. When fused, these inconsistencies accumulate into noisy geometry that contaminates the conditioning signals and degrades generation quality. We introduce AnchorWeave, a memory-augmented video generation framework that replaces a single misaligned global memory with multiple clean local geometric memories and learns to reconcile their cross-view inconsistencies. To this end, AnchorWeave performs coverage-driven local memory retrieval aligned with the target trajectory and integrates the selected local memories through a multi-anchor weaving controller during generation. Extensive experiments demonstrate that AnchorWeave significantly improves long-term scene consistency while maintaining strong visual quality, with ablation and analysis studies further validating the effectiveness of local geometric conditioning, multi-anchor control, and coverage-driven retrieval.",
    "keywords": [
      "Video Generation",
      "World Consistency",
      "Local Spatial Memories",
      "Memory-augmented",
      "Scene Consistency"
    ],
    "area": [
      "Computer Vision",
      "Generative AI",
      "Deep Learning"
    ],
    "published_time": "2026-02-16T17:23:08.000Z",
    "download_time": "2026-02-17 12:01:37",
    "extra_info": "{\"url\": \"https://huggingface.co/papers/2602.14941\", \"arxiv_url\": \"https://arxiv.org/abs/2602.14941\", \"thumbnail\": \"https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2602.14941.png\", \"original_title\": \"AnchorWeave: World-Consistent Video Generation with Retrieved Local Spatial Memories\"}"
  }
]