[
  {
    "id": "hackernews_45416228",
    "source": "Hacker News",
    "url": "https://www.npmjs.com/package/@anthropic-ai/claude-code",
    "title": "Claude Code 2.0",
    "summary": "Anthropic has officially launched Claude Code 2.0, a significant update to its specialized artificial intelligence offering tailored for software development. This new iteration, available as an npm package, is designed to provide developers with enhanced programmatic access to Claude's advanced large language model for a diverse range of coding tasks. These capabilities likely include more sophisticated code generation, improved debugging support, automated code review, and deeper understanding of programming logic across various languages. The transition to version 2.0 implies substantial advancements in the model's performance, accuracy, and integration features, aiming to further empower software engineers to more efficiently leverage AI throughout their development lifecycle. This release underscores Anthropic's strategic focus on equipping the developer community with powerful, accessible AI tools that can seamlessly integrate into modern application development, fostering greater productivity and innovation in coding endeavors.",
    "keywords": [
      "Anthropic",
      "Claude AI",
      "Code Generation",
      "Large Language Models",
      "npm Package",
      "Developer Tools"
    ],
    "area": [
      "Large Language Model",
      "Generative AI",
      "Natural Language Processing"
    ],
    "published_time": "2025-09-29 17:12:13",
    "download_time": "2025-09-29 20:01:10",
    "extra_info": "{\"score\": 244, \"by\": \"polyrand\", \"descendants\": 95, \"story_id\": 45416228}"
  },
  {
    "id": "hackernews_45415962",
    "source": "Hacker News",
    "url": "https://www.anthropic.com/news/claude-sonnet-4-5",
    "title": "Claude Sonnet 4.5",
    "summary": "Anthropic has unveiled Claude Sonnet 4.5, marking a significant update within its growing suite of large language models. Although detailed performance metrics are typically found within its accompanying system card, which is linked for public access, this release underscores Anthropic's continuous innovation in the field of artificial intelligence. Sonnet 4.5 is anticipated to build upon the strengths of its predecessors, potentially offering advancements in areas such as improved reasoning, enhanced contextual understanding, and refined safety protocols. The system card provides crucial insights into the model's design principles, training methodologies, and ethical considerations, guiding developers and researchers on its optimal and responsible deployment across various applications. This iteration highlights Anthropic's ongoing commitment to developing state-of-the-art AI while adhering to strict safety and ethical guidelines.",
    "keywords": [
      "Claude Sonnet",
      "Large Language Model",
      "Anthropic",
      "AI Development",
      "Generative AI",
      "AI Research"
    ],
    "area": [
      "Artificial Intelligence",
      "Large Language Model",
      "Generative AI"
    ],
    "published_time": "2025-09-29 16:52:59",
    "download_time": "2025-09-29 20:01:20",
    "extra_info": "{\"score\": 624, \"by\": \"adocomplete\", \"descendants\": 335, \"story_id\": 45415962}"
  },
  {
    "id": "hackernews_45415814",
    "source": "Hacker News",
    "url": "https://www.greptile.com/blog/sandboxing-agents-at-the-kernel-level",
    "title": "Sandboxing AI Agents at the Kernel Level",
    "summary": "This article delves into the crucial need for advanced security measures for increasingly autonomous AI agents, focusing on the innovative approach of implementing sandboxing at the kernel level. By establishing an isolated execution environment within the operating system's core, this method aims to provide robust protection against potential risks stemming from agent autonomy. These risks include unauthorized system access, data manipulation, or unintended operational consequences in complex, real-world scenarios. Leveraging the kernel's privileged position, sandboxing at this foundational layer allows for the stringent restriction of an AI agent's resource access and capabilities. This deep-level isolation is presented as a critical step toward ensuring the safe and reliable deployment of AI agents, particularly in sensitive or high-stakes applications. The article likely explores the technical complexities involved in integrating AI agent security directly into the OS kernel, discussing both the significant benefits and the engineering challenges associated with preventing accidental errors, adversarial attacks, or unforeseen emergent behaviors in advanced AI systems.",
    "keywords": [
      "Sandboxing",
      "AI Agents",
      "Kernel Security",
      "Operating Systems",
      "System Isolation",
      "Cybersecurity",
      "Autonomous Systems"
    ],
    "area": [
      "AI Agent",
      "Artificial Intelligence",
      "Others"
    ],
    "published_time": "2025-09-29 16:40:05",
    "download_time": "2025-09-29 20:01:17",
    "extra_info": "{\"score\": 38, \"by\": \"dakshgupta\", \"descendants\": 12, \"story_id\": 45415814}"
  },
  {
    "id": "hackernews_45416572",
    "source": "Hacker News",
    "url": "https://chatgpt.com/merchants",
    "title": "Instant Checkout for Merchants in ChatGPT",
    "summary": "OpenAI has reportedly introduced an \"Instant Checkout for Merchants\" feature within ChatGPT, signaling a strategic expansion of its conversational AI platform into the e-commerce and retail sectors. This new capability, highlighted by the dedicated URL \"https://chatgpt.com/merchants\", aims to revolutionize the online purchasing experience by allowing businesses to integrate streamlined transaction processes directly into their ChatGPT interactions. The core objective is to enable faster and more efficient customer checkouts, potentially leveraging AI-driven guidance, personalized recommendations, and automated payment processing within a conversational interface. This development positions ChatGPT not just as a tool for information or content generation, but as a practical solution for facilitating direct commercial transactions. It reflects a broader industry trend where large language models are being adapted for real-world business applications, offering tangible benefits like reduced friction in the sales funnel, improved customer satisfaction, and enhanced operational efficiency for merchants. This move underscores OpenAI's commitment to making AI a more integral part of daily commerce and business operations, transforming how online sales are conducted.",
    "keywords": [
      "ChatGPT",
      "E-commerce",
      "AI integration",
      "Payment processing",
      "Merchant solutions",
      "Conversational AI",
      "Instant checkout",
      "Large Language Model"
    ],
    "area": [
      "Artificial Intelligence",
      "Large Language Model",
      "AI Agent"
    ],
    "published_time": "2025-09-29 17:41:00",
    "download_time": "2025-09-29 20:01:27",
    "extra_info": "{\"score\": 67, \"by\": \"tortilla\", \"descendants\": 48, \"story_id\": 45416572}"
  },
  {
    "id": "hackernews_45417163",
    "source": "Hacker News",
    "url": "https://www.microsoft.com/en-us/microsoft-365/blog/2025/09/29/vibe-working-introducing-agent-mode-and-office-agent-in-microsoft-365-copilot/",
    "title": "Vibe Working: Introducing Agent Mode and Office Agent in Microsoft 365 Copilot",
    "summary": "Microsoft has unveiled significant advancements to its Microsoft 365 Copilot platform with the introduction of \"Agent Mode\" and \"Office Agent,\" under the theme of \"Vibe Working.\" These new functionalities are set to deepen the integration of artificial intelligence within the Microsoft 365 suite, aiming to revolutionize workplace productivity and user interaction. \"Agent Mode\" suggests a more autonomous and proactive AI assistant capability, while \"Office Agent\" likely refers to specialized AI agents tailored for specific Microsoft Office applications, such as Word, Excel, or PowerPoint. The overall initiative points towards a strategic move to empower users with intelligent agents that can anticipate needs, automate complex workflows, and provide personalized support across various professional tasks. This development highlights Microsoft's ongoing investment in leveraging AI to create a more efficient, seamless, and intelligent work environment, pushing the boundaries of what enterprise productivity tools can achieve through advanced AI agent technology. The focus is on enhancing the \"vibe\" or overall experience of working by making tools more intelligent and responsive.",
    "keywords": [
      "Microsoft 365 Copilot",
      "AI Agent",
      "Productivity Software",
      "Workplace AI",
      "Enterprise AI",
      "Digital Assistant",
      "Agent Mode"
    ],
    "area": [
      "Artificial Intelligence",
      "AI Agent",
      "Natural Language Processing"
    ],
    "published_time": "2025-09-29 18:32:47",
    "download_time": "2025-09-29 20:01:52",
    "extra_info": "{\"score\": 9, \"by\": \"prossercj\", \"descendants\": 1, \"story_id\": 45417163}"
  },
  {
    "id": "hackernews_45416764",
    "source": "Hacker News",
    "url": "https://www.wheresyoured.at/the-case-against-generative-ai/",
    "title": "The Case Against Generative AI",
    "summary": "The article titled 'The Case Against Generative AI' critically examines the burgeoning field of generative artificial intelligence, outlining various concerns and potential drawbacks associated with its rapid development and deployment. It explores ethical considerations such as bias embedded in training data, the propagation of misinformation, and intellectual property issues arising from content generation. Economic impacts, including job displacement in creative industries and changes in labor markets, are also discussed. Furthermore, the analysis addresses technical limitations like the phenomenon of 'hallucination' where models generate plausible but false information, and the significant computational resources and environmental footprint required. The piece concludes by urging a more cautious and responsible approach to generative AI development, advocating for robust regulatory frameworks and a deeper societal dialogue to mitigate risks and ensure equitable benefits.",
    "keywords": [
      "Generative AI",
      "AI Ethics",
      "Misinformation",
      "Copyright",
      "Job Displacement",
      "Hallucination",
      "AI Regulation",
      "Societal Impact"
    ],
    "area": [
      "Generative AI",
      "Artificial Intelligence",
      "Natural Language Processing"
    ],
    "published_time": "2025-09-29 17:58:13",
    "download_time": "2025-09-29 20:01:47",
    "extra_info": "{\"score\": 13, \"by\": \"speckx\", \"descendants\": 3, \"story_id\": 45416764}"
  },
  {
    "id": "MoneyPrinterTurbo",
    "source": "GitHub",
    "url": "https://github.com/harry0703/MoneyPrinterTurbo",
    "title": "MoneyPrinterTurbo 💸",
    "summary": "MoneyPrinterTurbo is an open-source project designed for automated short video generation. By simply providing a video theme or keywords, the system autonomously generates video scripts, visual materials, subtitles, and background music, culminating in a high-definition short video. Key features include a robust MVC architecture with both API and Web UI support, AI-powered script generation alongside custom script options, and support for various HD video aspect ratios (9:16 and 16:9). The platform facilitates batch video creation, adjustable clip durations, and multilingual content (Chinese and English). It offers diverse voice synthesis options with real-time preview, highly customizable subtitle generation (font, position, color, size, outline), and adaptable background music integration. MoneyPrinterTurbo leverages high-quality, copyright-free video assets, while also allowing users to incorporate their local materials. It boasts extensive integration with numerous large language model providers, including OpenAI, Moonshot, Azure, and DeepSeek, enhancing its content generation capabilities. This project significantly streamlines the video production workflow for content creators.",
    "keywords": [
      "AI Video Generation",
      "Short Video Automation",
      "Large Language Model Integration",
      "Voice Synthesis",
      "Subtitle Generation",
      "Content Creation",
      "Multimodal AI",
      "Video Editing Tools"
    ],
    "area": [
      "Artificial Intelligence",
      "Generative AI",
      "Video Understanding"
    ],
    "published_time": "2025-05-16T03:03:36Z",
    "download_time": "2024-05-17 10:00:00",
    "extra_info": null
  },
  {
    "id": "2509.22622",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2509.22622",
    "title": "LongLive: Real-time Interactive Long Video Generation",
    "summary": "We present LongLive, a frame-level autoregressive (AR) framework for real-time and interactive long video generation. Long video generation presents challenges in both efficiency and quality. Diffusion and Diffusion-Forcing models can produce high-quality videos but suffer from low efficiency due to bidirectional attention. Causal attention AR models support KV caching for faster inference, but often degrade in quality on long videos due to memory challenges during long-video training. In addition, beyond static prompt-based generation, interactive capabilities, such as streaming prompt inputs, are critical for dynamic content creation, enabling users to guide narratives in real time. This interactive requirement significantly increases complexity, especially in ensuring visual consistency and semantic coherence during prompt transitions. To address these challenges, LongLive adopts a causal, frame-level AR design that integrates a KV-recache mechanism that refreshes cached states with new prompts for smooth, adherent switches; streaming long tuning to enable long video training and to align training and inference (train-long-test-long); and short window attention paired with a frame-level attention sink, shorten as frame sink, preserving long-range consistency while enabling faster generation. With these key designs, LongLive fine-tunes a 1.3B-parameter short-clip model to minute-long generation in just 32 GPU-days. At inference, LongLive sustains 20.7 FPS on a single NVIDIA H100, achieves strong performance on VBench in both short and long videos. LongLive supports up to 240-second videos on a single H100 GPU. LongLive further supports INT8-quantized inference with only marginal quality loss.",
    "keywords": [
      "Long Video Generation",
      "Autoregressive Models",
      "Real-time Video Generation",
      "Interactive AI",
      "Video Generation Efficiency"
    ],
    "area": [
      "Generative AI",
      "Deep Learning",
      "Computer Vision"
    ],
    "published_time": "2025-09-26T17:48:24.000Z",
    "download_time": "2025-09-29 13:02:13",
    "extra_info": "{\"url\": \"https://huggingface.co/papers/2509.22622\", \"arxiv_url\": \"https://arxiv.org/abs/2509.22622\", \"thumbnail\": \"https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2509.22622.png\", \"original_title\": \"LongLive: Real-time Interactive Long Video Generation\"}"
  },
  {
    "id": "2509.22576",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2509.22576",
    "title": "EPO: Entropy-regularized Policy Optimization for LLM Agents",
    "summary": "Training LLM agents in multi-turn environments with sparse rewards, where completing a single task requires 30+ turns of interaction within an episode, presents a fundamental challenge for reinforcement learning. We identify a critical failure mode unique to this setting: the exploration-exploitation cascade failure. This cascade begins with early-stage policy premature convergence, where sparse feedback causes agents to commit to flawed, low-entropy strategies. Subsequently, agents enter late-stage policy collapse, where conventional entropy regularization becomes counterproductive, promoting chaotic exploration that destabilizes training. We propose Entropy-regularized Policy Optimization (EPO), a general framework that breaks this failure cycle through three synergistic mechanisms: (1) adopting entropy regularization in multi-turn settings to enhance exploration, (2) an entropy smoothing regularizer that bounds policy entropy within historical averages to prevent abrupt fluctuations, and (3) adaptive phase-based weighting that balances exploration and exploitation across training. Our analysis justifies that EPO guarantees monotonically decreasing entropy variance while maintaining convergence. EPO achieves up to 152% performance improvement on ScienceWorld and up to 19.8% on ALFWorld. Our work demonstrates that multi-turn sparse-reward settings require fundamentally different entropy control than traditional RL, with broad implications for LLM agent training.",
    "keywords": [
      "LLM Agents",
      "Reinforcement Learning",
      "Entropy Regularization",
      "Policy Optimization",
      "Sparse Rewards"
    ],
    "area": [
      "Large Language Model",
      "AI Agent",
      "Machine Learning"
    ],
    "published_time": "2025-09-26T16:51:44.000Z",
    "download_time": "2025-09-29 13:02:12",
    "extra_info": "{\"url\": \"https://huggingface.co/papers/2509.22576\", \"arxiv_url\": \"https://arxiv.org/abs/2509.22576\", \"thumbnail\": \"https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2509.22576.png\", \"original_title\": \"EPO: Entropy-regularized Policy Optimization for LLM Agents\\n  Reinforcement Learning\"}"
  },
  {
    "id": "2509.21766",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2509.21766",
    "title": "UltraHorizon: Benchmarking Agent Capabilities in Ultra Long-Horizon Scenarios",
    "summary": "Autonomous agents have recently achieved remarkable progress across diverse domains, yet most evaluations focus on short-horizon, fully observable tasks. In contrast, many critical real-world tasks, such as large-scale software development, commercial investment, and scientific discovery, unfold in long-horizon and partially observable scenarios where success hinges on sustained reasoning, planning, memory management, and tool use. Existing benchmarks rarely capture these long-horizon challenges, leaving a gap in systematic evaluation. To bridge this gap, we introduce UltraHorizon a novel benchmark that measures the foundational capabilities essential for complex real-world challenges. We use exploration as a unifying task across three distinct environments to validate these core competencies. Agents are designed in long-horizon discovery tasks where they must iteratively uncover hidden rules through sustained reasoning, planning, memory and tools management, and interaction with environments. Under the heaviest scale setting, trajectories average 200k+ tokens and 400+ tool calls, whereas in standard configurations they still exceed 35k tokens and involve more than 60 tool calls on average. Our extensive experiments reveal that LLM-agents consistently underperform in these settings, whereas human participants achieve higher scores, underscoring a persistent gap in agents' long-horizon abilities. We also observe that simple scaling fails in our task. To better illustrate the failure of agents, we conduct an in-depth analysis of collected trajectories. We identify eight types of errors and attribute them to two primary causes: in-context locking and functional fundamental capability gaps. https://github.com/StarDewXXX/UltraHorizon{Our code will be available here.}",
    "keywords": [
      "Autonomous agents",
      "Long-horizon scenarios",
      "Benchmarking",
      "LLM-agents",
      "Tool use"
    ],
    "area": [
      "Artificial Intelligence",
      "Large Language Model",
      "AI Agent"
    ],
    "published_time": "2025-09-26T02:04:00.000Z",
    "download_time": "2025-09-29 13:02:11",
    "extra_info": "{\"url\": \"https://huggingface.co/papers/2509.21766\", \"arxiv_url\": \"https://arxiv.org/abs/2509.21766\", \"thumbnail\": \"https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2509.21766.png\", \"original_title\": \"UltraHorizon: Benchmarking Agent Capabilities in Ultra Long-Horizon\\n  Scenarios\"}"
  },
  {
    "id": "2509.22624",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2509.22624",
    "title": "SPARK: Synergistic Policy And Reward Co-Evolving Framework",
    "summary": "Recent Large Language Models (LLMs) and Large Vision-Language Models (LVLMs) increasingly use Reinforcement Learning (RL) for post-pretraining, such as RL with Verifiable Rewards (RLVR) for objective tasks and RL from Human Feedback (RLHF) for subjective tasks. However, RLHF incurs high costs and potential reward-policy mismatch due to reliance on human preferences, while RLVR still wastes supervision by discarding rollouts and correctness signals after each update. To address these challenges, we introduce the Synergistic Policy And Reward Co-Evolving Framework (SPARK), an efficient, on-policy, and stable method that builds on RLVR. Instead of discarding rollouts and correctness data, SPARK recycles this valuable information to simultaneously train the model itself as a generative reward model. This auxiliary training uses a mix of objectives, such as pointwise reward score, pairwise comparison, and evaluation conditioned on further-reflection responses, to teach the model to evaluate and improve its own responses. Our process eliminates the need for a separate reward model and costly human preference data. SPARK creates a positive co-evolving feedback loop: improved reward accuracy yields better policy gradients, which in turn produce higher-quality rollouts that further refine the reward model. Our unified framework supports test-time scaling via self-reflection without external reward models and their associated costs. We show that SPARK achieves significant performance gains on multiple LLM and LVLM models and multiple reasoning, reward models, and general benchmarks. For example, SPARK-VL-7B achieves an average 9.7% gain on 7 reasoning benchmarks, 12.1% on 2 reward benchmarks, and 1.5% on 8 general benchmarks over the baselines, demonstrating robustness and broad generalization.",
    "keywords": [
      "Reinforcement Learning",
      "Large Language Models",
      "Large Vision-Language Models",
      "Reward Models",
      "Self-reflection"
    ],
    "area": [
      "Large Language Model",
      "Multimodal",
      "Deep Learning"
    ],
    "published_time": "2025-09-26T17:50:12.000Z",
    "download_time": "2025-09-29 13:02:14",
    "extra_info": "{\"url\": \"https://huggingface.co/papers/2509.22624\", \"arxiv_url\": \"https://arxiv.org/abs/2509.22624\", \"thumbnail\": \"https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2509.22624.png\", \"original_title\": \"SPARK: Synergistic Policy And Reward Co-Evolving Framework\"}"
  },
  {
    "id": "2509.22642",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2509.22642",
    "title": "WoW: Towards a World omniscient World model Through Embodied Interaction",
    "summary": "Humans develop an understanding of intuitive physics through active interaction with the world. This approach is in stark contrast to current video models, such as Sora, which rely on passive observation and therefore struggle with grasping physical causality. This observation leads to our central hypothesis: authentic physical intuition of the world model must be grounded in extensive, causally rich interactions with the real world. To test this hypothesis, we present WoW, a 14-billion-parameter generative world model trained on 2 million robot interaction trajectories. Our findings reveal that the model's understanding of physics is a probabilistic distribution of plausible outcomes, leading to stochastic instabilities and physical hallucinations. Furthermore, we demonstrate that this emergent capability can be actively constrained toward physical realism by SOPHIA, where vision-language model agents evaluate the DiT-generated output and guide its refinement by iteratively evolving the language instructions. In addition, a co-trained Inverse Dynamics Model translates these refined plans into executable robotic actions, thus closing the imagination-to-action loop. We establish WoWBench, a new benchmark focused on physical consistency and causal reasoning in video, where WoW achieves state-of-the-art performance in both human and autonomous evaluation, demonstrating strong ability in physical causality, collision dynamics, and object permanence. Our work provides systematic evidence that large-scale, real-world interaction is a cornerstone for developing physical intuition in AI. Models, data, and benchmarks will be open-sourced.",
    "keywords": [
      "World model",
      "Embodied Interaction",
      "Generative AI",
      "Robotics",
      "Physical Intuition"
    ],
    "area": [
      "Generative AI",
      "Robotics",
      "Video Understanding"
    ],
    "published_time": "2025-09-26T17:59:07.000Z",
    "download_time": "2025-09-29 13:02:11",
    "extra_info": "{\"url\": \"https://huggingface.co/papers/2509.22642\", \"arxiv_url\": \"https://arxiv.org/abs/2509.22642\", \"thumbnail\": \"https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2509.22642.png\", \"original_title\": \"WoW: Towards a World omniscient World model Through Embodied Interaction\"}"
  },
  {
    "id": "2509.21150",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2509.21150",
    "title": "CAD-Tokenizer: Towards Text-based CAD Prototyping via Modality-Specific Tokenization",
    "summary": "Computer-Aided Design (CAD) is a foundational component of industrial prototyping, where models are defined not by raw coordinates but by construction sequences such as sketches and extrusions. This sequential structure enables both efficient prototype initialization and subsequent editing. Text-guided CAD prototyping, which unifies Text-to-CAD generation and CAD editing, has the potential to streamline the entire design pipeline. However, prior work has not explored this setting, largely because standard large language model (LLM) tokenizers decompose CAD sequences into natural-language word pieces, failing to capture primitive-level CAD semantics and hindering attention modules from modeling geometric structure. We conjecture that a multimodal tokenization strategy, aligned with CAD's primitive and structural nature, can provide more effective representations. To this end, we propose CAD-Tokenizer, a framework that represents CAD data with modality-specific tokens using a sequence-based VQ-VAE with primitive-level pooling and constrained decoding. This design produces compact, primitive-aware representations that align with CAD's structural nature. Applied to unified text-guided CAD prototyping, CAD-Tokenizer significantly improves instruction following and generation quality, achieving better quantitative and qualitative performance over both general-purpose LLMs and task-specific baselines.",
    "keywords": [
      "CAD-Tokenizer",
      "Text-based CAD Prototyping",
      "Modality-Specific Tokenization",
      "Computer-Aided Design",
      "Large Language Models"
    ],
    "area": [
      "Multimodal",
      "Large Language Model",
      "Generative AI"
    ],
    "published_time": "2025-09-25T13:38:36.000Z",
    "download_time": "2025-09-29 13:02:17",
    "extra_info": "{\"url\": \"https://huggingface.co/papers/2509.21150\", \"arxiv_url\": \"https://arxiv.org/abs/2509.21150\", \"thumbnail\": \"https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2509.21150.png\", \"original_title\": \"CAD-Tokenizer: Towards Text-based CAD Prototyping via Modality-Specific\\n  Tokenization\"}"
  }
]