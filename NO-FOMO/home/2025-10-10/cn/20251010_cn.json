[
  {
    "id": "hackernews_45536694",
    "source": "Hacker News",
    "url": "https://discrete-distribution-networks.github.io/",
    "title": "Show HN: I invented a new generative model and got accepted to ICLR",
    "summary": "A new generative model, Discrete Distribution Networks (DDN), has been developed and accepted to ICLR2025. DDN proposes a novel approach to modeling data distributions, diverging from established models like Diffusion, GAN, VAE, and autoregressive models. Its core innovation lies in generating multiple outputs simultaneously within a single forward pass, utilizing these outputs to approximate the target data distribution. Critically, these combined outputs form a discrete distribution, hence the model's name. Key features of DDN include Zero-Shot Conditional Generation (ZSCG) and the use of a one-dimensional discrete latent representation structured in a tree-like fashion. This research offers a distinct perspective on generative modeling with potential implications for advancing the field.",
    "keywords": [
      "Generative Model",
      "Discrete Distribution Networks",
      "ICLR",
      "Zero-Shot Conditional Generation",
      "Latent Representation",
      "Data Distribution",
      "Machine Learning",
      "Deep Learning"
    ],
    "area": [
      "Artificial Intelligence",
      "Machine Learning",
      "Generative AI"
    ],
    "published_time": "2025-10-10 09:01:54",
    "download_time": "2025-10-10 20:01:08",
    "extra_info": "{\"score\": 411, \"by\": \"diyer22\", \"descendants\": 48, \"story_id\": 45536694}"
  },
  {
    "id": "hackernews_45541125",
    "source": "Hacker News",
    "url": "https://stratechery.com/2025/its-openais-world-were-just-living-in-it/",
    "title": "It's OpenAI's world, we're just living in it",
    "summary": "The title, \"It's OpenAI's world, we're just living in it,\" encapsulates a prevailing sentiment regarding OpenAI's profound and rapidly expanding influence across the artificial intelligence landscape. This evocative statement suggests a perception that OpenAI has ascended to a position of significant, perhaps even dominant, control over the direction and pace of AI development. It implies that other players in the industry, including startups, established tech giants, and researchers, are largely operating within paradigms or reacting to innovations established by OpenAI. This perceived hegemony stems from the company's groundbreaking advancements in large language models and generative AI, which have not only captivated public imagination but also set new benchmarks for capability and application. The article likely explores how OpenAI's rapid innovation cycle, strategic partnerships, and substantial funding have enabled it to dictate key trends, influence research agendas, and shape market expectations, positioning other entities as responders rather than primary drivers.",
    "keywords": [
      "OpenAI",
      "Artificial Intelligence",
      "AI Industry",
      "Technological Leadership",
      "Generative AI",
      "Large Language Models"
    ],
    "area": [
      "Artificial Intelligence",
      "Large Language Model",
      "Generative AI"
    ],
    "published_time": "2025-10-10 17:01:04",
    "download_time": "2025-10-10 20:01:19",
    "extra_info": "{\"score\": 56, \"by\": \"feross\", \"descendants\": 96, \"story_id\": 45541125}"
  },
  {
    "id": "hackernews_45540171",
    "source": "Hacker News",
    "url": "https://github.com/diffplug/gitcasso",
    "title": "Show HN: Gitcasso â€“ Syntax Highlighting and Draft Recovery for GitHub Comments",
    "summary": "Gitcasso is a newly developed browser extension that significantly enhances the GitHub user experience by introducing Markdown syntax highlighting directly into textareas and offering robust draft recovery functionalities. It compiles and displays all open pull request and issue tabs along with their respective drafts, with an unimplemented yet planned feature for automatic comment draft autosaving. The extension's conception was inspired by overtype.dev, another successful markdown textarea highlighter. A notable aspect of Gitcasso's creation lies in its development methodology, which heavily utilized Playwright and Claude Code. This approach allowed for near-automatic adaptation to upstream GitHub changes, addressing a common challenge in browser extension maintenance. The developer highlighted a novel experience where AI was instrumental in the actual construction of the tool, marking a significant step in AI-assisted software development and underscoring the potential of generative AI in streamlining complex programming tasks.",
    "keywords": [
      "Syntax Highlighting",
      "GitHub",
      "Browser Extension",
      "Draft Recovery",
      "Markdown",
      "Playwright",
      "Claude Code",
      "AI Assisted Development"
    ],
    "area": [
      "Artificial Intelligence",
      "Generative AI",
      "Others"
    ],
    "published_time": "2025-10-10 15:37:27",
    "download_time": "2025-10-10 20:01:32",
    "extra_info": "{\"score\": 16, \"by\": \"etwigg\", \"descendants\": 3, \"story_id\": 45540171}"
  },
  {
    "id": "hackernews_45542283",
    "source": "Hacker News",
    "url": "https://www.bnamericas.com/en/features/argentina-joins-openais-stargate-project-with-a-500mw-megadata-center",
    "title": "Argentina joins OpenAI's Stargate project with a 500MW data center",
    "summary": "Argentina has officially announced its participation in OpenAI's ambitious 'Stargate' project, a monumental initiative aimed at developing advanced AI supercomputing infrastructure. This collaboration involves the establishment of a substantial 500-megawatt (MW) data center within Argentina, positioning the nation as a key player in the global expansion of artificial intelligence capabilities. The Stargate project, widely reported to be a multi-billion dollar undertaking led by OpenAI in partnership with major technology investors, seeks to address the ever-growing demand for immense computational power required for training next-generation large language models and other sophisticated AI systems. The 500MW capacity signifies a significant investment in high-density computing facilities, essential for handling the extreme energy and cooling requirements of AI supercomputers. Argentina's involvement underscores a strategic move to attract high-tech investment and foster local expertise in advanced data center operations and AI infrastructure management, potentially creating numerous opportunities for technological development and economic growth within the region, while supporting OpenAI's long-term vision for AI research and deployment.",
    "keywords": [
      "OpenAI",
      "AI Infrastructure",
      "Data Center",
      "Supercomputing",
      "Stargate Project",
      "Large Language Models"
    ],
    "area": [
      "Artificial Intelligence",
      "Large Language Model",
      "Machine Learning"
    ],
    "published_time": "2025-10-10 18:38:54",
    "download_time": "2025-10-10 20:01:42",
    "extra_info": "{\"score\": 8, \"by\": \"mromanuk\", \"descendants\": 0, \"story_id\": 45542283}"
  },
  {
    "id": "hackernews_45536124",
    "source": "Hacker News",
    "url": "https://www.rfleury.com/p/multi-core-by-default",
    "title": "Multi-Core by Default",
    "summary": "The concept of \"Multi-Core by Default\" signifies a pivotal shift in software development and system design, where applications and operating systems are inherently engineered to leverage the ubiquitous presence of multi-core processors. This paradigm emphasizes that parallelism should not be an afterthought but a fundamental consideration from the initial stages of software architecture. The article likely delves into the historical context of single-core dominance and the subsequent transition driven by physical limitations in clock speed scaling. It highlights the imperative for developers to adopt concurrent programming models and tools to effectively harness the potential of modern hardware. This approach is critical for enhancing performance, improving responsiveness, and efficiently managing computational resources across a spectrum of devices, from embedded systems to high-performance computing clusters. Embracing a \"multi-core by default\" mindset is presented as essential for future-proofing software, ensuring scalability, and maximizing the efficiency of contemporary and upcoming computing platforms, thereby dictating a new standard for robust and performant application design.",
    "keywords": [
      "Multi-core processing",
      "Parallel computing",
      "Concurrency",
      "Software architecture",
      "System design",
      "Performance optimization"
    ],
    "area": [
      "Artificial Intelligence",
      "Machine Learning",
      "AI Agent"
    ],
    "published_time": "2025-10-10 07:11:06",
    "download_time": "2025-10-10 20:02:09",
    "extra_info": "{\"score\": 69, \"by\": \"kruuuder\", \"descendants\": 39, \"story_id\": 45536124}"
  },
  {
    "id": "claude-code",
    "source": "GitHub",
    "url": "https://github.com/anthropics/claude-code",
    "title": "Claude Code",
    "summary": "Claude Code is an innovative agentic coding tool designed to enhance developer productivity by integrating directly into the terminal, IDE, or GitHub workflows. This AI agent understands a user's codebase, enabling faster development through natural language commands. Its core functionalities include automating routine coding tasks, providing clear explanations for complex code segments, and streamlining common Git operations. Developers can interact with Claude Code to quickly execute commands, manage their project's version control, and gain insights into their code without leaving their development environment. The tool also facilitates bug reporting directly within its interface and fosters community engagement through a dedicated Discord channel. Anthropic collects usage data, conversation data, and user feedback, with clear policies regarding data usage and privacy safeguards, ensuring feedback is not used for model training and sensitive information has limited retention. This positions Claude Code as a versatile assistant for modern software development.",
    "keywords": [
      "Agentic Coding Tool",
      "AI Agent",
      "Natural Language Processing",
      "Code Generation",
      "Developer Tools",
      "Git Workflow Automation",
      "Codebase Analysis",
      "Terminal Integration"
    ],
    "area": [
      "Artificial Intelligence",
      "AI Agent",
      "Natural Language Processing"
    ],
    "published_time": "2025-10-10T16:02:03Z",
    "download_time": "2024-05-15 10:00:00",
    "extra_info": null
  },
  {
    "id": "xiaozhi-esp32",
    "source": "GitHub",
    "url": "https://github.com/78/xiaozhi-esp32",
    "title": "An MCP-based Chatbot",
    "summary": "The \"An MCP-based Chatbot\" project introduces an AI conversational robot that leverages Qwen/DeepSeek large language models and the Multi-Control Protocol (MCP) for versatile multi-device control. Acting as a voice interaction gateway, it incorporates advanced features like Wi-Fi/4G connectivity, offline voice wake-up via ESP-SR, and voiceprint recognition through 3D Speaker technology. The system utilizes a streaming ASR + LLM + TTS architecture for real-time speech processing and supports the OPUS audio codec. It is compatible with ESP32-C3, ESP32-S3, and ESP32-P4 chip platforms, offering extensive control capabilities for device peripherals such as volume, lighting, motors, and GPIO via device-side MCP. Additionally, cloud-side MCP expands its functionality to intelligent home automation, PC desktop operations, knowledge retrieval, and email management. The project supports extensive customization of wake words, fonts, expressions, and chat backgrounds, and is compatible with over 70 open-source hardware devices, positioning it as a robust solution for embedded AI applications.",
    "keywords": [
      "MCP Protocol",
      "AI Chatbot",
      "ESP32",
      "Voice Interaction",
      "Large Language Model",
      "IoT Control",
      "Embedded AI",
      "Speech Recognition"
    ],
    "area": [
      "Artificial Intelligence",
      "Large Language Model",
      "AI Agent"
    ],
    "published_time": "2025-10-10T02:58:47Z",
    "download_time": "2024-07-27 06:15:00",
    "extra_info": null
  },
  {
    "id": "stagehand",
    "source": "GitHub",
    "url": "https://github.com/browserbase/stagehand",
    "title": "Stagehand: The AI Browser Automation Framework",
    "summary": "Stagehand is an innovative AI browser automation framework designed to bridge the gap between low-level coding tools like Selenium, Playwright, or Puppeteer and often unpredictable high-level AI agents. It offers a unique hybrid approach, empowering developers to strategically choose between writing traditional code for precise actions and leveraging natural language prompts for navigating unfamiliar pages, thus making it a natural choice for robust production-grade browser automations. A core technical advantage is its deep integration with Playwright, allowing users to combine the reliability of code with the flexibility of AI. Stagehand further enhances efficiency by enabling users to preview AI actions before execution and cache repeatable actions, significantly saving time and computational resources. It also simplifies the integration of state-of-the-art computer use models from leading providers like OpenAI and Anthropic with just a single line of code. Focused on improving reliability, speed, and cost, Stagehand provides a versatile and powerful solution for complex web automation scenarios.",
    "keywords": [
      "Browser Automation",
      "AI Agent",
      "Playwright",
      "Natural Language Processing",
      "Large Language Model",
      "Web Automation",
      "Automation Framework",
      "Hybrid AI"
    ],
    "area": [
      "Artificial Intelligence",
      "Large Language Model",
      "AI Agent"
    ],
    "published_time": "2025-10-10T00:18:00Z",
    "download_time": "2024-06-25 12:30:00",
    "extra_info": null
  },
  {
    "id": "2510.08276",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2510.08276",
    "title": "Beyond Turn Limits: Training Deep Search Agents with Dynamic Context Window",
    "summary": "While recent advances in reasoning models have demonstrated cognitive behaviors through reinforcement learning, existing approaches struggle to invoke deep reasoning capabilities in multi-turn agents with long-horizon interactions. We propose DeepMiner, a novel framework that elicits such abilities by introducing high-difficulty training tasks and dynamic context window. DeepMiner presents a reverse construction method to generate complex but verifiable question-answer pairs from authentic web sources, which ensures the challenge and reliability of training data while injecting cognitive capabilities into multi-turn reasoning scenarios. We further design an elegant yet effective dynamic context management strategy for both training and inference, utilizing sliding window mechanisms while eliminating the dependency on external summarization models, thereby efficiently empowering the model to handle continuously expanding long-horizon contexts. Through reinforcement learning on Qwen3-32B, we develop DeepMiner-32B, which achieves substantial performance improvements across multiple search agent benchmarks. DeepMiner attains 33.5% accuracy on BrowseComp-en, surpassing the previous best open-source agent by almost 20 percentage points, and demonstrates consistent improvements on BrowseComp-zh, XBench-DeepSearch, and GAIA. Notably, our dynamic context management enables sustained interactions of nearly 100 turns within standard 32k context length, effectively addressing the context limitations that constrain existing multi-turn interaction systems.",
    "keywords": [
      "Deep Search Agents",
      "Dynamic Context Window",
      "Reinforcement Learning",
      "Multi-turn agents",
      "Context Management"
    ],
    "area": [
      "AI Agent",
      "Large Language Model",
      "Deep Learning"
    ],
    "published_time": "2025-10-09T14:31:39.000Z",
    "download_time": "2025-10-10 13:02:25",
    "extra_info": "{\"url\": \"https://huggingface.co/papers/2510.08276\", \"arxiv_url\": \"https://arxiv.org/abs/2510.08276\", \"thumbnail\": \"https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.08276.png\", \"original_title\": \"Beyond Turn Limits: Training Deep Search Agents with Dynamic Context\\n  Window\"}"
  },
  {
    "id": "2510.08240",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2510.08240",
    "title": "The Alignment Waltz: Jointly Training Agents to Collaborate for Safety",
    "summary": "Harnessing the power of LLMs requires a delicate dance between being helpful and harmless. This creates a fundamental tension between two competing challenges: vulnerability to adversarial attacks that elicit unsafe content, and a tendency for overrefusal on benign but sensitive prompts. Current approaches often navigate this dance with safeguard models that completely reject any content that contains unsafe portions. This approach cuts the music entirely-it may exacerbate overrefusals and fails to provide nuanced guidance for queries it refuses. To teach models a more coordinated choreography, we propose WaltzRL, a novel multi-agent reinforcement learning framework that formulates safety alignment as a collaborative, positive-sum game. WaltzRL jointly trains a conversation agent and a feedback agent, where the latter is incentivized to provide useful suggestions that improve the safety and helpfulness of the conversation agent's responses. At the core of WaltzRL is a Dynamic Improvement Reward (DIR) that evolves over time based on how well the conversation agent incorporates the feedback. At inference time, unsafe or overrefusing responses from the conversation agent are improved rather than discarded. The feedback agent is deployed together with the conversation agent and only engages adaptively when needed, preserving helpfulness and low latency on safe queries. Our experiments, conducted across five diverse datasets, demonstrate that WaltzRL significantly reduces both unsafe responses (e.g., from 39.0% to 4.6% on WildJailbreak) and overrefusals (from 45.3% to 9.9% on OR-Bench) compared to various baselines. By enabling the conversation and feedback agents to co-evolve and adaptively apply feedback, WaltzRL enhances LLM safety without degrading general capabilities, thereby advancing the Pareto front between helpfulness and harmlessness.",
    "keywords": [
      "LLM Safety",
      "Multi-agent Reinforcement Learning",
      "Safety Alignment",
      "Agent Collaboration",
      "Overrefusal Mitigation"
    ],
    "area": [
      "Large Language Model",
      "AI Agent",
      "Machine Learning"
    ],
    "published_time": "2025-10-09T14:03:05.000Z",
    "download_time": "2025-10-10 13:02:23",
    "extra_info": "{\"url\": \"https://huggingface.co/papers/2510.08240\", \"arxiv_url\": \"https://arxiv.org/abs/2510.08240\", \"thumbnail\": \"https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.08240.png\", \"original_title\": \"The Alignment Waltz: Jointly Training Agents to Collaborate for Safety\"}"
  },
  {
    "id": "2510.07242",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2510.07242",
    "title": "Hybrid Reinforcement: When Reward Is Sparse, It's Better to Be Dense",
    "summary": "Post-training for reasoning of large language models (LLMs) increasingly relies on verifiable rewards: deterministic checkers that provide 0-1 correctness signals. While reliable, such binary feedback is brittle--many tasks admit partially correct or alternative answers that verifiers under-credit, and the resulting all-or-nothing supervision limits learning. Reward models offer richer, continuous feedback, which can serve as a complementary supervisory signal to verifiers. We introduce HERO (Hybrid Ensemble Reward Optimization), a reinforcement learning framework that integrates verifier signals with reward-model scores in a structured way. HERO employs stratified normalization to bound reward-model scores within verifier-defined groups, preserving correctness while refining quality distinctions, and variance-aware weighting to emphasize challenging prompts where dense signals matter most. Across diverse mathematical reasoning benchmarks, HERO consistently outperforms RM-only and verifier-only baselines, with strong gains on both verifiable and hard-to-verify tasks. Our results show that hybrid reward design retains the stability of verifiers while leveraging the nuance of reward models to advance reasoning.",
    "keywords": [
      "Reinforcement Learning",
      "Large Language Models",
      "Reward Models",
      "Hybrid Reward Design",
      "Verifiable Rewards"
    ],
    "area": [
      "Large Language Model",
      "Machine Learning",
      "Natural Language Processing"
    ],
    "published_time": "2025-10-08T17:09:41.000Z",
    "download_time": "2025-10-10 13:02:22",
    "extra_info": "{\"url\": \"https://huggingface.co/papers/2510.07242\", \"arxiv_url\": \"https://arxiv.org/abs/2510.07242\", \"thumbnail\": \"https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.07242.png\", \"original_title\": \"Hybrid Reinforcement: When Reward Is Sparse, It's Better to Be Dense\"}"
  },
  {
    "id": "2510.08377",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2510.08377",
    "title": "UniVideo: Unified Understanding, Generation, and Editing for Videos",
    "summary": "Unified multimodal models have shown promising results in multimodal content generation and editing but remain largely limited to the image domain. In this work, we present UniVideo, a versatile framework that extends unified modeling to the video domain. UniVideo adopts a dual-stream design, combining a Multimodal Large Language Model (MLLM) for instruction understanding with a Multimodal DiT (MMDiT) for video generation. This design enables accurate interpretation of complex multimodal instructions while preserving visual consistency. Built on this architecture, UniVideo unifies diverse video generation and editing tasks under a single multimodal instruction paradigm and is jointly trained across them. Extensive experiments demonstrate that UniVideo matches or surpasses state-of-the-art task-specific baselines in text/image-to-video generation, in-context video generation and in-context video editing. Notably, the unified design of UniVideo enables two forms of generalization. First, UniVideo supports task composition, such as combining editing with style transfer, by integrating multiple capabilities within a single instruction. Second, even without explicit training on free-form video editing, UniVideo transfers its editing capability from large-scale image editing data to this setting, handling unseen instructions such as green-screening characters or changing materials within a video. Beyond these core capabilities, UniVideo also supports visual-prompt-based video generation, where the MLLM interprets visual prompts and guides the MMDiT during synthesis. To foster future research, we will release our model and code.",
    "keywords": [
      "UniVideo",
      "Video Generation",
      "Video Editing",
      "Multimodal Large Language Model",
      "Unified Modeling"
    ],
    "area": [
      "Multimodal",
      "Generative AI",
      "Computer Vision"
    ],
    "published_time": "2025-10-09T16:01:30.000Z",
    "download_time": "2025-10-10 13:02:27",
    "extra_info": "{\"url\": \"https://huggingface.co/papers/2510.08377\", \"arxiv_url\": \"https://arxiv.org/abs/2510.08377\", \"thumbnail\": \"https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.08377.png\", \"original_title\": \"UniVideo: Unified Understanding, Generation, and Editing for Videos\"}"
  },
  {
    "id": "2510.08540",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2510.08540",
    "title": "MM-HELIX: Boosting Multimodal Long-Chain Reflective Reasoning with Holistic Platform and Adaptive Hybrid Policy Optimization",
    "summary": "While current Multimodal Large Language Models (MLLMs) have demonstrated proficiency in reasoning tasks such as mathematics and logic, their capacity for long-chain reflective reasoning, a prerequisite for solving complex real-world problems, remains largely underexplored. In this work, we first conduct an extensive empirical investigation to evaluate this capability. Leveraging a carefully designed data synthesis engine, we construct MM-HELIX, a multimodal benchmark consisting 1,260 samples of 42 challenging synthetic tasks that require iterative thinking and backtracking. Empirical results on this benchmark reveal that existing MLLMs exhibit significant performance deficits in long-chain reflective reasoning. To address this limitation, we generate post-training data and further explore learning paradigms for exploiting such data. We first develop the Step-Elicited Response Generation pipeline to create MM-HELIX-100K, a large-scale dataset of 100k high-quality, reflective reasoning traces for instruction-tuning stage. Given that standard Reinforcement Learning fails on complex tasks due to sparse reward signals and catastrophic forgetting after Supervised Fine-Tuning, we propose Adaptive Hybrid Policy Optimization (AHPO), a novel training strategy that dynamically unifies offline supervision and online optimization into a single stage. This strategy enables the model to learn from expert data when rewards are sparse and conduct independent exploration once proficient. When applied to the Qwen2.5-VL-7B baseline, our method achieves a +18.6% accuracy improvement on MM-HELIX benchmark and demonstrates strong generalization with a +5.7% average performance gain on general mathematic and logic tasks. Our work demonstrate that reflective reasoning in MLLMs can be effectively learned and generalized, paving the way for developing more capable MLLMs.",
    "keywords": [
      "Multimodal Large Language Models",
      "Reflective Reasoning",
      "Long-Chain Reasoning",
      "Policy Optimization",
      "Instruction Tuning"
    ],
    "area": [
      "Multimodal",
      "Large Language Model",
      "Deep Learning"
    ],
    "published_time": "2025-10-09T17:53:58.000Z",
    "download_time": "2025-10-10 13:02:20",
    "extra_info": "{\"url\": \"https://huggingface.co/papers/2510.08540\", \"arxiv_url\": \"https://arxiv.org/abs/2510.08540\", \"thumbnail\": \"https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.08540.png\", \"original_title\": \"MM-HELIX: Boosting Multimodal Long-Chain Reflective Reasoning with\\n  Holistic Platform and Adaptive Hybrid Policy Optimization\"}"
  },
  {
    "id": "2510.07499",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2510.07499",
    "title": "When Thoughts Meet Facts: Reusable Reasoning for Long-Context LMs",
    "summary": "Recent Long-Context Language Models (LCLMs) can process hundreds of thousands of tokens in a single prompt, enabling new opportunities for knowledge-intensive multi-hop reasoning by integrating large sets of retrieved documents or, in some cases, directly all necessary information. However, simply feeding more documents into the context window fails to capture how evidence should be connected. We address this gap with thought templates, which recast reasoning as reusable thought caches, derived from prior problem solving traces, structuring how evidence is combined and guiding multi-hop inference with factual documents. To keep these templates effective, we propose an update strategy that iteratively refines templates derived from training data through natural-language feedback. Across diverse benchmarks and LCLM families, our approach delivers consistent gains over strong baselines in both retrieval-based and retrieval-free settings. Furthermore, we show that optimized templates can be distilled into smaller open-source models, demonstrating its broad applicability and transparent reasoning reuse. We refer to our framework as Thought Template Augmented LCLMs (ToTAL).",
    "keywords": [
      "Long-Context Language Models",
      "Multi-hop reasoning",
      "Thought templates",
      "Reusable reasoning",
      "Knowledge-intensive reasoning"
    ],
    "area": [
      "Large Language Model",
      "Natural Language Processing",
      "Deep Learning"
    ],
    "published_time": "2025-10-08T19:52:35.000Z",
    "download_time": "2025-10-10 13:02:23",
    "extra_info": "{\"url\": \"https://huggingface.co/papers/2510.07499\", \"arxiv_url\": \"https://arxiv.org/abs/2510.07499\", \"thumbnail\": \"https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.07499.png\", \"original_title\": \"When Thoughts Meet Facts: Reusable Reasoning for Long-Context LMs\"}"
  }
]