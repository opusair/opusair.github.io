[
  {
    "id": "Twitterd727e084-f40d-4373-93c4-24a641d96f51",
    "source": "Twitter",
    "url": "https://x.com/omarsar0/status/1927368367075197179",
    "title": "Agents Basics",
    "content": "Agents Basics It's super simple to create an agent by giving it a description, name, instructions, and tools.",
    "summary": "代理基础知识:创建代理非常简单，只需提供描述、名称、说明和工具。",
    "keywords": "代理,创建,描述,工具,说明",
    "area": "人工智能,多模态,智能体",
    "published_time": "2025-05-27T22:16:00Z",
    "download_time": "2023-10-03 10:56:00",
    "visual_resource": [
      "screenshot/twitter_Twitterd727e084-f40d-4373-93c4-24a641d96f51.png"
    ]
  },
  {
    "id": "Twittercd08f6e0-b7ce-406a-bf37-c7a885e4697f",
    "source": "Twitter",
    "url": "https://x.com/omarsar0/status/1927372457578483828",
    "title": "Handoff",
    "content": "The handoff feature enables agents to call other agents to complete tasks or hand over a conversation mid-action. Handoff enables complex multi-agent orchestration to support even more advanced and capable agentic systems. Lots of great cookbooks and agent examples",
    "summary": "交接功能允许代理在执行任务中途呼叫其他代理完成任务或移交会话。交接还能实现复杂多代理编排,支持更先进和强大的代理系统。",
    "keywords": "交接功能,代理,多代理编排,会话移交,代理系统",
    "area": "多模态,智能体,生成式AI",
    "published_time": "",
    "download_time": "2023-10-11 13:23:45",
    "visual_resource": [
      "screenshot/twitter_Twittercd08f6e0-b7ce-406a-bf37-c7a885e4697f.png"
    ]
  },
  {
    "id": "Twitter0666b196-9aeb-4af9-a4bd-cd879d386b49",
    "source": "Twitter",
    "url": "https://x.com/LangChainAI/status/1927413238733681027",
    "title": "Ready to deploy your own Open Agent Platform (OAP) instance? In our latest video, we show you how to self-host OAP in production—no managed instance required. OAP is an open-source, no-code platform for building, prototyping, and deploying intelligent agents. With its",
    "content": "Ready to deploy your own Open Agent Platform (OAP) instance? In our latest video, we show you how to self-host OAP in production—no managed instance required. OAP is an open-source, no-code platform for building, prototyping, and deploying intelligent agents. With its intuitive web UI, you can: Set up Tools and Supervisor agents out of the box Plug in your own RAG server for domain-specific knowledge Connect to your own MCP server to extend agent capabilities Build and manage custom agents—all in the browser Whether you’re a developer, product manager, or analyst, OAP gives you a full-stack agent platform, powered by LangGraph, with minimal setup. Watch the walkthrough: youtube.com/watch?v=GQCGwn Explore the platform: oap.langchain.com Docs: docs.oap.langchain.com GitHub: github.com/langchain-ai/o",
    "summary": "LangChain最新视频展示如何自托管Open Agent Platform (OAP)以进行生产。OAP是一个开源的无代码平台，适合构建、原型设计和部署智能代理。在直观的Web UI中，您可以设置现成的工具和监督代理，插入自己的RAG服务器以获取特定领域知识，连接到自己的MCP服务器以扩展代理功能，构建和管理自定义代理。平台由LangGraph支持，设置简单。这是一个适合开发者、产品经理和分析师的全栈代理平台。",
    "keywords": "LangChain,Open Agent Platform,智能代理,无代码平台,LangGraph",
    "area": "人工智能,大模型,智能体",
    "published_time": "2025-05-28T01:15:00Z",
    "download_time": "2025-05-28 03:15:00",
    "visual_resource": [
      "screenshot/twitter_Twitter0666b196-9aeb-4af9-a4bd-cd879d386b49.png"
    ]
  },
  {
    "id": "Twitterc0eb231e-1dbc-485a-a660-3d4b04a07428",
    "source": "Twitter",
    "url": "https://x.com/scaling01/status/1926788548155293978",
    "title": "On OpenAI's product strategy - super assistants, their largest competitors and their moats",
    "content": "On OpenAI's product strategy - super assistants, their largest competitors and their moats, based on recently revealed court exhibits. In H1 2025 OpenAI will start evolving ChatGPT into super-assistant, as models like o2 and o3 (now o3 and o4) are finally smart enough to perform agentic tasks. A super-assistant is an intelligent entitiy with T-shaped skills. It has broad skills for tedious daily tasks and deep expertise for tasks that most people find impossible. OpenAI recognizes that \"growth and revenue won't line up forever\", so they need to focus their efforts first on super-assistants to generate enough monetizable demand, to pursue more expensive models in H2. Interestingly, OpenAI sees Meta as their biggest competitor, since Google is at risk of cannibalizing their own core search business (as of Dec 2024).",
    "summary": "OpenAI计划将ChatGPT演变为超级助手，应对主要竞争对手和市场需求。超级助手将具备执行智能任务的能力，整合日常和专业技能。公司预计2025年初通过这种方式提升需求，并在2025年下半年开发更复杂的模型。不同于Google面临的自我产品侵蚀风险，Meta被视为主要竞争者。",
    "keywords": "OpenAI,产品战略,超级助手,竞争对手,智能实体",
    "area": "人工智能,自然语言处理,多模态",
    "published_time": "2025-05-26T07:52:00Z",
    "download_time": "2025-05-14 12:34:56",
    "visual_resource": [
      "screenshot/twitter_Twitterc0eb231e-1dbc-485a-a660-3d4b04a07428.png"
    ]
  },
  {
    "id": "Twitterce921784-5cf7-42ef-be2d-b3dd5a71ef44",
    "source": "Twitter",
    "url": "https://x.com/teortaxesTex/status/1927459880341782700",
    "title": "\"Kicking the Qwen randomly makes it work better\" like old TVs. I'm not reading any of it at this point.",
    "content": "\"kicking the qwen randomly makes it work better\" like old TVs. I'm not reading any of it at this point",
    "summary": "网友指出像老电视一样，用随机刺激可以改善Qwen的表现，但表示对内容失去兴趣。",
    "keywords": "Qwen, 老电视, 随机刺激, 改善表现, 失去兴趣",
    "area": "人工智能, 深度学习, 其他",
    "published_time": "2025-05-14T12:34:56Z",
    "download_time": "2025-05-14 12:34:56",
    "visual_resource": [
      "screenshot/twitter_Twitterce921784-5cf7-42ef-be2d-b3dd5a71ef44.png"
    ]
  },
  {
    "id": "Twitter1ac5dae4-aa58-43db-9c47-ea11235149af",
    "source": "Twitter",
    "url": "https://x.com/lateinteraction/status/1927392900632985694",
    "title": "What I’m trying to say is this conceptual ablation: If X + just about any technique -> huge improvements, for only a limited set of recent base models X, then the discovery is about the class X, not any of the techniques (yet).",
    "content": "What I’m trying to say is this conceptual ablation: If X + just about any technique -> huge improvements, for only a limited set of recent base models X, then the discovery is about the class X, not any of the techniques (yet).",
    "summary": "本文探讨了一种概念性消融：如果将X与几乎任何技术结合，可以在有限的一组最新基础模型X中获得显著提升，那么这种发现是关于X类的，而不是任何具体的技术。",
    "keywords": "概念性消融,技术结合,基础模型,显著提升,发现",
    "area": "机器学习,大模型,其他",
    "published_time": "2025-05-27T23:54:00Z",
    "download_time": "2023-10-07 16:42:38",
    "visual_resource": [
      "screenshot/twitter_Twitter1ac5dae4-aa58-43db-9c47-ea11235149af.png"
    ]
  },
  {
    "id": "Twitter048219eb-7cb5-4492-80a6-92a9f8a251d3",
    "source": "Twitter",
    "url": "https://x.com/scaling01/status/1927418304718623180",
    "title": "Claude 4 Sonnet beating o3-preview on ARC-AGI 2 while being <1/400th of the price",
    "content": "Claude 4 Sonnet beating o3-preview on ARC-AGI 2 while being <1/400th of the price",
    "summary": "Claude 4 Sonnet以低于o3-preview的1/400价格在ARC-AGI 2上表现出色。",
    "keywords": "Claude,Sonnet,o3-preview,ARC-AGI,价格",
    "area": "人工智能,机器学习,大模型",
    "published_time": "2025-05-28T01:35:00Z",
    "download_time": "2025-10-09 13:14:32",
    "visual_resource": [
      "screenshot/twitter_Twitter048219eb-7cb5-4492-80a6-92a9f8a251d3.png"
    ]
  },
  {
    "id": "Twitterffa3d7b1-6647-40f6-9ba3-e799fc38d508",
    "source": "Twitter",
    "url": "https://x.com/cto_junior/status/1926879933957038176",
    "title": "One possible explanation is Claude-4 is really not designed for 0-shotting code it works better in an agentic setup with feedback loop built in to gradually lead to an optimized code",
    "content": "One possible explanation is Claude-4 is really not designed for 0-shotting code it works better in an agentic setup with feedback loop built in to gradually lead to an optimized code",
    "summary": "Claude-4 可能并不适合零样本代码生成，在结合反馈循环的智能体设置中效果更佳，逐渐优化代码。",
    "keywords": "Claude-4,零样本,反馈循环,智能体优化,代码生成",
    "area": "人工智能, 生成式AI, 智能体",
    "published_time": "2025-05-26T13:55:00Z",
    "download_time": "2023-11-29 14:26:01",
    "visual_resource": [
      "screenshot/twitter_Twitterffa3d7b1-6647-40f6-9ba3-e799fc38d508.png"
    ]
  },
  {
    "id": "Twitter383e076d-fc7a-4371-a3dd-784346298e26",
    "source": "Twitter",
    "url": "https://x.com/SakanaAILabs/status/1926798125060002243",
    "title": "Following our Sudoku-based reasoning benchmark announcement, we've been evaluating the latest models to track improvements in their reasoning capabilities. Today, we’re launching the Sudoku-Bench Leaderboard",
    "content": "Following our Sudoku-based reasoning benchmark announcement, we've been evaluating the latest models to track improvements in their reasoning capabilities. Today, we’re launching the Sudoku-Bench Leaderboard: pub.sakana.ai/sudoku/ New technical report: arxiv.org/abs/2505.16135 You can now track new model progress on our live Leaderboard. Of the models we’ve benchmarked so far: OpenAI’s o3 Mini High leads overall. Interestingly, Gemini 2.5 Pro does better on the harder 6x6 puzzles! However, o3 is the only model that solves any of the 9x9 Sudokus, but only 2.9% and only the vanilla Sudoku’s. Crucially, NO model tested can yet conquer 9x9s requiring strong, creative reasoning. This benchmark remains a grand challenge! For a deeper dive into the benchmark, methodology, and our findings, check out our technical report. Want to test a model on Sudoku-Bench? It's simple! Visit the leaderboard. Choose a puzzle. We generate a prompt (puzzle + instructions) to paste into any model. Explore sample reasoning traces from our tests too!",
    "summary": "我们推出了Sudoku-Bench排名榜，可以跟踪最新模型在推理能力上的进展。OpenAI的o3 Mini High在整体上领先，而Gemini 2.5 Pro在较难的6x6谜题中表现更好。然而，没有任何模型能够成功解决需要强大创意推理的9x9谜题，这仍是一个巨大挑战。",
    "keywords": "Sudoku-Bench,推理能力,OpenAI,o3 Mini High,Gemini 2.5 Pro",
    "area": "人工智能,多模态,生成式AI",
    "published_time": "2025-05-26T08:30:00Z",
    "download_time": "2023-10-08 07:48:35",
    "visual_resource": [
      "screenshot/twitter_Twitter383e076d-fc7a-4371-a3dd-784346298e26.png"
    ]
  },
  {
    "id": "Twitter7ec69832-3598-432f-899e-e43487de5037",
    "source": "Twitter",
    "url": "https://x.com/_lewtun/status/1927043160275923158",
    "title": "Happy to share 💭 Mixture of Thoughts 💭",
    "content": "Happy to share 💭 Mixture of Thoughts 💭 A curated, general reasoning dataset that trims down over 1M samples from public datasets to ~350k through an extensive set of ablations 🧑‍🍳 Models trained on this mix match or exceed the performance of DeepSeek's distilled models -- not just on math/code but also on scientific benchmarks like GPQA We also validate that the \"additive\" methodology from Phi-4-reasoning really works! You can optimise the data mixture independently per reasoning domain and then bring it all together for the final run 🔥 Link to the dataset ⤵️",
    "summary": "分享了一种叫做\"思维混合\"的通用推理数据集，通过广泛的消融研究将100多万个样本精简到约35万。训练在此混合数据上的模型不仅在数学/代码方面，而且在GPQA等科学基准测试中，与DeepSeek的蒸馏模型匹配或超过其性能。验证了Phi-4推理中的\"附加\"方法确实有效。数据混合可以根据每个推理领域独立优化，然后汇总进行最终运行。",
    "keywords": "通用推理,深度学习,DeepSeek,数据集,科学基准",
    "area": "人工智能,机器学习,大模型",
    "published_time": "2025-05-27T00:44:00Z",
    "download_time": "2023-11-03 10:00:00",
    "visual_resource": [
      "screenshot/twitter_Twitter7ec69832-3598-432f-899e-e43487de5037.png"
    ]
  },
  {
    "id": "Twitter8e30306c-7c1a-4311-b78e-8d5bd35d5b54",
    "source": "Twitter",
    "url": "https://x.com/GoogleDeepMind/status/1927375853551235160",
    "title": "We're thrilled to announce SignGemma, our most capable model for translating sign language into spoken text.",
    "content": "We're thrilled to announce SignGemma, our most capable model for translating sign language into spoken text.\n🧏\nThis open model is coming to the Gemma model family later this year, opening up new possibilities for inclusive tech. Share your feedback and interest in early testing → goo.gle/SignGemma",
    "summary": "谷歌深度思维团队公布了他们最新的手语翻译模型SignGemma，这一开放模型即将加入Gemma模型家族，旨在为包容性技术带来新的可能性。",
    "keywords": "手语,翻译模型,SignGemma,包容性,技术",
    "area": "人工智能,自然语言处理,多模态",
    "published_time": "2025-05-27T22:46:00Z",
    "download_time": "2023-10-27 14:56:00",
    "visual_resource": [
      "screenshot/twitter_Twitter8e30306c-7c1a-4311-b78e-8d5bd35d5b54.png"
    ]
  },
  {
    "id": "Twitter2e898284-7745-4b4b-8030-b7daa6678457",
    "source": "Twitter",
    "url": "https://x.com/c_valenzuelab/status/1927149229966766373",
    "title": "Ensure models have infinite use cases",
    "content": "This is pretty wild. We wanted to ensure our models have infinite use cases that are less prescriptive and linear than the simplistic \"text-to-X\" approach. Which means that are still plenty of uses cases we have not yet discovered. Gen-4 and References feel like a step toward universality.",
    "summary": "这项努力是为了确保我们的模型具有无穷的使用场景，这些场景比简单的\"text-to-X\"方法更具创新性和包容性。虽然我们还没有发掘出所有可能性，但Gen-4和参考文献是朝着普适化的一步。",
    "keywords": "模型,使用场景,创新性,包容性,普适化",
    "area": "人工智能,多模态,生成式AI",
    "published_time": "2025-05-27T07:45:00Z",
    "download_time": "2023-10-02 14:30:00",
    "visual_resource": [
      "screenshot/twitter_Twitter2e898284-7745-4b4b-8030-b7daa6678457.png"
    ]
  },
  {
    "id": "Twitter395ee417-8271-45cb-a90a-f0e2e1ea560f",
    "source": "Twitter",
    "url": "https://x.com/TheTuringPost/status/1927123359969468420",
    "title": "A new recipe for training multimodal models",
    "content": "A new recipe for training multimodal models 👉 Mixed together various data types: text next to images, video frames after captions, then webpages, etc. This way the model learns to connect what it reads with what it sees. ByteDance proposed and implemented this idea in their BAGEL, a new open-source multimodal model. Here's how it works:",
    "summary": "一个新的多模态模型训练方法被提出，通过结合文本、图像、视频帧等多种数据类型，模型可以学会连接阅读与视觉。此想法由字节跳动提出并在其开源多模态模型BAGEL中实现。",
    "keywords": "多模态模型,字节跳动,BAGEL,数据整合,模型训练",
    "area": "多模态,深度学习,自然语言处理",
    "published_time": "6:03 AM · May 27, 2025",
    "download_time": "2023-10-02 10:00:00",
    "visual_resource": [
      "screenshot/twitter_Twitter395ee417-8271-45cb-a90a-f0e2e1ea560f.png"
    ]
  },
  {
    "id": "Twitter147bc4e1-87bd-48b5-9092-2eea33f11d52",
    "source": "Twitter",
    "url": "https://x.com/mervenoyann/status/1926987808360509636",
    "title": "X",
    "content": "what happened in open AI past week? so many vision LM & omni releases\nhere's our picks\nmultimodal\n > new moondream (VLM) is out: it's 4-bit quantized (with QAT) version of moondream-2b, runs on 2.5GB VRAM at 184 tps with only 0.6% drop in accuracy (OS)\n > ByteDance released BAGEL-7B, an omni model that understands and generates both image + text. they also released Dolphin, a document parsing VLM\nThe tweet is truncated. To view the full content, please visit the tweet URL.",
    "summary": "最近一周，Open AI 发布了多个视觉语言模型和全能模型的新版本。其中，MoonDream 推出了经过 QAT 4-bit 量化的 VLM，仅在 184 tps 下就能在 2.5GB VRAM 上运行，精确度仅下降 0.6%。同时，字节跳动发布了 BAGEL-7B，可以理解和生成图文内容，还推出了用于文档解析的 Dolphin VLM。",
    "keywords": "Open AI,视觉语言模型,全能模型,ByteDance,VLM",
    "area": "多模态,大模型,自然语言处理",
    "published_time": "2025-05-26T21:04:00Z",
    "download_time": "2023-10-04 15:26:34",
    "visual_resource": [
      "screenshot/twitter_Twitter147bc4e1-87bd-48b5-9092-2eea33f11d52.png"
    ]
  },
  {
    "id": "2CuZyE4YMs7xD8HK7cf5xQ",
    "source": "wechat",
    "url": "https://mp.weixin.qq.com/s/2CuZyE4YMs7xD8HK7cf5xQ",
    "title": "大模型玩不好数独？！Transformer作者初创公司公布排行榜：o3 Mini High“变异数独”正确率仅2.9%",
    "summary": "由Transformer作者Llion Jones创立的Sakana AI公司，发布了AI数独能力基准测试Sudoku-Bench，旨在评估大模型的创造性推理能力。测试结果揭示，大模型整体数独正确率仅15%，在更具挑战性的9x9变异数独中，即使是高性能模型o3 Mini High，正确率也仅有2.9%。这凸显了当前大模型普遍存在的“记忆依赖症”缺陷，即它们倾向于记忆而非真正进行逻辑推理。该基准通过引入无法依靠记忆解决的“变异数独”，为促进AI推理能力的实质性提升提供了新方向，NVIDIA CEO黄仁勋亦肯定此类谜题对提升AI推理能力的重要性。",
    "keywords": [
      "大模型",
      "数独",
      "推理能力",
      "Sudoku-Bench",
      "SakanaAI",
      "变异数独",
      "Transformer作者",
      "记忆依赖症"
    ],
    "area": [
      "人工智能",
      "大模型",
      "机器学习"
    ],
    "content": "标题：大模型玩不好数独？！Transformer作者初创公司公布排行榜：o3 Mini High“变异数独”正确率仅2.9%\n公众号：量子位\n--------------------------------------------------\n\n大模型做数独，总体正确率只有15%？？？\n\n继出场自带十篇完整学术论文的史上首个“AI科学家”之后，Transformer作者Llion Jones又带着他的创业公司Sakana AI来搞事情了。\n\n这次，Sakana AI公布了一个AI模型解决数独问题能力的排行榜。\n\n问题集是该公司推出的全新基准Sudoku-Bench，包含了从简单的4x4到复杂的9x9现代数独问题，旨在考验大模型创造性推理能力。\n\n榜单显示，大模型不仅总体正确率只有15%，在9×9的现代数独中，即使是高性能模型o3 Mini High，正确率也只有2.9%。\n\nSudoku-Bench项目在2025NVIDIA GTC开发者大会上进行了展示。\n\nNVIDIA首席执行官黄仁勋对此评价：\n\n像数独这样的谜题将有助于提高AI的推理能力。\n\nSudoku-Bench是Sakana AI在今年3月发布的一项由不同难度级别的数独谜题组成的基准测试，用于衡量人工智能的多层次和创造性推理能力。\n\n1、现有问题：大模型的 “记忆依赖症”\n\n目前大多数推理基准测试存在一个缺陷：大模型往往通过记忆标准答案或固定模式来完成任务，而不是真正运用逻辑推理能力。\n\n当遇到与训练数据中 “类似” 的问题时，模型会直接套用记忆中的解决方案，而非通过逻辑推导得出答案。\n\n对于全新规则或未见过的模式，模型往往无法有效应对，因为缺乏可直接匹配的记忆模板。\n\n传统数独游戏对大模型来说可能已经 “太简单”，它们可能只是记住了套路，而不是学会如何创造性地解决新问题。\n\n2、解决方案：Sudoku-Bench用 “变异数独” 考倒大模型\n\n近年来，各种各样具有独特规则的衍生谜题出现。\n\n这些“变异数独”谜题需要多步骤和创造性的推理技巧，但只有一个正确答案，特点是无法通过记忆解决，必须通过多步逻辑推理找到 “突破口”。\n\n这些特点使得“变异数独”成为测试AI推理能力的理想选择。\n\n以下就是一个“变异数独”示例，你不仅需要遵循原始规则，而且沿着彩色线条排列的数字还需要遵循额外的规则。\n\nSudoku-Bench基准包括传统和现代数独（变异数独）问题，难度分级，从当前模型可以解决的简单问题到甚至最先进的推理模型也无法处理的极其困难的问题。\n\nSudoku-Bench还包含了由Nikoli（日本著名的数独公司，数独正是其名称的由来）提供的100道手工数独题。\n\n3、大模型的 “惨败”：基线实验结果\n\n在今年3月该基准发布后，研究人员测试了多个AI模型，包括Gemini 2.5 Pro、GPT-4.1、Claude 3.7等在内的最先进大模型。\n\n为了给模型一个公平的机会，团队为模型提供了部分完成的谜题，并评估它们完成谜题的能力。\n\n结果显示，一些模型在这种辅助下表现得相当不错，但关键结果在于最后两列。\n\n即使是最先进的模型，平均连一个正确的数字都放不下，而OpenAI最新的推理模型ChatGPT o3是唯一能够解决基准测试中所有谜题的模型。\n\n最新的排行榜显示：\n\n测试团队详细列出了模型在每个谜题上的表现，感兴趣的朋友可戳文末链接查看～\n\nSakana AI由前谷歌研究人员Llion Jones（Transformer作者之一）和David Ha于2023 年7月在东京成立，主要对生成文本和图像的AI基本模型进行研究。\n\n此前，该公司开源发布了AI科学家和AI审稿人，前者一出场就独自完成了十篇完整的学术论文，包括但不限于扩散模型方向、Transformer与强化学习等，引起了不小的轰动。\n\n后者能对AI写的论文进行评审，提供改进意见，主打“以我之矛攻我之盾”。\n\n该公司还发布了一种名为“连续思维机器 (CTM)”的新型AI模型，通过像人类一样“逐步”思考并学习世界的内部模型，超越了简单的模式识别，并获得了逐步解决迷宫等复杂问题的能力。\n\nSakana AI还与Cracking The Cryptic（YouTube 上最大的谜题评论频道之一）合作，Cracking The Cryptic每天都会演示一些世界上最好的数独谜题的逻辑解决方案。\n\nSakana AI获得了这些视频的文字记录以及答题过程中采取的行动数据。这些数据可以作为训练AI推理模型的理想数据，并与Sudoku-Bench一起发布。\n\n著名的数独出题人Marty Sears还为Sakana AI定制了一款名为“奇偶鱼”的数独游戏：沿着Sakana AI红色标志线相邻的任何数字都必须包含一个偶数和一个奇数。\n\n感兴趣的朋友可以尝试一下（解答过程已附在文末）～\n\n技术报告：https://arxiv.org/abs/2505.16135排行榜：https://pub.sakana.ai/sudoku/Github：https://github.com/SakanaAI/Sudoku-Bench奇偶鱼题目：https://sudokupad.app/wsj7iunsg6解答过程：https://www.youtube.com/watch?v=JdHSSNKuIzU参考链接：[1]https://x.com/SakanaAILabs/status/1926905826465161629[2]https://sakana.ai/sudoku-bench/\n\n— 完 —\n\n📪 量子位AI主题策划正在征集中！欢迎参与专题365行AI落地方案，一千零一个AI应用，或与我们分享你在寻找的AI产品，或发现的AI新动向。\n\n💬 也欢迎你加入量子位每日AI交流群，一起来畅聊AI吧～\n\n一键关注 👇 点亮星标\n\n一键三连「点赞」「转发」「小心心」\n\n欢迎在评论区留下你的想法！",
    "published_time": "2025-05-28T04:23:13.000Z",
    "download_time": "2025-05-30T00:28:47.698150",
    "visual_resource": [
      "screenshot/wechat_wx_bbaaa987.jpg"
    ],
    "meta-data": "{\"original_metadata\": {\"date_modified\": \"2025-05-28T04:23:13.000Z\", \"image\": \"https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtAHkwSrvicgK1yjPVBOuCG2fPpys2kE35ctegAwrfibERAZ5icoA65PQuCEGMH9B4X0yVyYZlP5f4ueA/0?wx_fmt=jpeg\", \"id\": \"2CuZyE4YMs7xD8HK7cf5xQ\"}, \"extraction_info\": {\"account\": \"量子位\", \"file_path\": \"./database/content/wechat/2CuZyE4YMs7xD8HK7cf5xQ.txt\"}}"
  },
  {
    "id": "pC84-TMj94gb5n5PpaDolg",
    "source": "wechat",
    "url": "https://mp.weixin.qq.com/s/pC84-TMj94gb5n5PpaDolg",
    "title": "Claude 4破解困扰人类4年系统bug，30年码龄程序员200小时没搞定，GPT-4.1/Gemini-2.5也做不到",
    "summary": "Anthropic旗舰大模型Claude Opus 4成功破解了一个困扰资深C++程序员长达四年、耗时200小时未解的复杂系统顽固性bug，而此前GPT-4.1和Gemini-2.5等模型均未能解决。这位拥有30年开发经验的程序员在33个prompt和一次重启后，Claude Opus 4便清晰定位并提供了解决方案。此次事件凸显了Claude 4系列模型在编程和推理能力上的显著提升，特别是其Code模式作为智能代码助手，可高效处理代码重构、bug修复等工程任务，展示了AI在复杂软件开发领域日益强大的辅助与问题解决潜力，预示着AI辅助编程的未来趋势。",
    "keywords": [
      "ClaudeOpus4",
      "bug修复",
      "大模型",
      "编程能力",
      "AI辅助编程",
      "代码重构",
      "生成式AI"
    ],
    "area": [
      "人工智能",
      "大模型",
      "生成式AI"
    ],
    "content": "标题：Claude 4破解困扰人类4年系统bug，30年码龄程序员200小时没搞定，GPT-4.1/Gemini-2.5也做不到\n公众号：量子位\n--------------------------------------------------\n\n30年码龄程序员4年都没搞定的bug，Claude Opus 4只用几个小时轻松破解了。\n\n全程只需30个prompt+1次重启。\n\n而人类在过去4年花了至少200个小时，都没找到这个bug在哪。\n\n一位资深C++程序员的分享，最近火了。\n\n要知道，他曾在FAANG（指Meta、亚马逊、苹果、奈飞、谷歌硅谷五巨头）担任工程师，如今也是团队中“定海神针”一样的人物。\n\n这个bug不仅困扰他，包括GPT-4.1、Gemini-2.5以及Claude-3.7也找不到。\n\n有围观的程序员表示，这种剧情他也经历过！\n\n一个月没解决的bug，用o1-Pro十分钟就搞定了。\n\nAnthropic的开发者关系主管也留言表示，这样的故事可能会越来越常见。\n\n故事的主角名叫ShelZuuz。\n\n这位老哥自称有30年C++开发经验，在目前的团队里承担“技术支援”的角色，大家卡了一周的问题，他当场就能解决。\n\n从他在Reddit上的资料来看，这些介绍应该不是吹水，他7年来发布的帖子都是和hacker、硬件等相关。\n\n然鹅大佬也有解决不了的难题。\n\n4年前，因为一次设计6万行代码的大规模重构，系统里突然出现了一个bug：在一个特定shader（着色器）被特定使用方式下，出现了一个边界条件下的问题。\n\n大概就是在一种非常特殊的组合条件下才会触发渲染错误，平时难以察觉，但只要触发就会出错，属于典型的顽固型bug。\n\nShelZuuz老哥表示，这个bug业务优先级不那么高，但也很烦人。在系统没有重构前，这个bug并不存在。\n\n过去几年里，他一直在尝试解决这个问题，零零碎碎花了有200个小时时间，都没能定位和修复它。\n\n因此，他把这个bug称为“白鲸bug”。\n\n这是参考了文学作品《白鲸》中，哈克船长执着半生都在追逐一头行动诡异的白鲸。\n\n这不，最近Claude Opus 4发布了么，老哥就想着用它试试看。\n\n结果配合着Claude Code模式，只用几个小时，这个bug就被解决了。\n\nClaude Opus 4不仅提供了系统重构前后的完整代码，并且明确说明了为什么在新架构下会出问题：\n\n定位bug全程只用了33个提示词（大概几个小时）、外加一次重启。\n\n老哥表示，他之前尝试过GPT-4.1、Gemini 2.5、Claude 3.7等高级AI模型，但这些模型都没能找到头绪，Opus 4是第一个成功定位问题的。\n\n有人就简单算了笔账：这样级别的工程师，200小时工时费2.5万美元起步，而Claude订阅费只要200美元（doge）。\n\n也有人补充说，这个结果一定程度上也取决于提示词的质量，但不得不承认Claude在编程方面真的很强。\n\n就在上周，Claude 4系列上新，其中Claude Opus 4是旗舰款。\n\n从官方发布中可以明显感知到，Claude系列正在猛猛提升自己的编程和推理能力。\n\n展示能力的方式都变成了连续24小时畅玩宝可梦、独立运行并持续编码7小时……\n\n同时还发布了Claude Code，也就是前面ShelZuuz用到的能力。\n\n这个智能代码助手可以帮助开发者通过自然语言命令理解、浏览和修改整个代码库，让你能够将修复bug、实现新功能、代码重构、编写测试、跨文件修改等大量工程任务交给AI完成。\n\n发布几天时间里，全球的开发者们都在尝试用Claude 4解决各种编程代码问题。\n\n当然也衍生了一些有趣的玩法，比如让它用ASCII来张自画像。\n\n嗯……怎么有点ET的感觉？\n\n参考链接：\n\n[1]https://www.reddit.com/r/ClaudeAI/comments/1kvgg7s/claude_opus_solved_my_white_whale_bug_today_that/?share_id=-Y9J9Hna8rIemyMsG8Jp9&utm_content=1&utm_medium=ios_app&utm_name=ioscss&utm_source=share&utm_term=1[2]https://x.com/deedydas/status/1927188036560760844\n\n— 完 —\n\n📪 量子位AI主题策划正在征集中！欢迎参与专题365行AI落地方案，一千零一个AI应用，或与我们分享你在寻找的AI产品，或发现的AI新动向。\n\n💬 也欢迎你加入量子位每日AI交流群，一起来畅聊AI吧～\n\n一键关注 👇 点亮星标\n\n一键三连「点赞」「转发」「小心心」\n\n欢迎在评论区留下你的想法！",
    "published_time": "2025-05-28T04:23:13.000Z",
    "download_time": "2025-05-30T00:28:59.412368",
    "visual_resource": [
      "screenshot/wechat_wx_ba2d50c1.jpg"
    ],
    "meta-data": "{\"original_metadata\": {\"date_modified\": \"2025-05-28T04:23:13.000Z\", \"image\": \"https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtByts5aLdmL34037Zsk2h6Jeh0rHXK5PIteEOPFGDI8tteia9wNqmdTZq69BsuLzLUySFlakM1iaU0w/0?wx_fmt=jpeg\", \"id\": \"pC84-TMj94gb5n5PpaDolg\"}, \"extraction_info\": {\"account\": \"量子位\", \"file_path\": \"./database/content/wechat/pC84-TMj94gb5n5PpaDolg.txt\"}}"
  },
  {
    "id": "qcGrNjIqU1cLSg_31wijJg",
    "source": "wechat",
    "url": "https://mp.weixin.qq.com/s/qcGrNjIqU1cLSg_31wijJg",
    "title": "一个省略号提示+强化学习搞定大模型“过度思考”，中科院自动化所新方法：从强制推理到自主选择",
    "summary": "中科院自动化研究所与鹏城实验室联合提出AutoThink新方法，旨在解决大语言模型“过度思考”问题。该方法通过在提示词中加入省略号，并结合三阶段强化学习，赋予大模型自主决定何时以及如何深度思考的能力，使其能根据题目难度动态切换思考模式，实现“按需思考”。实验结果显示，AutoThink不仅能有效提升模型在复杂任务上的准确率，同时大幅减少Token消耗，显著提高推理效率，并已集成至ScienceOne平台。此创新范式为大模型实现性能与算力的双重优化提供了新思路，推动了模型向更智能、更经济的通用智能方向发展。",
    "keywords": [
      "大语言模型",
      "过度思考",
      "强化学习",
      "AutoThink",
      "推理优化",
      "Token效率",
      "任务感知",
      "省略号提示"
    ],
    "area": [
      "大模型",
      "自然语言处理",
      "强化学习"
    ],
    "content": "标题：一个省略号提示+强化学习搞定大模型“过度思考”，中科院自动化所新方法：从强制推理到自主选择\n公众号：量子位\n--------------------------------------------------\n\n在日益强调“思维能力”的大语言模型时代，如何让模型在“难”的问题上展开推理，而不是无差别地“想个不停”，成为当前智能推理研究的重要课题。\n\n中国科学院自动化研究所联合鹏城实验室提出了一种高效的推理策略，赋予推理大模型根据题目难度自主切换思考模式的能力：\n\n通过一个小小的省略号作为提示词 + 多阶段强化学习，引导大模型自主决定是否深度思考、思考多少。\n\n在大语言模型快速发展的今天，越来越多的模型开始具备“深度思考能力”。\n\n比如，DeepSeek-R1系列模型引入了一种特别的提示结构：先<think> ，再<answer>。也就是说，模型在回答之前会“思考”一番，生成一整段包含反复自我反思、自我验证的逻辑推理，然后才给出结论[1]。这种方式是近来提升模型准确率的重要方法。“深度思考”的确带来了好处，模型不再“张口就答”，而是会分析、论证、验证；在复杂问题中，能显著提升答对率，避免“拍脑袋”行为。但是，如果问题本身很简单，模型还有必要“苦思冥想”一大段吗？\n\n答案是：未必。事实上很多情况下，模型在解决简单任务时也会机械地生成一大堆推理语句。这就好比你问一个人“2+3等于几”，他却要从自然数定义讲起，列出加法交换律，甚至反复试错，最后才告诉你答案是5。这种现象称为过度思考（Overthinking）。\n\n过度思考问题在DeepSeek-R1、Claude 3.7、Qwen3等推理模型中广泛存在。尤其是当prompt总是强制模型使用<think>标签时，它就会默认开启“深度思考模式”，不论问题简单或复杂，推理过程长度极长，带来了响应延迟和计算成本上升；甚至在冗余思考中“越想越错”，反而降低了准确率。\n\n目标：教会模型学会「什么时候该思考」\n\n团队认为，推理过程的存在不该是“硬规定”，而应该因题制宜。就像人类一样：面对简单问题能立刻给出答案；面对复杂问题才会进行详细推理与分析。那么，大模型能不能也具备这样的“任务感知能力”？能不能学会自己判断：这道题该不该思考，该思考多少？\n\n这是AutoThink背后的初衷。AutoThink 不再让模型“永远思考”，而是训练它——学会何时该思考，何时可以跳过思考，甚至决定思考多少。\n\n团队提出了一个简单而有效的方案，叫做AutoThink。它有两核心个关键词：\n\n通过这两者的结合让模型具备了类似人类的“任务感知能力”：简单问题不浪费思考，复杂问题多加推理，真正做到“按需思考”，如图1所示。相比之下，传统方法要么手动控制思考模型[2]，要么不区分题目难度地压缩推理过程[3]。\n\n实现Autothink的第一步，其实很简单：只需要在原有的prompt里，加入一个省略号 “…”，模型就会自行决定是否进行推理。\n\n举个例子：\n\n<think> Okay, I have finished thinking. →总是跳过深度思考\n\n实验发现，“省略号提示词”在没有任何训练的情况下，已经能激发出两种模式的随机共存，有些题目模型会写出完整思考，有些则会直接给出简洁的参考答案，如图2(a)所示。用“省略号提示词”进行推理的平均准确率和推理长度都介于标准提示和不思考提示之间。这种“隐式控制”行为打开了一扇门——模型已经有潜力学会“选择是否思考”，只需要再稍作引导。\n\n虽然加入 “…” 可以让模型切换推理模式，但模型并不会根据题目的难易程度来自主选择。也就是说，它可能对简单题深度推理，对难题却直接跳过思考。这种随机行为仍然缺乏任务感知能力。如图2b (上)所示。使用省略号提示后，模型在不同难度题目上“跳过思考”的比例分布相对平坦。这说明，虽然省略号提示可以开启“是否思考”的能力，但不能赋予模型“知道何时该思考”的智慧。\n\n为了教会模型自主思考，团队设计了一个三阶段的强化学习策略，从最基础的模式稳定，到行为优化，再到推理剪枝。经过训练后，模型的思考模式变化成图2b (下) 那样：模型不再“随缘”地决定是否思考，而是展现出更符合人类直觉的行为模式：在难度较高的问题上，模型更倾向于进入思考模式；而在容易的问题上，则更愿意跳过思考、直接作答。\n\n团队采用GRPO的强化学习方法。为了鼓励模型尽可能在不思考的前提下答对题目，首先设计了一个基础奖励函数 (naive reward)，在答对的前提下“不思考”奖励最高（+2），答错且不思考惩罚最重（-1），体现了“能不想还答对最好，答错就该罚”的原则。\n\n阶段一：防止模式坍缩，稳定思考行为\n\n尽管上述naive reward优雅，但依照基础奖励函数训练的模型可能倾向于“全都思考”或“全都不思考”——这都是不健康的行为。例如，如果模型发现“都不思考”能更快提升平均奖励，就会彻底放弃思考！\n\n为解决这个问题，加一层动态调节机制，根据整个训练过程中每个batch里的思考和不思考的比例，调整每条数据的奖励。这个阶段调整奖励函数如下：\n\n阶段二：在两种模式下分别优化准确率\n\n在稳定模型思考与否的行为后，解除第一阶段的束缚，让模型自由选择是否思考。此时的奖励与 naive reward 一致。这个阶段的目标是放任模型自由发展，鼓励模型对于当前无法解决的问题使用思考模式深度探究，对于已经能够解决的问题使用不思考模式简洁回答。在这个阶段，往往会观察到伴随着训练准确率的提升，不思考和思考的回答长度均上升。\n\n阶段三：在基于响应长度奖励，引导“简洁推理”\n\n虽然第二阶段帮助模型提升了准确率，但也带来一个副作用——推理过程变得越来越长。模型在没有限制的情况下，容易“滔滔不绝”，输出一大段冗长推理。因此，在阶段三引入了一个“长度感知奖励机制” [4]，简单来说，把一个 GRPO Group 的回答分为正确和错误的两组，对于回答正确的组，惩罚没必要的长回答；对于回答错误的组，鼓励简洁作答：\n\n这个阶段在尽可能小地牺牲模型性能的情况下，压缩模型的输出长度，并最终得到一个简洁的、具有针对题目难度自主思考的模型。\n\n为便于理解理解奖励的变化选一个例子可视化了阶段一（左）和阶段三（右）的四个模态的回答的奖励函数情况。\n\n在多个数学Benchmark 和多个R1-Style的基础模型上验证了 AutoThink。\n\n实验结果显示：AutoThink 不仅能提升基模的性能，同时大幅减少了推理时的Token消耗，如表1所示。相比之下，大部分的开源模型的性能增强的代价是推理长度（思考过程）的成倍增长；而简洁思考的模型性能往往相比于基础模型几乎无提升甚至下降。特别地：在已经经过大量RL后训练的DeepScaleR[5]上，AutoThink依然能节省额外10%的Token消耗。\n\n消融实验：三阶段到底有没有用？\n\n为了验证AutoThink多阶段训练设计的必要性，专门设计了两个关键的消融实验。\n\n一方面，移除阶段一中的批次平衡奖励，观察模型是否还能维持“思考”与“不思考”的动态共存；另一方面，尝试直接跳过阶段二，仅保留初始与最终阶段，测试是否还能实现高效推理与准确率提升。\n\n如图4所示，实验结果表明：阶段一的batch奖励平衡是防止模式坍缩、维持推理多样性的关键机制，而跳过阶段二会导致准确率停滞，削弱后续阶段的推理剪枝效果。这验证了三阶段训练方案在稳定性与性能提升上的协同必要性。\n\n除了提升准确率和节省token，也从更细致的角度，去理解AutoThink在推理过程中到底发生了什么变化。通过以下三个维度的分析，发现AutoThink并不是“简单粗暴地省略推理”，而是在做有策略的思考选择。\n\n关键词频率分析：不思考 ≠ 胡说八道\n\n统计推理过程中常见的关键词，比如 “Calculate”, “Result”, “Check”等，它们通常用于表达模型的中间推理步骤。结果发现：即使在“不思考模式”下，AutoThink依然频繁使用这类词语。如图5(左)所示，这表明它并非“跳过推理直接乱猜”，而是在内部快速做出判断后，简洁地表达结果。\n\n行为与难度匹配：越难越思考，越简单越跳过\n\n将测试数据按难度划分，并观察AutoThink在不同难度上的“思考比例”。如图5 (右) 所示，结果表明：经AutoThink训练后，模型更倾向于在简单题（如Math）上快速给出答案，而在复杂题上主动开启推理模式，分配更多的推理 token。\n\n我们进一步选取了三个代表性问题，比较AutoThink在不同提示和模式下的表现。如图6-8所示，在不同难度上AutoThink展现出灵活的、根据题目难度自适应的自主思考行为。\n\nAutoThink 提供了一种简单而有效的推理新范式：通过省略号提示配合三阶段强化学习，引导模型不再“逢题必思”，而是根据问题难度自主决定是否思考、思考多少。在多个数学数据集上，AutoThink 实现了优异的准确率–效率平衡，既提升性能，又节省算力，展示出强的适应性和实用性。该研究成果也集成于一站式智能科研平台ScienceOne，并将用于训练ScienceOne的基座大模型S1-Base。\n\n局限与展望\n\n当然，AutoThink 还不是完美的，也能观察到：\n\n这些问题是后续工作的重点方向，团队相信，让大模型“更聪明地思考、更简洁地表达”，是未来通用智能演进的重要一步。\n\n论文地址：https://arxiv.org/abs/2505.10832代码仓库：https://github.com/ScienceOne-AI/AutoThink模型地址：https://huggingface.co/collections/SONGJUNTU/autothink-682624e1466651b08055b479\n\n参考文献[1] Daya Guo, Dejian Yang, Haowei Zhang, Junxiao Song, Ruoyu Zhang, Runxin Xu, Qihao Zhu,Shirong Ma, Peiyi Wang, Xiao Bi, et al. Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning. arXiv preprint arXiv:2501.12948, 2025.[2] Wenjie Ma, Jingxuan He, Charlie Snell, Tyler Griggs, Sewon Min, and Matei Zaharia. Reasoning models can be effective without thinking. arXiv preprint arXiv:2504.09858, 2025.[3] Bairu Hou, Yang Zhang, Jiabao Ji, Yujian Liu, Kaizhi Qian, Jacob Andreas, and Shiyu Chang.Thinkprune: Pruning long chain-of-thought of llms via reinforcement learning. arXiv preprintarXiv:2504.01296, 2025.[4] Jixiao Zhang and Chunsheng Zuo. Grpo-lead: A difficulty-aware reinforcement learningapproach for concise mathematical reasoning in language models. arXiv preprintarXiv:2504.09696, 2025.[5] Michael Luo, Sijun Tan, Justin Wong, Xiaoxiang Shi, William Y. Tang, Manan Roongta, ColinCai, Jeffrey Luo, Li Erran Li, Raluca Ada Popa, and Ion Stoica. Deepscaler: Surpassingo1-preview with a 1.5b model by scaling rl, 2025. Notion Blog.\n\n一键三连「点赞」「转发」「小心心」\n\n欢迎在评论区留下你的想法！\n\n— 完 —\n\n🌟 点亮星标 🌟",
    "published_time": "2025-05-28T04:23:13.000Z",
    "download_time": "2025-05-30T00:29:09.851460",
    "visual_resource": [
      "screenshot/wechat_wx_438670d1.jpg"
    ],
    "meta-data": "{\"original_metadata\": {\"date_modified\": \"2025-05-28T04:23:13.000Z\", \"image\": \"https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtBHYQjMiappg4LGkN8wRtPFmWuXTHcWbOcGrQugicwyB9rV5naXFicWp1ryNicFQTfgmfkxxr48zbnVbw/0?wx_fmt=jpeg\", \"id\": \"qcGrNjIqU1cLSg_31wijJg\"}, \"extraction_info\": {\"account\": \"量子位\", \"file_path\": \"./database/content/wechat/qcGrNjIqU1cLSg_31wijJg.txt\"}}"
  },
  {
    "id": "tukh12k0iG-b3WbysI_15w",
    "source": "wechat",
    "url": "https://mp.weixin.qq.com/s/tukh12k0iG-b3WbysI_15w",
    "title": "阿里通义发布并行计算新策略：1.6B等效4.4B，内存消耗骤降95%",
    "summary": "阿里通义团队提出大模型（LLM）“计算缩放”新范式PARSCALE，旨在在不显著增加内存与时间成本的前提下，提升模型能力。该策略受CFG（无分类器引导）启发，将并行计算从生成阶段扩展至训练与推理全流程，通过P条可学习并行路径、差异化输入变换与动态聚合实现。PARSCALE使得1.6B模型性能可接近4.4B模型，但内存占用仅为后者1/22，并可直接应用于现有模型，显著降低训练成本。其突破了传统参数或推理时间扩展瓶颈，为大模型的高效发展提供了全新优化路径。",
    "keywords": [
      "PARSCALE",
      "大模型",
      "并行计算",
      "计算缩放",
      "内存优化",
      "CFG",
      "推理优化",
      "参数高效微调"
    ],
    "area": [
      "大模型",
      "机器学习",
      "自然语言处理"
    ],
    "content": "标题：阿里通义发布并行计算新策略：1.6B等效4.4B，内存消耗骤降95%\n公众号：量子位\n--------------------------------------------------\n\n既能提升模型能力，又不显著增加内存和时间成本，LLM第三种Scaling Law被提出了。\n\n对于1.6B模型，能实现性能接近4.4B模型，内存占用仅为后者的1/22，延迟增加量为1/6。\n\n并且可直接应用于现有模型（如Qwen-2.5），无需从头训练。\n\n这就是阿里通义团队提出的PARSCALE。\n\n目前LLMs的优化主要有两种思路：参数扩展（如GPT-4）和推理时间扩展（如DeepSeek-R1），但会增加内存和时间成本。\n\n阿里通义团队提出的新范式受CFG（无分类器引导）双路径推理机制的启发。\n\n他们将CFG的并行思想从 “生成阶段的推理优化” 扩展为 “训练和推理全流程的「计算缩放」”。\n\n让我们来扒一扒技术细节。\n\nCFG 通过同时运行有条件生成（输入提示词）和无条件生成（不输入提示词）两条路径，再通过加权平均融合结果，提升生成质量（如文本相关性、图像细节精准度）。\n\n其核心在于利用并行计算（两次前向传播）增强模型决策的多样性和准确性，而无需增加模型参数。\n\n研究人员观察到CFG的有效性可能源于计算量的增加（两次前向传播），而非单纯的条件引导。\n\n由此提出假设：并行计算的规模（如路径数量）可能是提升模型能力的关键因素，而非仅依赖参数规模或推理时间的串行扩展（如生成更多token）。\n\nCFG用2条并行路径提升性能，PARSCALE则将路径数量扩展为P条（如P=8），并通过可学习的输入变换和动态聚合，使并行计算成为一种可扩展的 “计算缩放” 范式。下图展示了PARSCALE方法。\n\n1、输入层：可学习的多路径输入变换\n\n核心改进是将CFG的固定双路径扩展为P条可学习的并行路径，每条路径通过可训练的前缀嵌入生成差异化输入。\n\n前缀嵌入生成：为每个并行路径引入可训练的前缀向量（维度与输入嵌入一致），拼接在原始输入前，形成路径专属输入。\n\nKV缓存区分：在Transformer的注意力层中，不同路径的键（K）和值（V）缓存相互独立，确保各路径的计算互不打扰，增强输出多样性。\n\n2、计算层：并行前向传播\n\n并行执行：将P个差异化输入同时输入模型，利用GPU的并行计算能力，一次性完成P路前向传播，生成P个输出流。\n\n效率优势：通过批量矩阵运算实现P路并行，计算效率随P线性增长，共享模型主体参数，仅增加前缀嵌入等少量可训练参数。\n\n3、输出层：动态加权聚合\n\n通过多层感知机（MLP）动态计算各路径输出的聚合权重，替代 CFG 的固定权重机制：若某路径输出与当前输入语义匹配度高，MLP 会为其分配更高权重。\n\n当P=8时，1.6B参数模型在HumanEval的性能（Pass@1=39.1%）接近4.4B参数模型（Pass@1=45.4%），但内存占用仅为后者的1/22，延迟增加量为1/6。\n\n在GSM8K数学推理任务中，P=8使1.8B模型性能提升34%（相对基准），显著高于参数扩展的增益。\n\n阶段1：用传统方法预训练模型至收敛（1Ttokens）。\n\n阶段2：冻结主体参数，仅训练前缀嵌入和聚合权重（20Btokens，占总数据的 2%）。\n\nP=8模型在GSM8K上提升34%，且与从头训练效果相当，证明少量数据即可激活并行路径的有效性。且该策略使训练成本降低约 98%\n\n研究团队在Qwen-2.5-3B模型上进行持续预训练和参数高效微调（PEFT），仅调整前缀和聚合权重。\n\n结果显示，在代码生成任务（HumanEval+）中PEFT 方法使Pass@1提升15%，且冻结主体参数时仍有效，证明动态调整 P 的可行性。\n\nPARSCALE通过可学习的多路径输入、动态聚合权重、全流程并行优化，将CFG的 “双路径启发” 升级为一种通用的计算缩放范式。\n\n感兴趣的朋友可到官方查看更多细节～\n\n论文链接：https://arxiv.org/abs/2505.10475代码地址：https://github.com/QwenLM/ParScale参考链接：https://x.com/iScienceLuvr/status/1923262107845525660\n\n— 完 —\n\n📪 量子位AI主题策划正在征集中！欢迎参与专题365行AI落地方案，一千零一个AI应用，或与我们分享你在寻找的AI产品，或发现的AI新动向。\n\n💬 也欢迎你加入量子位每日AI交流群，一起来畅聊AI吧～\n\n一键关注 👇 点亮星标\n\n一键三连「点赞」「转发」「小心心」\n\n欢迎在评论区留下你的想法！",
    "published_time": "2025-05-28T04:23:13.000Z",
    "download_time": "2025-05-30T00:29:19.086251",
    "visual_resource": [
      "screenshot/wechat_wx_6f5fafc2.jpg"
    ],
    "meta-data": "{\"original_metadata\": {\"date_modified\": \"2025-05-28T04:23:13.000Z\", \"image\": \"https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtArogqibFfK994adaJfw3uicc4z1j8pmSQMVFPm97Hiaq2RopTm80F5vvwue4PDwZq4DDcSDMFuREDGA/0?wx_fmt=jpeg\", \"id\": \"tukh12k0iG-b3WbysI_15w\"}, \"extraction_info\": {\"account\": \"量子位\", \"file_path\": \"./database/content/wechat/tukh12k0iG-b3WbysI_15w.txt\"}}"
  },
  {
    "id": "VKsZftqpNCtKQsQEb5g_Mg",
    "source": "wechat",
    "url": "https://mp.weixin.qq.com/s/VKsZftqpNCtKQsQEb5g_Mg",
    "title": "港科大Apple新研究：Tokens使用量减少，模型推理还更强了",
    "summary": "香港科技大学与苹果等机构研究人员提出Laser系列创新方法，显著提升大推理模型（LRMs）的效率与准确率。针对现有LRMs在复杂推理任务中Tokens使用量巨大的问题，Laser通过统一的长度奖励设计和动态难度感知机制，实现了Tokens使用量大幅减少（如在AIME24上降低63%），同时推理准确率不降反升（提升6.1%）。研究表明，该方法促使模型形成更健康的思考模式，减少冗余的“自我反思”。Laser系列在多个基准测试和不同规模模型上展现卓越性能与泛化能力，为构建更高效、更智能的AI模型提供了新路径，强调准确性与简洁性并存的高级智能。",
    "keywords": [
      "大推理模型",
      "Tokens效率",
      "推理能力",
      "准确率",
      "Laser方法",
      "奖励函数",
      "模型优化",
      "思维模式"
    ],
    "area": [
      "人工智能",
      "机器学习",
      "大模型"
    ],
    "content": "标题：港科大Apple新研究：Tokens使用量减少，模型推理还更强了\n公众号：量子位\n--------------------------------------------------\n\n1+1等于几？\n\n现在的大推理模型（LRMs）已经展现出了非凡的推理能力。但是面对这样最简单的数学问题，现有的LRMs仍需要花费1400+的tokens来思考。\n\n那么有办法让LRMs在推理思考时更快更强吗？\n\n来自港科大、港城、滑铁卢大学和Apple的研究人员，最近提出了Laser系列新方法，实现了更好的模型效率和准确率平衡，做到了两者的共同显著提升。\n\n经过Laser和它的进阶方法Laser-D、Laser-DE训练后的模型，相较于训练前模型或者其他方法训练的模型，在准确率（Accuracy）和Tokens使用效率（Efficiency）上，同时取得了显著的提升。\n\n例如在知名复杂数学推理基准AIME24上，Laser-D和Laser-DE方法能够让模型在减少Tokens使用量63%的情况下，还继续提升6.1的性能。\n\n同时，研究人员还发现，经过训练的模型的思考过程里，冗余的“self-reflection”的比例大大降低，呈现出了一种更加健康的思考模式。\n\n这一研究也在𝕏引起了讨论：\n\n那么，Laser是如何让大模型推理又快又好的呢？\n\nLaser的研究人员首先发现，仅仅通过在强化学习过程中，对模型输出长度进行截断，就可以让训练后的模型的推理效率大幅提升。\n\n但这种方式，只能带来效率的提升，对于模型推理的准确性仍然有不小的损害。\n\n这意味着，推理的准确性和效率其实是一个平衡问题（Trade-off)，用更多的Tokens经常能取得更高的准确率，反之可能准确率就会受到损害。\n\n所以不应该仅仅关注某一指标，而应该将两者一同考虑，将问题的重点放在如何提升它们之间的平衡上面。\n\nLaser主要通过以下三点创新来平衡效率和准确率，以做到双提升：\n\n1、统一视角：提出了一套统一的框架来看待各类基于长度的奖励设计（Length-based Reward），并且将训练时截断这一简单方法也统一进了这一套框架内。\n\n2、Laser（Length-bAsed StEp Reward）：基于这一个统一框架，研究人员提出一种全新的基于目标长度和阶跃函数（Step Function）的奖励设计，规避了之前奖励设计存在的一些问题。\n\n3、动态且带有难度感知的Laser-D、Laser-DE方法：进一步的，研究人员提出了一套自动适配机制，来匹配不同难度下，不同题目的最优目标长度，让Laser达到最优的平衡。\n\n下面分别详细展开下。\n\n研究人员首先将直接截断训练的方法和先前不同的长度奖励设计联系起来，统一成了一套统一的奖励设计框架。\n\n具体而言，所有的这些方法，都可以看做是正确性的奖励C(x)、基于长度的奖励S(x)，以及一个控制开关λ(y)的组合。\n\n表中最右侧的可视化图片，展示了不同的方法对应的奖励函数的不同形状，其中蓝线代表正确的回复对应的奖励函数，红线代表错误的回复对应的奖励函数。\n\n从图上可以看到，训练时直接截断的方法，有一个很大的问题在于，当模型产生的回复很长的时候，正确回复和错误回复的奖励会杂糅在一起，使得模型无法正确区分回复的正确性，影响对对应数据的学习。\n\n为了解决训练截断中“无法区分正确但冗长的回答”这一问题，研究人员提出了Laser奖励函数。\n\nLaser不再“惩罚”所有长回答，而是对在目标长度以内生成的正确回答给予额外的正向奖励。\n\n这种阶跃函数（Step Function）形式的奖励机制，既鼓励简洁，也保留了对准确推理的认可，有效提升了准确率与效率的整体平衡。\n\n在进一步提升准确率与效率的平衡性上，研究人员提出了LASER-D方法：\n\n通过引入动态调整目标长度与题目难度感知机制，模型在训练过程中可以根据题目的难易程度，自适应设定更合适的token使用上限。\n\n这一机制通过监控模型在不同难度题目上的生成表现，动态评估不同难度题目的最优目标长度。\n\n具体来说，这一机制会定期使用一个小规模的监控集，对不同长度设定下的“预期正确回答数量”进行估算，并据此动态更新易/中/难三类题目的目标长度，几乎不增加训练开销，却显著提升了训练时奖励函数的灵活性与适应性。\n\n此外，他们还提出了LASER-DE。即在模型答错时，鼓励模型在更长长度上进行探索，尝试纠正错误、发现更优的推理路径，从而提升在困难题目上的表现。\n\n这一系列改进让LASER系列方法在多个benchmark上，实现了更优的性能-效率双赢效果。\n\n研究人员用DeepSeek-R1-Distill-Qwen的1.5B / 7B / 32B三个不同规模的模型，在MATH500、AIME24、AMC23、Olympiad Bench上进行了广泛实验。\n\n首先，他们通过调整各个方法在训练中的关键参数，绘制出不同方法在准确率（Accuracy）与token使用量（Efficiency）上的帕累托（Pareto）前沿。\n\n如图所示，在AIME2024和所有Benchmarks的平均上，原始模型（蓝色虚线）在token使用上代价巨大。\n\n而其他baselines方法虽然在效率上有所提升，但准确率下降明显。\n\n相比之下，LASER、LASER-D和LASER-DE（橙红色）始终位于原模型的准确率之上——\n\n在显著减少Tokens使用的同时，准确率还明显高于baseline，展现出强大的推理性能和推理效率双提升。\n\n特别是在AIME2024上，LASER-D在只使用原始模型1/3 Tokens的情况下，就能取得+6.1的准确率提升，证明其在复杂数学推理任务中的强大效果。\n\n在7B和32B模型上，LASER-D和LASER-DE相较于其他方法，在准确率和token使用效率上都取得了更优表现。\n\nDeepSeek-R1-Distill-Qwen-7B模型上，例如对于AIME24，LASER-D在7B模型上，在提升5.1的准确率的同时，平均token使用量还能降低60%，再次实现效率准确率双提升。\n\n研究人员还在多个领域外（OOD）测试集（GPQA、LSAT、MMLU）上对他们的方法进行了验证。\n\n实验结果表明，在OOD测试集上，LASER、LASER-D和LASER-DE取得良好的泛化，同样取得了最优的准确率与效率平衡，实现了准确率效率双提升。\n\n为了进一步理解LASER系列方法为何能在保持准确性的同时大幅压缩token使用，研究人员对模型推理行为的变化进行了分析。\n\n结果显示，经过LASER训练后，模型生成中冗余的Backtracking（反复自我否定）显著减少，而Verification（验证）、Subgoal Setting（子目标拆解）等关键推理行为得以保留甚至增强。\n\n这表明LASER不仅压缩了长度，还引导模型学会了更简洁、结构更清晰的思考方式。\n\n这也与文章开头展示的 “1+1等于几” 的案例相呼应——\n\n训练后的模型不再陷入反复的self-reflections，而是能直接识别出问题的关键，做出高效、准确的回应。\n\n团队表示，他们相信“能够准确且精简地表达”是高级智能的重要体现。\n\n真正强大的模型，应在准确性与简洁性之间实现良好平衡，而非只追求其中任何一者。\n\nLASER系列方法正是朝这一目标迈出的关键一步，它不仅压缩了推理长度，更提升了推理质量。\n\n团队也表示，未来将继续探索更灵活、更通用的方法，进一步推高模型的这一高级智能的能力。\n\n论文： https://arxiv.org/abs/2505.15612GitHub仓库： https://github.com/hkust-nlp/Laser\n\n一键三连「点赞」「转发」「小心心」\n\n欢迎在评论区留下你的想法！\n\n— 完 —\n\n🌟 点亮星标 🌟",
    "published_time": "2025-05-28T04:23:13.000Z",
    "download_time": "2025-05-30T00:29:30.403526",
    "visual_resource": [
      "screenshot/wechat_wx_53c6a818.jpg"
    ],
    "meta-data": "{\"original_metadata\": {\"date_modified\": \"2025-05-28T04:23:13.000Z\", \"image\": \"https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtAHkwSrvicgK1yjPVBOuCG2fmGoxkB62QWsMJV2cyzXyxb3hD6gS0McJgdcVnCmWoCrBXwNqx1muwA/0?wx_fmt=jpeg\", \"id\": \"VKsZftqpNCtKQsQEb5g_Mg\"}, \"extraction_info\": {\"account\": \"量子位\", \"file_path\": \"./database/content/wechat/VKsZftqpNCtKQsQEb5g_Mg.txt\"}}"
  },
  {
    "id": "_3GnRpcgD_c5_nkzE_Fkyg",
    "source": "wechat",
    "url": "https://mp.weixin.qq.com/s/_3GnRpcgD_c5_nkzE_Fkyg",
    "title": "新智元十年，ASI降临，诚邀你加入！",
    "summary": "新智元即将迎来其十年里程碑，同时传达了“ASI降临”的前瞻性展望，这预示着人工智能领域正迈向超越人类智能的奇点时刻。该标题不仅是新智元媒体自身发展的重要节点，更强调了通用人工智能（AGI）乃至超级人工智能（ASI）未来可能带来的深远影响，暗示了技术突破和业界发展的新篇章。此次发布可能伴随着某项重大活动或合作倡议，旨在邀请各界共同探讨并见证AI的未来发展趋势。此举体现了业界对高级AI形态的持续关注与探索。",
    "keywords": [
      "新智元",
      "ASI",
      "人工智能",
      "超级智能",
      "AI发展",
      "科技媒体",
      "十周年"
    ],
    "area": [
      "人工智能",
      "大模型",
      "智能体"
    ],
    "content": "标题：新智元十年，ASI降临，诚邀你加入！\n公众号：新智元\n--------------------------------------------------\n\n新智元报道",
    "published_time": "2025-05-28T05:06:10.000Z",
    "download_time": "2025-05-30T00:27:28.308284",
    "visual_resource": [
      "screenshot/wechat_wx_b14aed7a.jpg"
    ],
    "meta-data": "{\"original_metadata\": {\"date_modified\": \"2025-05-28T05:06:10.000Z\", \"image\": \"https://mmbiz.qpic.cn/sz_mmbiz_jpg/UicQ7HgWiaUb0UW7sJXoiaeUGtFg6Lh1gfPFfounjYicVzj0abXr6Q50yIQq326SJr1we8zc3c9D0S7WhOMiaJia1ibUg/0?wx_fmt=jpeg\", \"id\": \"_3GnRpcgD_c5_nkzE_Fkyg\"}, \"extraction_info\": {\"account\": \"新智元\", \"file_path\": \"./database/content/wechat/_3GnRpcgD_c5_nkzE_Fkyg.txt\"}}"
  },
  {
    "id": "3HqPGCvgvShv6pLeElVEAQ",
    "source": "wechat",
    "url": "https://mp.weixin.qq.com/s/3HqPGCvgvShv6pLeElVEAQ",
    "title": "AI狂飙100天，中国力量突起！顶流视频号10分钟看尽全球最强杀招",
    "summary": "文章回顾了自2025年初全球AI版图的剧烈重绘。中国DeepSeek以开源大模型DeepSeek-R1的卓越能力，突破硅谷技术壁垒，引发市场震动。面对挑战，OpenAI迅速通过价格战、发布GPT-4.5及GPT-4o进行反击，马斯克亦通过Grok抢占算力话语权。在此期间，DeepSeek进一步推出本地可运行的多模态模型V3，推动AI从实验室走向普通用户。至4月，AI发展已从“参数至上”转向“实用主义”，国产大模型全面接入主流平台，标志着AI技术正加速走向全民普及，重塑社会生产方式。",
    "keywords": [
      "DeepSeek",
      "OpenAI",
      "大模型",
      "开源",
      "算力",
      "多模态",
      "AI竞争",
      "技术普惠"
    ],
    "area": [
      "人工智能",
      "大模型",
      "多模态"
    ],
    "content": "标题：AI狂飙100天，中国力量突起！顶流视频号10分钟看尽全球最强杀招\n公众号：新智元\n--------------------------------------------------\n\n新智元报道\n\n2025年开年，全球AI版图被彻底重绘。\n\n从中国DeepSeek掀起的开源风暴，到OpenAI主导的闭源反击，短短四个月间，东西方科技力量在算力、模型、生态、资本等层面激烈碰撞，AI技术不再只是前沿产业话题，更成为改变社会生产方式的核心力量。\n\n1月，DeepSeek发布超级大模型DeepSeek-R1，以超97%的数学解题准确率、远超人类程序员的编程能力震惊业界，更以全面开源五大核心技术库点燃开发者热情，首周下载量破亿，彻底打破硅谷的「技术壁垒」。英伟达股价随即暴跌17%，标志着产业格局进入洗牌期。\n\n硅谷快速反应。2月，OpenAI祭出「价格战+情感智能」组合拳，推出GPT-4.5、开放搜索功能、下调API价格；而马斯克则用Grok-3和「算力神话」抢占全球注意力，试图稳住AI话语权。\n\n3月，DeepSeek再次发力，发布可本地运行的多模态模型V3与轻量逻辑模型R1，让AI真正从「高墙实验室」走向「普通人桌面」。与此同时，OpenAI推出GPT-4o，革新语音交互与内容创作，引爆创意热潮，也引发伦理争议。\n\n4月，AI迈入全民普及时代。OpenAI发布o3、o4-mini，代表从「参数至上」迈向「实用主义」；DeepSeek则进一步优化V3模型，使其在普通笔电上流畅运行。支付宝、微信等主流平台全面接入国产大模型，AI从高端科技变为大众工具。\n\n在这场全球技术竞赛中，新智元作为顶尖头部AI科技媒体，始终站在风暴核心。",
    "published_time": "2025-05-28T05:06:10.000Z",
    "download_time": "2025-05-30T00:27:36.406015",
    "visual_resource": [
      "screenshot/wechat_wx_0e9dc156.jpg"
    ],
    "meta-data": "{\"original_metadata\": {\"date_modified\": \"2025-05-28T05:06:10.000Z\", \"image\": \"https://mmbiz.qpic.cn/sz_mmbiz_jpg/UicQ7HgWiaUb15VnEUUFuicY1icOBIJEjH5m5UCefNjTgqjCXky1Pyf5JBlfAOiasssLmLluzBkmNsP7iaeEOcHUY7CA/0?wx_fmt=jpeg\", \"id\": \"3HqPGCvgvShv6pLeElVEAQ\"}, \"extraction_info\": {\"account\": \"新智元\", \"file_path\": \"./database/content/wechat/3HqPGCvgvShv6pLeElVEAQ.txt\"}}"
  },
  {
    "id": "hZqnANXmojmHv1gE9ISgfA",
    "source": "wechat",
    "url": "https://mp.weixin.qq.com/s/hZqnANXmojmHv1gE9ISgfA",
    "title": "第二次Sora时刻来了！全球首款实时摄像头诞生，真人感拉满颠覆全行业",
    "summary": "新智元报道指出，硅谷公司AKOOL正式发布全球首款实时AI摄像头——AKOOL Live Camera，被誉为AI视频领域的“第二次Sora时刻”。该产品集虚拟数字人、实时翻译、实时换脸及实时视频生成四大功能于一体，以超低延迟和影视级画质，实现了“边拍边生”的突破性创新。AKOOL Live Camera具备情境感知与情感响应的智能交互能力，彻底改变了传统“文生视频”的预制化模式。通过4D面部映射、神经语音引擎等先进技术，AKOOL正推动数字交互从“预制化”迈向“智能化响应”时代，有望深刻革新视频制作与数字营销行业。",
    "keywords": [
      "AKOOLLiveCamera",
      "实时AI视频",
      "虚拟数字人",
      "实时视频生成",
      "低延迟",
      "Sora时刻",
      "情境感知",
      "生成式AI"
    ],
    "area": [
      "人工智能",
      "生成式AI",
      "多模态"
    ],
    "content": "标题：第二次Sora时刻来了！全球首款实时摄像头诞生，真人感拉满颠覆全行业\n公众号：新智元\n--------------------------------------------------\n\n新智元报道\n\n就在今天，AI视频领域，再次迎来了高能时刻！\n\n硅谷新锐公司AKOOL正式发布的全球首款实时摄像头——AKOOL Live Camera，一举点燃了全行业的热情！\n\n它不仅能秒变虚拟数字人、实时翻译多语言、无缝替换人脸，还能动态生成影视级画质的视频画面，将四大功能集于一身。\n\n更炸裂的是，这一切都在实时进行的——延迟低到惊人，交互智能到仿佛面对真人，真正把「沉浸感」拉满。\n\n无论是它的超低延迟，影视级画质，还是环境感知+情感响应的智能交互能力，都再次刷新行业纪录。\n\n如果说，Sora曾代表了AI视频生成的巅峰速度，那AKOOL则让我们第一次见识到什么叫「边拍边生」的科幻现实。\n\nAI视频的「第二次Sora时刻」，来了！\n\n视频加载失败，请刷新页面再试\n\n此次AKOOL Live Camera的四大功能，每个都让人眼前一亮。\n\n首先就是虚拟数字人功能，它能打造出栩栩如生的数字分身。\n\n通过4D面部映射技术与传感器融合方案，实时摄像头可精准捕捉人类微表情、手势轨迹及语音语调变化，驱动虚拟数字人实现自然语言处理+非语言信号同步输出。\n\n无论是在产品发布会中作为代言人的虚拟替身，还是在电商直播的主播分身，都能让观众感受到高度逼真的交流体验。\n\nAI视频翻译功能，更是打破了语言的壁垒，构建了全新解决方案。\n\n现在，AKOOL Live Camera已经能够实时翻译150+语言，并保持说话者的声音特色和同步口型动作。\n\n比如在一场跨国直播活动上，来自世界各地的观众都能通过该功能，以自己熟悉的语言理解直播内容，极大地提升了信息传播的效率和范围。\n\n实时换脸功能同样引人注目。\n\n在视频生成过程中，AKOOL Live Camera可以实现人脸的精准替换，并且完美反应人物的情绪和微表情特征。\n\n这一功能在影视制作、电商直播等领域有着广阔的应用前景。比如，同一美妆产品，在面对全球不同地区的用户时，可以一键切换成当地的主持人。\n\n实时AI视频生成功能，则彻底颠覆了传统视频制作模式。\n\n无需预先录制、编写脚本和复杂的后期制作，AKOOL实时摄像头就能根据用户的实际需求，理解对话上下文，即时生成超逼真的视频内容。\n\n这意味着，内容创作者可以更快速、灵活地响应各种场景需求，大大提高了视频制作的效率和创意空间。\n\n2024年，OpenAI的Sora凭借文生视频的功能引发全球关注，让人们见识了AI在视频创作领域的惊人潜力。\n\nAKOOL则带着AKOOL Live Camera这款颠覆性产品，开启了实时视频生成领域的「新时代」。\n\n无需脚本：打破「文生视频」的创作枷锁\n\n它直接捕捉人类实时互动数据，如面部表情、语音、手势，无需脚本即可动态生成视频。\n\n例如：跨国CEO直播时，虚拟形象可根据观众所在国家的语言、文化习惯实时切换语言和手势，全程零延迟互动。\n\n超低延迟+超逼真效果：重新定义「实时」标准\n\n生成的虚拟形象最低延迟只有500毫秒，在盲测中94%的人无法区分真假，连细微的眨眼、嘴角弧度都与真人无异。\n\n情境感知+动态响应：让虚拟形象「活起来」\n\n区别于Sora的静态逻辑，只能基于固定文本指令生成内容，无法感知环境变化或用户实时反馈。\n\nAKOOL Live Camera具备环境感知能力，例如在会议室强光下自动调整面部光影，在嘈杂环境中增强语音清晰度；\n\n能实时解析用户情绪，比如观众皱眉时，虚拟形象会放慢语速、重复重点；学生走神时，虚拟教师会切换教学案例，真正实现「互动式沟通」。\n\n可以说，这一产品的发布，标志着数字交互从「预制化」迈入「智能化响应」时代，全球AI视频生成领域迎来里程碑式进展。\n\nAKOOL Live Camera背后依托的，是足够先进的技术架构。\n\n4D面部映射技术，能通过摄像头和传感器，精确捕捉用户面部的细微动作和表情变化，为虚拟形象的生成提供了丰富的数据基础。\n\n神经语音引擎则负责分析用户的语音特征，生成自然流畅的合成语音，并根据情感状态进行实时调整。\n\n情境感知渲染技术使虚拟形象能够根据环境光线、背景以及观众互动等因素，实时渲染出逼真的效果。\n\n而边缘人工智能处理与云渲染相结合的方式，既保证了本地设备处理的低延迟，又利用云端强大的计算资源生成高保真的视觉效果和环境背景。\n\n自2022年成立以来，AKOOL发展迅猛，于2024年实现4000万美元营收，与多家世界500强公司达成战略合作，在全球生成式人工智能领域占据重要地位。\n\nAKOOL的创始人吕家俊博士毕业于伊利诺伊大学香槟分校人工智能专业，作为连续创业者，还深度参与过两家B+轮科技公司的早期运行。团队核心成员汇聚了全球众多顶尖人工智能专家和工程师，为产品的持续创新提供了坚实保障。\n\nCEO吕家俊表示：「AKOOL Live Camera不仅在改进视频创作技术，更在改变视频制作方式。从全球产品发布会到企业会议，甚至医疗保健，我们正在为实时视频开辟新的可能。」\n\nAKOOL最新推出的实时摄像头，将视频翻译、虚拟数字人、实时面部交换和动态视频生成等功能集于一体，实现了低延迟、高保真的实时交互视频。AKOOL正在用技术的力量，重新定义视频创作和数字营销的新未来。\n\n预约成为首批AKOOL Live Camera的用户。让我们一起见证实时AI视频生成的未来！\n\n预约地址：https://akool.com/live-camera?utm_code=GHYCPorUty",
    "published_time": "2025-05-28T05:06:10.000Z",
    "download_time": "2025-05-30T00:27:48.544932",
    "visual_resource": [
      "screenshot/wechat_wx_6a4adf73.jpg"
    ],
    "meta-data": "{\"original_metadata\": {\"date_modified\": \"2025-05-28T05:06:10.000Z\", \"image\": \"https://mmbiz.qpic.cn/sz_mmbiz_jpg/UicQ7HgWiaUb15VnEUUFuicY1icOBIJEjH5mQCLTeEvkOtm8t5xL0Q8LyEicUiayicCAjib3aKuMq6nJLicI2UIIg29xtDw/0?wx_fmt=jpeg\", \"id\": \"hZqnANXmojmHv1gE9ISgfA\"}, \"extraction_info\": {\"account\": \"新智元\", \"file_path\": \"./database/content/wechat/hZqnANXmojmHv1gE9ISgfA.txt\"}}"
  },
  {
    "id": "yzfNRAJyITdHN4xskNCSWg",
    "source": "wechat",
    "url": "https://mp.weixin.qq.com/s/yzfNRAJyITdHN4xskNCSWg",
    "title": "刚刚2岁的Llama，「爸妈」都跑了！小扎手拆Meta AI，LeCun保持独立",
    "summary": "Meta正经历AI部门的深度重组，拆解旧有研发体系为AI产品与AGI基础团队，以应对Llama系列大模型表现不佳、核心人才大量流失以及外部竞争加剧的挑战。此前，Llama 4遭遇“翻车”被曝性能争议与跳票，而Llama首版多数作者已离职创业或加入竞对，加剧人才真空。尽管重组旨在吸引新研究者，但首席AI科学家LeCun坚持其与主流LLM发展相悖的“世界模型”路线，FAIR仍保持独立，这为Meta的AGI战略及团队协同带来不确定性。此次变革显示Meta在投入巨资后，正加紧调整AI战略以提升竞争力。",
    "keywords": [
      "Meta",
      "Llama",
      "AI重组",
      "人才流失",
      "大模型",
      "LeCun",
      "AGI",
      "多模态"
    ],
    "area": [
      "人工智能",
      "大模型",
      "多模态"
    ],
    "content": "标题：刚刚2岁的Llama，「爸妈」都跑了！小扎手拆Meta AI，LeCun保持独立\n公众号：新智元\n--------------------------------------------------\n\n新智元报道\n\n小扎最近着实有点烦。\n\n一是谷歌、OpenAI、Anthropic等竞争对手不断「上压力」，谷歌I/O大会、Claude 4出炉，而OpenAI的奥特曼牵手了Apple乔布斯时代的乔纳森做硬件；\n\n二是刚刚2岁的Llama（2023年开源），最初署名的14名作者走的走，创业的创业，选择留下的只有3人；\n\n三是Llama 4不仅翻车，Behemoth还面临跳票，即使是Scout、Maverick被开发者调侃为Llama 3.5；\n\n四是作为「技术老大」的Yann LeCun天天可劲地说LLM要完蛋，与当下LLM发展背道而驰。\n\n终于，小扎「痛定思痛」决定重组Meta的AI团队！\n\n2025年5月，根据首席产品官Chris Cox 的内部备忘录，旧研发体系将被拆分为：\n\nAI产品团队\n\n负责Meta AI助手、AI Studio开发平台及Facebook/Instagram/WhatsApp的AI功能，负责人为Connor Hayes；\n\nAGI基础团队\n\n基础团队将统筹Llama大模型系列，并提升推理、多媒体与语音能力，负责人为Ahmad Al-Dahle和Amir Frenkel。\n\nAI研究部门\n\n基础人工智能研究团队FAIR，仍然是Yann LeCun领导，仍保持在新组织结构之外。\n\n不过，其中专注于多媒体研究的团队将并入新的AGI基础团队。\n\n重组还伴随高层轮换：FAIR联合创始人Robert Fergus自Google DeepMind回归，接替4月离任的 Joelle Pineau。\n\n其实在今年2月，大受DeepSeek震撼的Meta就已经对GenAI团队进行了一次重大调整——任命了一位新的产品负责人，并调离了两位工程负责人。\n\n如今，全面押注AI的Meta已经花掉了650亿美元，而其中的大头都流向了AI和数据中心。\n\n2023年Llama首版论文中的14名作者，如今只剩3人留在Meta：研究科学家Hugo Touvron、研究工程师Xavier Martinet以及技术项目负责人Faisal Azhar。\n\n论文地址：https://arxiv.org/pdf/2302.13971\n\n其余都流向创业公司或竞争对手，最受瞩目的去处是法国初创 Mistral AI。\n\n人才真空直接影响研发节奏。\n\n内部人士称，Llama 4 Behemoth原定2025年春季上线，如今已推迟许久，部分原因是「缺乏足够资深的训练与优化工程师」。\n\n华尔街分析将此视为Meta AI连续四季科技人才「负增长」的后果，也解释了公司为何急于重组研发框架流程，以期吸引新一波研究者加入。\n\n以下列表基于研究人员的LinkdIn资料，展示了他们的去向。\n\nNaman Goyal\n\n现任职位：Thinking Machines Lab技术团队成员\n\n何时离开：2025年2月\n\n在Meta的时间：6年7个月\n\nBaptiste Rozière\n\n现任职位：Mistral AI科学家\n\n何时离开：2024年8月\n\n在Meta的时间：5年1个月\n\nAurélien Rodriguez\n\n现任职位：Cohere基础模型训练总监\n\n何时离开：2024年7月\n\n在Meta的时间：2年7个月\n\nEric Hambro\n\n当前职位：Anthropic技术团队成员\n\n何时离开：2023年11月\n\n在Meta的时间：3年3个月\n\nTimothée Lacroix\n\n现任职务：Mistral联合创始人兼首席技术官\n\n何时离开：2023年6月\n\n在Meta的时间：8年5个月\n\nMarie-Anne Lachaux\n\n现任职位：Mistral创始成员兼AI研究工程师\n\n在Meta的时间：5年\n\nThibaut Lavril\n\n现任职位：Mistral AI研究工程师\n\n在Meta的时间：4年5个月\n\nArmand Joulin\n\n现任职位：Google DeepMind杰出科学家\n\n何时离开：2023年5月\n\n在Meta的时间：8年8个月\n\nGautier Izacard\n\n现任职位：微软AI技术专家\n\n何时离开：2023年3月\n\n在Meta的时间：3年2个月\n\nEdouard Grave\n\n现任职位：Kyutai研究科学家\n\n何时离开：2023年2月\n\n在Meta的时间：7年2个月\n\nGuillaume Lample\n\n现任职位：Mistral联合创始人兼首席科学家\n\n何时离开：2023年初\n\n在Meta的时间：7年\n\n今年4月，Meta宣布发布多模态 Llama 4 家族，但很快就翻车，并陷入三大争议：\n\n基准「灌水」——\n\n开发者质疑Meta提前手动标注测试集、让模型在常用榜单上异常亮眼，Meta高管被迫公开否认。\n\nLlama 4 Behemoth 跳票——\n\n华尔街日报披露，内部训练日志显示Behemoth在推理水平上「没有显著超越竞品」，多次训练中断造成资金与算力浪费。\n\n开发者失望——\n\nBusiness Insider援引一线工程师说法：「Scout、Maverick 更像Llama 3.5」，缺失Meta对外宣称的「跨10M token上下文」完备能力，导致社区不少项目仍停留在Llama 3 生态。\n\n尽管官方博客宣称Llama 4 开启原生多模态新时代，实际体验却暴露视觉‑语言对齐不稳定、话题回答走偏等问题。\n\n更雪上加霜的是，新版模型的延迟与资源吃紧，被认为无法在移动端或Ray‑Ban智能眼镜这种边缘设备上流畅运行。\n\n虽然Meta在备忘录中提到将团队重组为两个，但是Yann LeCun领导的FAIR似乎依然「独立于AI之外」。\n\n面对外界唱衰，Meta 首席AI科学家Yann LeCun 坚持他自己的路线路线：\n\n在多场采访中，他痛批「纯粹堆参数的自回归 LLM 注定走向瓶颈」，主张「世界模型＋对比学习」才是通往AGI的正道。\n\n但问题是现在全世界，包括谷歌、OpenAI、Anthropic和Grok都在LLM的道路上狂奔，而Meta的技术领导人却在公开场合不断唱衰LLM，可想而知团队的氛围了。\n\nLeCun多次引用「猫智商论」，嘲讽同行对AI末日论的恐慌，认为真正威胁不是AI本身，而是「被少数巨头封闭垄断的黑箱模型」。\n\n他公开支持Meta将Llama系列继续开源，即便因此加剧外部分叉与人才流失，仍强调生态繁荣比商业独占更重要。\n\nLeCun还在演讲中抛出「自监督外推器」（Self‑Supervised Predictor）概念，宣称将联合FAIR与AGI基础团队用世界模型驱动下一代AI，也被视为Meta重组后研究‑产品两条腿走路的理论底座。\n\n这种「与世皆敌」的态度，让LeCun给小扎抛出一个不大不小的问题：\n\n团队心不齐，队伍怎么带？\n\nhttps://www.axios.com/2025/05/27/meta-ai-restructure-2025-agi-llama\n\nhttps://www.businessinsider.com/meta-llama-ai-talent-mistral-2025-5",
    "published_time": "2025-05-28T05:06:10.000Z",
    "download_time": "2025-05-30T00:27:56.724835",
    "visual_resource": [
      "screenshot/wechat_wx_18d42434.jpg"
    ],
    "meta-data": "{\"original_metadata\": {\"date_modified\": \"2025-05-28T05:06:10.000Z\", \"image\": \"https://mmbiz.qpic.cn/sz_mmbiz_jpg/UicQ7HgWiaUb15VnEUUFuicY1icOBIJEjH5mvjzLeypwZ2xfXtOAHOxebBVHE0kCOu4jzBR3rwr77m5N46XCz2AvLQ/0?wx_fmt=jpeg\", \"id\": \"yzfNRAJyITdHN4xskNCSWg\"}, \"extraction_info\": {\"account\": \"新智元\", \"file_path\": \"./database/content/wechat/yzfNRAJyITdHN4xskNCSWg.txt\"}}"
  },
  {
    "id": "Q4Il_vDhKbncI-kiOPnikQ",
    "source": "wechat",
    "url": "https://mp.weixin.qq.com/s/Q4Il_vDhKbncI-kiOPnikQ",
    "title": "SIGGRAPH 2025 | CLR-Wire：曲线框可生成？可交互？深大VCC带你见证魔法",
    "summary": "深圳大学黄惠团队独立推出CLR-Wire技术，首次实现将复杂三维曲线框结构统一编码至连续潜空间，解决了传统方法难以同时捕捉线框几何和拓扑信息的难题。该创新方案通过结合变分自编码器与流匹配方法，构建了能够进行高效生成与平滑插值的三维线框模型，并支持无条件及基于点云、图像的条件生成。实验证明，CLR-Wire在生成精度、多样性方面显著超越现有技术，尤其在复杂拓扑结构处理上表现出色。此项技术为工业设计、三维重建及内容创作等领域带来了高效可靠的解决方案，为未来交互式3D设计与语义驱动控制奠定基础。",
    "keywords": [
      "CLR-Wire",
      "三维曲线框",
      "连续潜空间",
      "三维生成",
      "计算机图形学",
      "流匹配",
      "变分自编码器"
    ],
    "area": [
      "生成式AI",
      "深度学习",
      "计算机视觉"
    ],
    "content": "标题：SIGGRAPH 2025 | CLR-Wire：曲线框可生成？可交互？深大VCC带你见证魔法\n公众号：机器之心\n--------------------------------------------------\n\n深圳大学黄惠团队独立推出 CLR-Wire：连续潜空间驱动的三维曲线框生成方法，首次实现了将复杂的三维曲线框结构统一编码到连续的潜空间中，解决了传统方法难以同时有效捕捉线框几何和拓扑信息的难题。这一创新技术能够实现复杂三维结构的高效生成与平滑插值，在工业设计、三维重建及内容创作等领域具有广泛的实际应用前景。第一作者为深圳大学可视计算研究中心 (VCC) 博士研究生马雪奇，合作者刘奕林、高天龙、黄期瑞均为 VCC 研究生。CLR-Wire 相关代码已全面开源，欢迎大家试用和建议。\n\n项目主页：https://vcc.tech/research/2025/CLRWire\n\n项目代码：https://github.com/qixuema/CLR-Wire\n\n论文链接：https://arxiv.org/abs/2504.19174\n\n在计算机图形学的世界里，当我们谈论三维线框插补时，我们在讨论些什么？\n\n或许，是如何让一个圆柱平滑地演变为一个精致的碟状结构；或许，是如何巧妙地将一个醒酒器无缝过渡为圆润的花瓶；甚至，是如何从一栋带有屋顶的建筑物，逐渐变化为简单明朗的方形结构，以及诸如漏斗或盘状结构之间的自由形态过渡。\n\n聪明的 CLR-Wire (发音：Clear-Wire) 为我们提供了答案：\n\n它创新地将几何曲线与拓扑结构统一编码至连续潜空间，实现了不同三维曲线框之间的平滑过渡。这不仅拓展了三维线框建模的边界，也为三维形状生成和交互式设计开启了全新的想象空间。\n\n接下来，让我们深入探索 CLR-Wire 的关键技术与背后机理。\n\nCLR-Wire 的关键技术与背后机理\n\n三维曲线框作为对三维形状的简洁抽象表示，在形状简化 [Mehra et al. 2009]、曲面重建 [Pan et al. 2015] 及交互式设计 [Gal et al. 2009] 中具有重要意义。然而，早期方法多依赖高质量点云提取角点或边缘 [Liu et al. 2021; Zhu et al. 2023]，缺乏对线框的拓扑重建；最新 B-rep 生成方法如 SolidGen [Jayaraman et al. 2023]、BrepGen [Xu et al . 2024] 虽然可以建模顶点、边、面，但主要面向规则几何，对不规则形状支持不足，且采用几何与拓扑分离的建模方式，容易引入误差。\n\n该工作提出了 CLR-Wire，首先，通过多层交叉注意力将神经参数化曲线及其离散拓扑关系联合编码为定长潜向量，并借助变分自编码器构建连续的潜空间分布； 随后，采用流匹配方法实现从高斯噪声到完整线框的生成，并支持无条件生成以及基于点云、图像的条件生成。实验结果表明，该方法在生成精度、新颖性和多样性方面均显著优于最先进方法，并能有效适应复杂拓扑结构，为 CAD 设计与三维内容创作提供了高效可靠的全新解决方案。\n\n本工作围绕三维曲线框的连续潜空间表示与生成，主要贡献如下：\n\n引入了线框的连续潜空间表示，实现了三维曲线框几何与拓扑的平滑插值；\n\n构建了基于连续潜空间的三维曲线框生成框架；\n\n支持无条件及条件驱动（点云或图像）的线框生成。\n\nCurveVAE\n\nCurveVAE 模块的目标是将各类三维几何曲线映射为紧凑的潜向量表示。首先，该方法对每条曲线进行标准化处理，通过平移使曲线起点位于固定位置，并通过旋转和缩放对齐终点至另一固定位置，以消除不同曲线之间的位置、朝向和尺度差异，从而提升训练稳定性。随后，沿标准化后的曲线均匀采样若干点，利用交叉注意力机制对高维的曲线点云进行特征降维，再通过多层一维卷积压缩为潜向量，同时保留曲线的细节。在解码阶段，解码器先用一维上采样卷积恢复至较高维度的特征，再结合位置编码与交叉注意力机制，通过多层感知机将连续参数映射回曲线上对应的位置，最终实现曲线的连续化重建。\n\nWireframeVAE\n\nWireframeVAE 模块旨在将来自曲线编码器的潜向量、对应的顶点坐标以及邻接关系列表进行融合编码，并把它们一起映射为一个全局潜向量。为此，该方法首先通过广度优先遍历的方式对邻接列表中的线段顺序进行排序，然后使用 Perceiver 聚合模块融合曲线特征、顶点信息和拓扑连接关系，生成统一的全局潜向量。在解码阶段，该方法使用一组可学习的查询向量对该全局潜向量进行交叉注意力操作，提取各条曲线的特征，再通过特征映射器分别预测邻接关系、顶点坐标和曲线潜向量，从而完整重建线框结构。此外，通过构建差分形式的邻接关系，该方法简化了邻接列表的表示。最后，在训练中结合均方误差损失、交叉熵损失和散度损失，以确保几何信息与拓扑信息的高效融合与高质量重建。\n\nWireframeVAE 流程图\n\nFlow Matching\n\n基于线框潜在表示的 Flow Matching 模块，旨在逐步从噪声中生成线框样本的潜向量表示。该方法通过训练一个速度场网络来描述潜向量随时间的演化，将初始噪声分布沿着一条概率路径演变为目标潜在分布。网络在训练过程中最小化预测速度与实际变化速度之间的误差，以学习到正确的演化场。训练完成后，只需求解该演化过程，即可生成新的潜空间样本。为了支持条件生成，方法还引入了预训练的图像特征提取模型和点云特征提取网络，从而兼顾无条件生成和基于稀疏点云或单视图图像的三维线框生成。\n\n结果展示\n\n为了评估线框生成质量，该方法首先采用 CD 和 EMD 来度量生成线框与参考线框在几何形状上的相似性；随后引入分布式指标以衡量样本的多样性与一致性：COV 用于评估生成结果的覆盖率，MMD 衡量结果与真实分布的差异，1-NN 则量化两者分布的相近程度。结合这些指标，该方法与 3Dwire [Ma et al. 2024]、DeepCAD [Wu et al. 2021] 及 BrepGen [Xu et al. 2024] 在无条件生成任务上进行了对比。\n\n在无条件生成实验中，3DWire 仅能生成由直线段构成的线框，无法描述曲线；DeepCAD 和 BrepGen 虽能生成带曲面模型，但其线框多依赖于表面生成，结构简单且缺乏细节。相比之下，CLR-Wire 通过统一的连续潜空间同时编码几何与拓扑，能够直接生成完整且多样的自由曲线框。\n\n在 ABC 数据集上与其他方法的无条件生成结果对比\n\n此外，通过从大量生成样本中进行多次随机抽样实验，该方法在各项评价指标上均显著超越其他方法：更高的覆盖率表明生成结果多样性更强，更低的分布差异度体现了几何一致性更好，而最近邻评分则证明了潜空间分布与测试集高度契合，进一步验证了该方法的建模能力和可靠性。\n\n与其他方法的无条件生成定量指标对比结果（左） 与基于点云的线框重建方法的对比（右）\n\n在有条件生成实验中，该方法测试了以点云或图像为条件的线框生成能力。针对点云条件，该方法在稀疏和局部缺失场景下，与依赖密集点云的 RFEPS [Xu et al. 2022] 和 NerVE [Zhu et al. 2023] 进行了对比。CLR-Wire 在 CD、EMD 和 F1 Score 上均优于其他方法，且生成的线框在细节和拓扑上更为完整。传统方法依赖局部尖锐特征，面对平滑或缺失输入易产生不完整结构，而该方法凭借预训练的全局潜空间和几何 — 拓扑先验，有效弥补稀疏与不完整信息，保持重建完整性与一致性。\n\n点云条件下不同方法的重建结果对比 （左） 该方法在部分点云条件下生成结果（右）\n\n此外，将单视图图像和草图作为条件输入时，该方法同样能够生成完整且具新颖性的三维曲线框，展现出良好的跨模态生成能力和应用潜力。\n\n该方法在单视图与草图条件下的生成结果\n\n在潜空间插值实验中，该方法实现了不同线框之间的平滑过渡。该方法首先提取不同线框对应的潜向量，然后通过球面线性插值生成中间潜在表示序列，再解码为相应的三维曲线框。结果表明，该插值过程不仅在几何细节上保持了高保真度，还成功捕捉了起始与目标线框之间的拓扑变化，展示了该方法在直观编辑与交互式操作等应用场景中的潜在价值。\n\n潜空间插值可视化：(b)–(e) 展示了不同拓扑形状的连续过渡，其中 (e) 从瓶状结构平滑变换到开口碗状，体现了该方法对几何与拓扑变化的捕捉能力\n\n总结与展望\n\n该方法提出了将不规则三维曲线框统一映射至连续潜空间的框架，实现了在潜空间中融合几何细节与拓扑连接，保证了线框生成过程中的一致性与完整性。实验验证了该表示在潜空间插值、无条件与有条件生成方面均具备优异的多样性与精度，显著提升了复杂曲线框的生成能力。尽管该潜空间已展示出平滑插值的能力，但在可控生成与编辑方面仍需进一步研究。未来，仍需要将潜空间与文本描述更紧密地对齐，以实现更高层次的语义驱动控制。\n\n© THE END\n\n转载请联系本公众号获得授权\n\n投稿或寻求报道：liyazhou@jiqizhixin.com",
    "published_time": "2025-05-28T08:10:04.000Z",
    "download_time": "2025-05-30T00:26:18.310685",
    "visual_resource": [
      "screenshot/wechat_wx_633868d7.jpg"
    ],
    "meta-data": "{\"original_metadata\": {\"date_modified\": \"2025-05-28T08:10:04.000Z\", \"image\": \"https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWic6dWJP4fbjQQ0J78sktTAYgFl0Yhk7icTzMFLkERUZYiaIh2BkxK7LXRpNeur0vvqtG78qsKPaEh6A/0?wx_fmt=jpeg\", \"id\": \"Q4Il_vDhKbncI-kiOPnikQ\"}, \"extraction_info\": {\"account\": \"机器之心\", \"file_path\": \"./database/content/wechat/Q4Il_vDhKbncI-kiOPnikQ.txt\"}}"
  },
  {
    "id": "sFK1ukPNmI89kLREdPbckg",
    "source": "wechat",
    "url": "https://mp.weixin.qq.com/s/sFK1ukPNmI89kLREdPbckg",
    "title": "LLM加RL遭质疑：故意用错奖励，数学基准也显著提升，AI圈炸了",
    "summary": "一篇来自华盛顿大学等机构的开创性论文挑战了当前大型语言模型（LLM）与强化学习（RLVR）结合的训练范式。研究发现，即使采用随机或错误等缺乏监督信息的“虚假奖励”，也能显著提升Qwen2.5-Math-7B模型在数学推理基准MATH-500上的性能。作者指出，这种异常提升源于RLVR机制意外激发了Qwen模型预训练中固有的代码推理能力，而非模型真正学习到新技能，且该效果并非普遍适用于所有模型，特异性依赖于模型预存能力。该研究对高质量监督信号的必要性提出质疑，并强调未来RLVR研究需在更多样化的模型上进行验证，并深入理解模型预训练能力对后续训练行为的影响。",
    "keywords": [
      "LLM",
      "强化学习",
      "大语言模型",
      "虚假奖励",
      "Qwen模型",
      "数学推理",
      "代码推理",
      "模型泛化"
    ],
    "area": [
      "人工智能",
      "大模型",
      "机器学习"
    ],
    "content": "标题：LLM加RL遭质疑：故意用错奖励，数学基准也显著提升，AI圈炸了\n公众号：机器之心\n--------------------------------------------------\n\n编辑：泽南、+0\n\n我们训练了这么久，都在训练些什么？\n\n这是今年最「好笑」的一篇论文。\n\n本文一出，所有的大语言模型（LLM）+ 强化学习（RL）都要被质疑是否有意义了。\n\n这周二，一篇来自华盛顿大学、艾伦人工智能实验室、伯克利的论文引爆了 AI 界。\n\n论文：Spurious Rewards: Rethinking Training Signals in RLVR\n\n项目链接：https://github.com/ruixin31/Rethink_RLVR/tree/main\n\n作者驳斥了最近大模型领域盛行的强化学习方式，他们发现：使用虚假奖励训练 Qwen2.5-Math-7B 模型也可以提高 MATH-500 的成绩，如果是随机奖励，成绩能提高 21%，如果是错误奖励，成绩能提升 25%（真实奖励能提升 28.8%）。\n\n这是怎么一回事？大模型的训练技巧真的有用吗？该工作的作者写了一篇博客进行了介绍：\n\n质疑强化学习 (RLVR) 传统观点\n\n近一段时间，可验证奖励强化学习（RLVR）已成为增强大型语言模型（LLM）推理能力的标准方法。传统观点认为，高质量的监督信号对于有效的 RLVR 训练至关重要。最近的研究挑战了这一假设，表明使用 RLVR 对单个样本或无监督样本进行训练仍然可以在 Qwen-Math 模型上取得显著的进步。\n\n但是，我们不禁要问：单样本或无监督 RLVR 中的训练信号来自哪里？为了提供有意义的 RLVR 训练信号，奖励的最低要求是什么？\n\n我们的发现令人震惊。\n\n虚假奖励，即使是随机的或错误的，也能显著提升 Qwen-Math 表现\n\n我们发现，RLVR 可以通过所谓的「虚假奖励」—— 提供极少甚至误导性指导的信号，大幅提升数学推理能力。\n\n以下是我们尝试过的一些有趣的奖励：\n\n格式奖励：仅因答案包含 \\boxed { } 而给予奖励 —— 因答案包含 \\boxed {} 表达式而给予奖励。此格式也是系统提供给模型的提示中指定的格式，从而提供了一种「提示遵循」的概念。\n\n随机奖励：完全任意的反馈 —— 字面意思：1 if (random.random () < rate) else 0\n\n错误奖励：故意设置错误的监督信号 —— 获取错误但可信的标签的步骤：\n\n按频率对模型的 rollout 进行排序\n\n取最常见的答案\n\n如果答案正确，则丢弃样本\n\n在模型最常见答案错误的子集上进行训练，并将该特定答案作为训练标签。\n\n我们还与文献中研究过的其他一些弱奖励进行了比较：\n\n多数投票奖励：将多数投票的答案作为标签。\n\n单样本强化学习：在单个样本上进行标准强化学习虚拟学习 (RLVR)。\n\nRLVR 在不同训练信号上进行 150 步训练后的 MATH-500 准确率。我们证明，即使是「虚假奖励」也能在 Qwen 模型上带来显著的 MATH-500 提升。需要注意的是，这些奖励信号不适用于其他模型，例如 Llama3 和 OLMo2，因为它们的推理先验有所不同。\n\n从 AI 社区广泛用于强化学习的模型 Qwen2.5-Math-7B 开始，我们在多个数学推理基准测试中取得了与基于真实值监督模型相当的性能提升。\n\n这一发现直接挑战了强化学习在提升 AI 推理能力方面所起作用的现有理解。\n\n有反转：虚假奖励并非对所有模型都有效\n\n当我们将实验扩展到其他未专门针对数学推理进行优化的模型系列（包括 Qwen2.5-Base、Olmo2 和 Llama3 变体）时，观察到了一些有趣的现象：\n\n与 Qwen-Math 不同，其他模型在「虚假奖励」方面表现得非常有限。\n\n（我们主要讨论 MATH-500 上的表现，有关 AMC、AIME 2024，尤其是训练数据截止日期之后的 AIME 2025 测试集的更多结果，请参阅完整论文 。）\n\n对真实标签进行首次健全性检查。它提高了所有模型的性能。在使用真实标签进行简单的 GRPO 时，我们看到所有模型系列都得到了改进，Qwen 和 Qwen-Math 的改进比 Llama 和 OLMo 模型更大。\n\n多数投票结果如何？先前的研究已提出提高模型一致性的方法。我们发现，这确实对大多数模型有益，但对 OLMo 却无益。\n\n如果我们只在响应包含 \\\\boxed {} 时才给予奖励会怎么样？实验发现，仅仅训练模型生成可解析的结果，就能在 Qwen 模型上获得巨大的性能提升 ——Qwen2.5-1.5B 的绝对提升高达 49.9%。但这种奖励会损害 Llama3.2-3B-Instruct 和 OLMo2-SFT-7B 的性能，分别降低 7.3% 和 5.3%。有趣的是，性能在达到峰值后开始逐渐下降。我们假设这是因为模型已经「学习」了格式，因此进一步的训练并不能为其提供更多信息。\n\n错误的奖励 —— 事情开始变得有趣起来。我们发现，它仍然显著地提高了 Qwen 模型的性能，但对 Llama 模型没有影响，并且损害了 OLMo-Base 和 OLMo-SFT 模型。\n\n最后，如果我们不观察模型本身，直接随机地将奖励 0 或 1 分配给模型，结果会怎样？这仍然有效吗？你猜对了，对于 Qwen 模型有效，但对于其他模型无效。\n\n请注意，随机奖励在 Qwen2.5-1.5B 中不起作用，并且仅在约 120 步后才在 Qwen2.5-7B 中开始起作用。基于这一观察，我们对其进行了更长时间的训练（300 步），发现与其他带信号的奖励相比，这些模型的收敛水平较低。\n\n这种依赖于架构的行为表明，RLVR 的有效性更多地取决于预先存在的模型能力，而不是监督信号的质量。\n\n给未来工作的实践性警示\n\nQwen 模型凭借其开源权重和在推理任务上的高性能，已成为开源社区中 RLVR 研究事实上的选择 —— 近期一系列关于 RLVR 的研究都是基于以 Qwen 为中心的实验得出结论的（请参阅原论文以获取列表）。\n\n然而，我们发现近期有两项研究表明，使用弱监督的 RLVR 在 Qwen 模型上效果良好，但这些结论无法泛化到其他模型家族。\n\n测试时强化学习：该论文提出在测试样本上进行 RLVR，并使用同策略 (on-policy) 下多数投票 (majority-voted) 的答案来计算奖励。\n\n单样本强化学习：这篇论文表明，仅用一个样本进行 RLVR 就可以达到与在标准训练集上进行 RLVR 相当的性能。\n\n我们在多种基础模型上评估了最近提出的两种弱监督 RL 方法 ——TTRL 和单样本 RL。我们发现，这些提出的训练奖励在 Qwen 模型上能够持续奏效。然而，除了少数例外，这些相同的信号在其他模型家族上通常无法带来收益，这与我们使用虚假奖励进行训练时观察到的有限泛化能力相呼应。\n\n因此，我们建议未来的 RLVR 研究应该在其他模型上进行验证。\n\n是什么让带有虚假奖励的 RLVR 生效呢？\n\n现在，你可能会好奇 —— 为什么会发生这种情况？？为什么所有这些虚假奖励 都在 Qwen-Math 模型上有效？魔法究竟在哪里？\n\n总的来说，我们假设 RLVR 训练结果的差异是由于每个模型在预训练过程中学到的特定推理策略不同所致。特别是，某些策略可能很容易被 RLVR 引出 (elicited)，而其他策略则可能更难显现，或者根本不存在。\n\n我们识别出了一种这样的预存策略：生成代码以辅助数学推理，Qwen-Math 能够有效利用它，而其他模型家族则利用得较少。我们将代码推理作为一项有启发性的案例研究来进行调查，但这并非完整的解释：我们观察到其他一些行为也很容易被引出，并且常常与性能相关，例如「不重复」。更多详情请参阅论文。\n\n个有启发性的案例研究：代码推理\n\n通过仔细分析，我们发现了一个关键洞察：即使在进行 RLVR 训练之前，Qwen-Math 也有 65.0% 的时间会生成 Python 代码来解决数学问题。更惊人的是，在没有代码执行器的情况下，它常常能生成正确的代码输出以及问题的正确答案。\n\n然而，这种频繁且高质量的代码推理能力在其他模型中并不存在。\n\n下面是一个 Qwen-Math-7B 如何能精确预测到小数点后 15 位 —— 比 iPhone 计算器还多一位的例子。\n\nQwen2.5-Math-7B 的代码推理回应示例。该问题从 MATH-500 测试集中随机选取。请注意，代码及其执行结果均由 Qwen2.5-Math-7B 自回归生成 。并未向模型提供外部代码解释器。\n\n在应用 RLVR 之后，无论奖励质量如何，这种代码推理的频率平均增加到 90% 以上。\n\n这种推理策略的转变——而非获取新的推理技能——似乎是驱动性能提升的原因。Qwen 模型通过 RLVR 训练学会了使用更多的代码推理。从语言推理到代码推理的转变有效地提升了性能。\n\n对于 Qwen-Math 和 Qwen 模型而言，代码频率与性能高度相关。代码越多 —> 正确答案越多，反之亦然。然而，在那些能产生代码但无法产生优质代码的模型（例如 OLMo2-7B-SFT）中，这种相关性是相反的。\n\n细粒度准确率追踪 — 我们仅从选择正确的推理策略中能获益多少？\n\n更有趣的是，我们追踪了那些在 RLVR 前后推理策略发生改变的问题，并分析了性能增益究竟从何而来。我们发现：\n\n虚假奖励在将模型行为转换为代码推理方面更为激进，并且极少将原本是代码推理的行为转变为自然语言推理。令人印象深刻的是，看起来基于虚假奖励的 RLVR 做出了正确的选择 —— 对于那些从自然语言推理切换到代码推理的问题，性能急剧提升了约 55%。另一方面，真实标签奖励则将自然语言推理的性能提升了 60.2%！下面的流程图包含了更详细的说明。\n\n我们进一步量化了每种策略转换行为对每个模型性能增益的贡献。看到这一点非常酷：如果一个模型擅长代码推理（代码准确率 > 语言准确率），RLVR 的增益主要来自于从语言到代码推理的转换；如果一个模型不擅长代码推理（代码准确率 < 语言准确率），RLVR 的增益则主要来自于从代码到语言推理的转换。\n\n在成功引导模型推理策略的奖励上平均计算，对整体性能增益的部分贡献。\n\n基于我们初步观察到的这些强相关性，我们假设代码推理是 Qwen 模型中导致良好数学性能的推理行为之一。\n\n为了验证我们的假设，我们通过提示和强化学习明确地约束模型生成代码推理。我们观察到，在所有测试的模型中，代码推理的频率与基准性能之间存在强相关性。（相关性的方向取决于特定模型的代码质量）。\n\n通过提示诱导代码推理\n\n我们仅仅通过提示模型，让它以「让我们用 Python 来解决这个问题。」 (Let's solve this using Python) 这句话来开始其回应。这个简单的做法显著提升了 Qwen-math 模型的性能，但却降低了 Llama 和 OLMo 模型的性能。\n\n通过强化学习 (RL) 诱导代码推理\n\n鉴于提示实验的成功，我们设计了一种额外的虚假奖励：只要模型的回应中包含字符串 python，就给予奖励。这极大地鼓励了所有模型去使用代码推理（在训练 50 步之后，超过 99% 的回应包含代码）。\n\n在下方的图表中，我们展示了类似的趋势，但如果我们使用强化学习来训练模型更多地使用 Python 代码，效果会更加显著。Qwen-Math 和 Qwen2.5-7B 模型的性能得到了提升，而其他模型的性能则有所下降。\n\n但为什么要随机？\n\n当我们看到训练曲线随着 random.random () < 0.5 产生的奖励而攀升时，我们感到困惑。 完全无意义、毫无信息的奖励，又怎能真正促进模型学习呢？\n\n这个悖论促使我们去寻找人工智能领域的「伦敦色散力」—— 就像电中性的原子之间仍然神秘地相互吸引一样。在深入研究 GRPO 后，我们发现裁剪项可能是关键。我们通过三种方法对裁剪因子进行了消融研究：\n\n(a) 在损失计算中直接禁用裁剪。\n\n(b) 调整训练和推演的批量大小，使推演模型与策略保持一致。\n\n(c) 减小推演批量大小以维持等效条件。\n\n方法 (b) 和 (c) 确保每个推演步骤只有一个梯度更新，从而自然地避免了裁剪约束。\n\n在 Qwen2.5-Math-7B 模型上，对 GRPO 中的裁剪项进行消融研究时的性能和代码推理频率。使用带有裁剪的随机奖励进行训练，会增加代码推理模式并提高性能。\n\n在使用标准 GRPO 裁剪的情况下，随机奖励为 Qwen2.5-Math-7B 带来了约 21% 的性能提升，并增加了代码推理模式。但是，当我们通过上述三种方法中的任何一种消除裁剪效应时，随机奖励并未带来任何改善。\n\n我们推测这是由于 GRPO 公式本身存在的偏差，我们将在下面详细说明。在裁剪的作用下，随机奖励并非教给模型任务的质量 —— 相反，它们触发了一种集中效应 ，使模型专注于其现有的推理模式分布。当禁用裁剪时，这种集中机制就完全消失了。\n\n启示与未来工作\n\n虚假奖励通过放大现有能力起作用： 带有虚假奖励的 RLVR 可以作为一种机制，来放大和凸显在预训练过程中学到的有用推理表示。当提出新的 RLVR 方法时，它们应该审视其带来的益处是否超越了揭示这些表面模式的层面，以研究真正学习发生的程度。\n\n在更多模型家族上测试关于 RL 方法的主张： 鉴于不同的模型家族具有不同的预存能力，我们建议未来的 RLVR 研究或许应该在多样化的模型上进行验证，而不是仅仅依赖于单一的「事实标准」选择，因为我们已经证明，即使使用完全虚假的奖励信号，也很容易在 Qwen 模型上获得明显的性能增益。\n\n首先了解你的模型： 我们应该更加意识到，在预训练期间学到的推理模式会严重影响下游的 RLVR 训练行为 —— 无论是在设计预训练方法时，还是在使用预训练模型进行 RLVR 时，都应如此。\n\n参考内容：\n\nhttps://rethink-rlvr.notion.site/Spurious-Rewards-Rethinking-Training-Signals-in-RLVR-1f4df34dac1880948858f95aeb88872f\n\n© THE END\n\n转载请联系本公众号获得授权\n\n投稿或寻求报道：liyazhou@jiqizhixin.com",
    "published_time": "2025-05-28T08:10:04.000Z",
    "download_time": "2025-05-30T00:26:28.286036",
    "visual_resource": [
      "screenshot/wechat_wx_311fcc7a.jpg"
    ],
    "meta-data": "{\"original_metadata\": {\"date_modified\": \"2025-05-28T08:10:04.000Z\", \"image\": \"https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWibPsWibzGOHYBMyw9VU4bSiaTicp2U1ibBmuzpqC0qGdrG76FicFAv7bNsq7hUotnTrSUtCtMJZeUuEvJQ/0?wx_fmt=jpeg\", \"id\": \"sFK1ukPNmI89kLREdPbckg\"}, \"extraction_info\": {\"account\": \"机器之心\", \"file_path\": \"./database/content/wechat/sFK1ukPNmI89kLREdPbckg.txt\"}}"
  },
  {
    "id": "vJlbt4snSxxNXqmmQc71uA",
    "source": "wechat",
    "url": "https://mp.weixin.qq.com/s/vJlbt4snSxxNXqmmQc71uA",
    "title": "华为盘古首次露出，昇腾原生72B MoE架构，SuperCLUE千亿内模型并列国内第一",
    "summary": "华为盘古团队近日发布突破性混合专家模型（MoE）——分组混合专家模型（MoGE），旨在解决传统MoE中专家激活不均衡导致的计算效率瓶颈。该架构通过引入分组机制，在4K昇腾大规模集群上实现专家负载均匀分布，并构建出盘古Pro MoE大模型。该模型（总参数72B，激活参数16B）在昇腾300I/800I平台上展现出卓越推理效率，最高可达1528 tokens/s。在最新SuperCLUE榜单上，盘古Pro MoE在千亿参数以内大模型中并列国内第一。此次创新不仅标志着大模型技术从“参数军备竞赛”转向“实效主义”，更凭借软硬件协同优化，为企业级应用的高效部署提供了新范式。",
    "keywords": [
      "华为盘古",
      "混合专家模型",
      "MoGE",
      "昇腾",
      "大模型",
      "SuperCLUE",
      "负载均衡",
      "推理效率"
    ],
    "area": [
      "人工智能",
      "深度学习",
      "大模型"
    ],
    "content": "标题：华为盘古首次露出，昇腾原生72B MoE架构，SuperCLUE千亿内模型并列国内第一\n公众号：机器之心\n--------------------------------------------------\n\n机器之心编辑部\n\n当前，混合专家模型（Mixture of Experts, MoE）在大型语言模型中的兴起，使得以较小的计算开销换取更大能力成为可能。然而，传统 MoE 普遍存在专家激活频次高度不均衡现象，当专家并行部署于不同硬件设备时，易引发系统效率瓶颈。\n\n为此，华为盘古团队提出分组混合专家模型（Mixture of Grouped Experts, MoGE），通过在专家选择阶段引入分组机制，可确保跨设备的计算负载均衡，成功在 4K 昇腾大规模集群进行高效训练。\n\n同时，基于 MoGE 架构构建的盘古 Pro MoE 大模型（72B 总参数、16B 激活参数）在昇腾 300I Duo 和 800I A2 可实现更优的专家负载分布与计算效率（321 tokens/s 和 1528 tokens/s）。\n\n中文技术报告：https://gitcode.com/ascend-tribe/pangu-pro-moe/tree/main\n\n英文技术报告：https://arxiv.org/pdf/2505.21411\n\n在模型能力方面，盘古 Pro MoE 在最新一期业界权威大模型榜单 SuperCLUE 上交出了超能打的成绩，实现了综合能力的领先。\n\n具体来说，和其他动辄千亿以上的大模型（如 DeepSeek-R1 具有 671B 参数）相比，盘古 Pro MoE 以 72B 总参数量达到了 59 分，千亿参数量以内大模型排行并列国内第一。并且，16B 激活参数量可以媲美其他厂商更大规模的模型。\n\n图源：https://www.superclueai.com/\n\n序言\n\n混合专家模型已成为大型语言模型领域的革新范式 —— 近年来，模型与数据集规模呈指数级增长，而 MoE 通过稀疏激活机制（仅针对每个 token 激活部分专家子集），在维持高表达能力的同时降低计算开销，使其在大规模应用中极具吸引力。\n\n然而，传统 MoE 架构面临的核心挑战是专家负载不均衡：当部分专家因过度专业化或 token 分配过载时，其他专家则处于低效利用状态。由于专家通常分布于多设备并行执行，MoE 模块的整体时延往往由承载最多 token 的设备决定，这种不均衡会严重损害计算效率与系统吞吐量。\n\n针对这一行业难题，华为盘古团队（以下简称团队）推出全新盘古 Pro MoE 大模型。\n\n该模型创新性提出分组均衡路由技术，通过硬约束的负载均衡策略，确保每个 token 在预定义的专家分组内激活等量专家，这样就天然的确保了跨设备的专家负载均衡；结合仿真优化算法，从层数、宽度、专家数等多维度优化资源分配，构建出昇腾亲和的盘古 Pro MoE 架构。同时，深度融合昇腾 300I Duo/800I A2 硬件加速架构的并行计算特性与算子级编译优化技术，实现从算法设计到系统落地的全栈创新。\n\n实验表明，盘古 Pro MoE 在同等算力条件下推理延迟更低，和业界同规模大模型相比，通用和复杂推理综合精度领先，为超大规模模型的工业化部署提供新范式。\n\n接下来将系统性解析盘古 Pro MoE 的核心技术原理与工程实现路径。\n\n昇腾原生的 MoGE 新架构\n\n从「无序激活」到「精准协同」\n\n问题背景\n\n传统 Top-K 路由存在无序激活的缺陷，也就是说，专家激活无限制，导致某些专家并行（EP）组负载过高（如某些组激活 4 个专家，某些组专家无激活），引发计算瓶颈和端到端延迟上升。\n\n如下图所示，子图 (a) 展示了在专家并行度 (EP)=4 时，从 24 个专家池中选取 8 个专家的激活专家分布对比；子图 (b) 则呈现了传统 MoE 和本文所提 MoGE 两种路由机制下估计的不平衡分数分布，其中分布估计的参数设定为 N=64（总专家数）、K=8（单 token 选择专家数）、M=8（组数）、∣X∣=16（输入序列长度）。\n\n通过可视化可观察到，传统 Top-K 路由易导致专家负载倾斜。这是基于 MoE 的大模型的行业痛点，负载不均衡导致硬件资源利用率低下，推理速度无法线性扩展，尤其在分布式训练和推理场景中问题加剧。\n\n分组均衡路由\n\n为了解决传统 Top-K 路由无序激活的问题，团队提出分组均衡路由的设计思想：强制每个 Token 在每个专家组内激活相同数量的专家（如每组激活 1 个专家，总激活数 = 组数 × 每组激活数），确保计算负载均匀分布。\n\n实现细节如下：\n\n专家均匀划分为 M 组（如 64 专家→8 组，每组 8 专家）；每组内独立进行 Top-K 路由（如每组 Top-2），全局激活数 = 组数 × 每组激活数。\n\n分组均衡路由的优势包括：1）吞吐友好： 组间负载差异为 0，避免跨组通信瓶颈；2）动态扩展性：Batch Size 变化时负载均衡性稳定。\n\nMoGE 架构示意图。N 个专家被均匀划分为 M 个不重叠的组并且每一个组内激活相同数量的专家。\n\n均衡辅助损失\n\n团队采用 Batch 级辅助均衡辅助损失函数，其形式定义为：\n\n其中超参数 α 控制辅助损失的强度。此处，f_i 表示批次 B 中被路由到专家 i 的 token 占比，p_i 则代表该专家在整个批次内的平均专家权重：\n\n式中 I {⋅} 为指示函数，s_i,t 表示 token t 对专家 i 的门控得分。\n\n架构仿真\n\n基于分组均衡路由的 MoGE 模块，团队继续通过仿真设计出昇腾亲和的模型架构。在模型设计过程中，采用分层策略，通过从粗粒度到细粒度的渐进式调优，平衡昇腾 300I Duo 和 800I A2 平台上的精度与推理效率。\n\n该策略包含三个阶段：首先，通过粗粒度筛选依据单服务器内存带宽和时延约束确定参数范围；其次，基于领域知识对潜在模型进行候选集缩减，缩小设计空间；最后，利用算子级仿真器评估候选模型性能。该仿真器关联系统硬件参数（如 TFLOPS、内存访问带宽、内存容量及互连拓扑），并自动搜索最优并行策略。\n\n通过分层策略与细粒度仿真，下图中标橘黄色星的模型在指定条件下展现出对昇腾 300I Duo 和 800I A2 平台的最佳亲和性，本文即采用该组超参数配置。\n\n推理性能\n\n盘古 Pro MoE 在昇腾平台上实现了混合并行与通信优化等软硬协同的系统优化、量化压缩等算法优化、MulAttention 和 SwiftGMM 等高性能算子优化，在一系列模型和系统联合优化的推理加速技术加持下，显著提升了模型的推理效率。\n\n在昇腾 300I Duo 平台的支持下，盘古 Pro MoE 单卡吞吐可达 201 tokens/s，并通过引入 MTP 解码和多 token 优化可进一步提升至 321 tokens/s，展现出百亿级大模型推理的极致性价比。\n\n基于昇腾 800I A2 平台，在低并发场景下模型可实现毫秒级响应；在高并发条件下单卡吞吐可达 1148 tokens/s，结合 MTP 解码等联合优化可提升至 1528 tokens/s，性能大幅领先于同等规模的 320 亿和 720 亿参数稠密模型。\n\n盘古 Pro MoE 全面赋能业务高效落地与大规模部署，助力各类应用场景实现高性能推理体验。\n\n模型能力\n\n业界公开测评\n\n盘古 Pro MoE 基础模型在跨语言多领域基准测试中展现出色性能：英语能力涵盖通用推理、阅读理解及常识推理；逻辑推理能力覆盖代码生成和中英双语数学问题等；中文评估则包含知识问答和阅读理解等，全面验证模型在复杂认知任务上的通用性与领域适应性。\n\n在监督微调与强化学习的双重优化下，盘古 Pro MoE 展现出卓越的复杂推理能力。\n\n模型在多领域评测体系进行测试：通用能力涵盖英语与中文，代码能力依托 LiveCodeBench 实时编程及 MBPP+，数学推理则通过 AIME 竞赛题、MATH-500 难题及中国数学奥林匹克 (CNMO) 验证。\n\n对比基线选取同规模前沿模型，包括开源的稠密模型 Qwen3-32B、GLM4-Z1-32B）及 MoE 模型（Llama4 Scout），盘古 Pro MoE 在复杂推理任务上展示出同规模最优的性能。\n\n硬件效能革命\n\nMoE 架构中的专家负载均衡与资源效率提升及模型行为稳定性增强相关。为探究此问题，本文对比分析了主流开源 MoE 模型 DeepSeek-V2 和盘古 Pro MoE 的专家负载分布。\n\n如下图所示，DeepSeek-V2 存在显著失衡，负载最高的专家处理高达 30% 的总 token 量；呈现高度集中现象。相比之下，盘古 Pro MoE 展现出近乎均匀的分布特性，各专家处理 token 占比均约 12.5%，与理论理想值高度吻合。\n\n这种均衡激活模式表明盘古 Pro MoE 对专家容量的高效利用，负载均衡对大规模 MoE 模型有助于实现高效可扩展性能。\n\n行业价值\n\n让「大模型」回归实用场景\n\n盘古 Pro MoE 的诞生，标志着大模型从「参数军备竞赛」转向「实效主义」：在企业级应用中，其动态负载均衡技术有效降低云端推理成本，支撑高并发实时场景；同时通过轻量化推理引擎适配华为昇腾系列芯片，赋能广大客户运行百亿级模型，为 AI 产业应用领域开辟新蓝海。\n\n华为以硬核创新重新定义大模型的价值。盘古 Pro MoE 的发布，不仅是 AI 领域的一次范式革命，更将为全球企业提供「高效、普惠」的智能底座。即刻体验技术突破，携手华为共启智能新时代！\n\n© THE END\n\n转载请联系本公众号获得授权\n\n投稿或寻求报道：liyazhou@jiqizhixin.com",
    "published_time": "2025-05-28T08:10:04.000Z",
    "download_time": "2025-05-30T00:26:37.976630",
    "visual_resource": [
      "screenshot/wechat_wx_7b5c2ec1.jpg"
    ],
    "meta-data": "{\"original_metadata\": {\"date_modified\": \"2025-05-28T08:10:04.000Z\", \"image\": \"https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWibPsWibzGOHYBMyw9VU4bSiaTj6gkAUia2Bq6PrC5QsFHibqsLicEVCGASJPXHjp8zPIjsVBRnx843SIVA/0?wx_fmt=jpeg\", \"id\": \"vJlbt4snSxxNXqmmQc71uA\"}, \"extraction_info\": {\"account\": \"机器之心\", \"file_path\": \"./database/content/wechat/vJlbt4snSxxNXqmmQc71uA.txt\"}}"
  },
  {
    "id": "Lcn4vdU_toUSMSWP-51Ovg",
    "source": "wechat",
    "url": "https://mp.weixin.qq.com/s/Lcn4vdU_toUSMSWP-51Ovg",
    "title": "爆火论文颠覆RL认知！「错误奖励」让LLM推理暴涨24.6%，学界惊了",
    "summary": "一项颠覆性研究发现，大语言模型（LLM）的增强学习（RL）训练中，即使是“伪奖励”（包括错误奖励、随机奖励或格式奖励）也能显著提升模型推理能力。华盛顿大学、AI2、UC伯克利团队实验证实，Qwen模型在伪奖励下数学推理性能飙升24.6%。研究揭示，这种提升并非模型真正“学会”新知识，而是通过GRPO算法的裁剪机制，促使其从自然语言推理转向更高效的“代码推理”策略。然而，该现象对Llama3、OLMo2等其他模型无效甚至有害，表明RL效果的有效性可能高度依赖模型预训练能力和特定算法特性，挑战了传统强化学习对高质量奖励信号的认知。",
    "keywords": [
      "伪奖励",
      "强化学习",
      "大语言模型",
      "数学推理",
      "代码推理",
      "GRPO",
      "Qwen",
      "AI训练"
    ],
    "area": [
      "人工智能",
      "大模型",
      "机器学习"
    ],
    "content": "标题：爆火论文颠覆RL认知！「错误奖励」让LLM推理暴涨24.6%，学界惊了\n公众号：AI生成未来\n--------------------------------------------------\n\n如您有工作需要分享，欢迎联系：aigc_to_future\n\n转载自：新智元\n\n如有侵权，联系删稿\n\n今早的一篇爆火论文，彻底颠覆了人们对「强化学习」的传统认知。\n\n仅用随机奖励，甚至是错误答案，也能让AI在数学推理中性能暴涨！\n\n来自华盛顿大学、AI2、UC伯克利研究团队证实，「伪奖励」（Spurious Rewards）也能带来LLM推理能力提升的惊喜。\n\n地址：https://rethink-rlvr.notion.site/Spurious-Rewards-Rethinking-Training-Signals-in-RLVR-1f4df34dac1880948858f95aeb88872f\n\n实验中，他们用伪奖励训练了Qwen2.5-Math-7B，在MATH-500数据集中发现：\n\n格式奖励性能提升16.4%；错误奖励提升24.6%；随机奖励提升21.4%。\n\n可见，伪奖励如同黑魔法，能够让Qwen的数学能力整体实现15-20%的飙升。\n\n然而，对Qwen有效的伪奖励在其他模型中，如Llama3、OLMo2，突然失效。\n\n值得一提的是，他们还发现RLVR可以激励Qwen2.5-Math的独特行为，其在代码推理上，性能从66.7%飙升至90%。\n\n即便是使用伪奖励，结果也是如此。\n\n当随机奖励可以大幅提升模型性能，就得重新思考：到底是RL在学习，还是在放大「先验」行为？\n\n谷歌DeepMind研究科学家Xidong Feng表示，这篇论文会让一大堆LLM+RL的研究受到质疑。\n\n另一位DeepMind科学家Andrew Lampinen称赞道，这确实是一个反常识典型案例。\n\n在大模型训练中，可验证奖励强化学习（RLVR）是一种提升推理能力常见的策略。\n\n传统观念认为，RLVR的成功离不开「高质量」的奖励信号。\n\n就好比，老师给学生的正确答案，或评分一样，只有「教得对」，才能「学得好」。\n\n而这项新研究，直接挑战了RLVR这一观念。\n\n如上所见，即使奖励信号完全随机，甚至给出误导性的信号，Qwen-Math依然能在数学推理上取得惊人的进步。\n\n这到底是怎么回事？对此，研究人员发起了疑问——\n\n单样本或无监督RLVR的训练信号从何而来？奖励提供有意义的RLVR训练信号的最低要求是什么？\n\n针对Qwen-Math、Llama 3.1、OLMo2模型，研究人员为其设置了三种有趣的伪奖励形式：\n\n· 格式奖励：仅回答包含 \\boxed{} 就给予奖励。这种格式在模型系统中已指定，类似指令遵循的概念。\n\n· 随机奖励：完全随机的反馈。简单来说，如果 random.random() < rate 则 1，否则 0\n\n· 错误奖励：故意提供错误的监督信号。\n\n在错误奖励中，人为构造错误且具有迷惑性答案的步骤：\n\n按频率对模型的输出进行排序；选取最常见的回答；如果该回答正确，则丢弃该样本；在模型最常见回答错误的子集上进行训练，并使用该特定回答作为训练标签。\n\n此外，在比较过程中，研究团队还引入了弱奖励：\n\n· 多数投票奖励：以多数投票的答案作为标签\n\n· 单样本RL：在单个样本上进行标准RLVR\n\n针对数学优化的Qwen模型，不论是在MATH、AMC，还是AIME基准上，数学推理性能都有大幅提升。\n\n然而，对于那些未针对数学推理优化模型，研究人员观察到了有趣的现象。\n\n与其他模型不同，Qwen-Math在「伪奖励」下表现提升甚微。具体来说，Qwen 2.5-7B在错误奖励下的性能28.5%，接近于真实奖励的33.3%。\n\n而在Llama3.1、OLMo2这两款模型上，剧情更是出现了大反转。\n\nLlama3.1-8B-Instruct在错误奖励在提升仅1.3%，而随机奖励性能暴减4.9%。\n\n与此同时，OLMo2-7B在伪奖励情况下，把性能衰退更是展现地淋漓尽致。\n\n此外，研究团队还发现，对真实标签（ground truth labels）进行简单的GRPO训练时，可以提升所有模型的性能。\n\n其中，Qwen和Qwen-Math模型，相比Llama和OLMo模型提升更为显著。\n\n在多数投票奖励中，此前已有研究提出用其来提升模型的一致性。实验中，作者发现它确实对大多数模型都有帮助，但对OLMo无效。\n\n针对格式奖励，他们还发现，仅教模型生成可解析的结果，就能在Qwen模型上获得「巨大」的性能提升。\n\n结果显示，Qwen2.5-1.5B绝对性能提升高达49.9%。\n\n但这种奖励，却让Llama3.2-3B-Instruct和OLMo2-SFT-7B的性能，分别降低了7.3%和5.3%。\n\n有趣的是，模型的性能在达到峰值后，逐渐下降。\n\n这里，研究人员推测这是因为模型已「学会」该格式，进一步训练不再提供更多信息。\n\n在错误奖励的实验中，Qwen模型性能仍显著提升 ，但其对Llama无影响，并损害了OLMo-Base和OLMo-SFT的性能。\n\n接下来，如果完全不看回答内容，随机分配0或1的奖励，会有效吗？\n\n答案是——对于Qwen是有效的，但对其他模型无效。\n\n值得注意的是，随机奖励对Qwen2.5-1.5B无效，且对Qwen2.5-7B需训练约120步后，才开始生效。\n\n因此，研究人员训练了更长时间（300 步），发现模型在随机奖励下的收敛水平低于其他有信号的奖励。\n\n这种依赖于模型架构的行为表明，RLVR的有效性更多取决于模型预训练时的能力，而非监督信号的质量。\n\n如今，Qwen因强大推理性能，已成为开源社区RLVR研究的默认选择。\n\n针对以上「伪奖励」的实验结果，研究人员对未来的研究给出了一些建议。\n\n近期两项研究表明，RLVR仅在「弱监督」下对Qwen模型有效，但这些结论无法推广到其他模型系列：\n\n1. 测试时强化学习（TTRL）：在测试阶段，实时收集多个输出答案，用多数投票结果作为奖励信号\n\n2. 单样本强化学习（1-shot RL）：仅用单个样本的RLVR训练，就能达到传统大规模训练集的效果\n\n因此，未来的RLVR研究，还应在其他模型上进行验证。\n\n现在，你可能会好奇——这到底是怎么回事？为什么这些伪奖励在Qwen-Math上有效？\n\n研究人员假设，RLVR训练结果的差异源于各模型在预训练期间，学习的特定推理策略的不同。\n\n特别是，某些策略可能更容易被RLVR激发，而其他策略可能更难以显现或完全缺乏。\n\n通过仔细分析，研究者发现了一个关键洞察：\n\nQwen-Math在RLVR训练前，就有65.0%的概率使用Python代码来解决数学问题。\n\n更令人印象深刻的是，即使没有代码执行器，它也常常能生成正确的代码输出以及问题的正确答案。\n\n然而，这种频繁且高质量的代码推理能力在其他模型中并不存在。在应用RLVR后，无论奖励质量如何，Qwen-Math 的代码推理频率平均增加到超过90%。\n\n如下示例中，展示了Qwen-Math-7B如何精确预测3√13到小数点后15位。\n\n令作者惊讶的是，这比iPhone计算器还多出一位精度。\n\n这种推理策略的转变，而非获得新的推理技能，似乎是性能提升的一种驱动力。\n\nQwen模型通过RLVR训练学会更多地使用代码推理——从语言推理到代码推理的转变有效地提升了性能。\n\n对于Qwen-Math和Qwen模型，代码使用频率与性能高度相关。\n\n代码越多，正确答案越多，反之亦然。\n\n然而，在那些能生成代码但无法生成高质量代码的模型，如OLMo2-7B-SFT，这种相关性是相反的。\n\n由此，研究人员得出——生成代码以辅助数学推理训练策略，Qwen-Math能加以有效利用，而其他模型家族则不然。\n\n更有趣的是，研究人员还追踪了RLVR前后推理策略发生切换的问题，并分析性能提升的具体来源。\n\n如下图所示，「伪奖励」在将模型行为切换到代码推理方面更为激进，且很少将原本的代码推理行为转为自然语言推理。\n\n令人印象深刻的是，伪奖励下的RLVR似乎做出了正确的选择——从自然语言推理切换到代码推理的问题，性能提升了约55%。\n\n另一方面，真实奖励则将自然语言推理的性能提升了60.2%！\n\n接下来，研究人员进一步量化了每种策略切换行为，对各模型性能提升的贡献。\n\n有趣的是，如果模型擅长代码推理（代码准确率>语言准确率），RLVR性能提升主要来自从语言推理到代码推理的切换；反之亦然。\n\n成功引导模型推理策略的奖励对总体性能提升的部分贡献平均值\n\n基于这些初步观察中的强相关性，他们假设代码推理是Qwen模型在数学任务中表现优异的一种推理行为。\n\n为了验证这一假设，研究人员通过提示和RL明确约束模型生成代码推理。\n\n结果观察到，所有测试模型的代码推理频率与基准测试性能之间存在强相关性。（相关性的方向取决于特定模型的代码质量）。\n\n· 通过提示诱导代码推理\n\n简单提示模型以「让我们用Python解决这个问题」开始回答，这显著提升了 Qwen-Math 模型的性能，但降低了Llama和OLMo模型的性能。\n\n· 通过强化学习诱导代码推理\n\n在提示实验成功后，研究者设计了一个额外的伪奖励，只要回答中包含字符串「python」，就给予奖励。\n\n这强烈鼓励所有模型使用代码推理，在第50步后代码推理占比>99%。\n\n在下图中，展示了类似趋势，但通过RL训练模型使用更多Python代码时，效果更加显著。Qwen-Math和Qwen2.5-7B的性能提升，而其他模型的性能下降。\n\n当研究人员看到使用 random.random() < 0.5 生成的奖励，使得训练曲线上升时，感到非常困惑。\n\n完全无意义的奖励——不提供任何信息的奖励——怎么可能帮助模型学习？\n\n这个悖论让我们开始寻找 AI 的「伦敦色散力」（London dispersion force of AI）——就像电中性原子之间仍然神秘地相互吸引一样。\n\n在深入研究GRPO后，作者发现裁剪（clipping）项可能是关键。他们通过以下三种方法对裁剪因子进行了消融实验：\n\n(a) 直接在损失计算中禁用裁剪，\n\n(b) 调整训练和rollout批大小，使展开模型与策略模型保持一致，\n\n(c) 减少展开大小以维持等效条件。\n\n方法 (b) 和 (c) 确保每次展开步骤仅进行一次梯度更新，自然避免了裁剪约束。\n\n在 Qwen2.5-Math-7B 上消融 GRPO 中裁剪项时的性能和代码推理频率。使用随机奖励并启用裁剪的训练增加了代码推理模式并提升了性能。\n\n总体而言，所有无裁剪运行的方差都很大，尤其是那些进行8次梯度更新，且物理关闭裁剪功能的运行（绿色）。\n\n这些无裁剪运行的平均值与启用裁剪和随机奖励的标准GRPO损失相比，呈现出平坦的曲线。\n\n在标准GRPO裁剪下，随机奖励让Qwen2.5-Math-7B性能提升21%，并增加了代码推理模式。\n\n但当研究人员通过上述三种方法消除裁剪效果时，随机奖励没有带来任何改进。他们推测，这是由于GRPO公式本身的偏见。\n\n在裁剪下，随机奖励并不会教授任务质量，而是触发了一种集中效应，使模型专注于其现有的推理模式分布。\n\n当裁剪被禁用时，这种集中机制完全消失。\n\nRulin Shao是华盛顿大学的二年级博士生，师从Pang Wei Koh教授和Luke Zettlemoyer教授。同时，她还是Meta的访问研究员，与Scott Yih及Mike Lewis共事。\n\n她在卡内基梅隆大学获得机器学习硕士学位，师从Eric Xing教授；本科毕业于西安交通大学，获数学学士学位。\n\n她的研究兴趣主要集中在信息检索与生成模型之间的协同增效作用。此外，也关注视觉语言多模态学习以及长上下文建模等领域。\n\nStella Li是华盛顿大学艾伦计算机科学与工程学院的二年级博士生，师从Yulia Tsvetkov教授。\n\n此前，她在约翰斯·霍普金斯大学获得了计算机科学、认知科学（侧重语言学）及应用数学（侧重统计学）专业的学士和硕士学位。期间，她曾在学校的语言与语音处理中心担任研究助理，师从Philipp Koehn教授和Kenton Murray教授。\n\n她的研究领域是自然语言处理，尤其是对运用计算方法建模乃至揭示认知过程深感兴趣。此外，研究兴趣还包括临床推理、社会推理、以人为本的NLP、多语言处理等诸多方向。\n\nRui Xin是华盛顿大学的一名博士生，师从Pang Wei Koh教授和Sewoong Oh教授。\n\n此前，他在杜克大学获得数学与计算机科学专业的学士学位，师从Cynthia Rudin教授和Margo Seltzer教授。\n\n他的研究兴趣是隐私保护机器学习。\n\nScott K. Geng是华盛顿大学的博士生，师从Pang Wei Koh教授和Ranjay Krishna教授。\n\n此前，他在哥伦比亚大学获得数学与计算机科学专业的学士学位，师从Carl Vondrick教授和Junfeng Yang教授。\n\n他对计算机视觉和自然语言处理等领域有着广泛的兴趣。\n\nhttps://x.com/StellaLisy/status/1927392717593526780\n\nhttps://rethink-rlvr.notion.site/Spurious-Rewards-Rethinking-Training-Signals-in-RLVR-1f4df34dac1880948858f95aeb88872f\n\n加入「AI生成未来社区」群聊，一起交流讨论，涉及 图像生成、视频生成、3D生成、具身智能等多个不同方向，备注不同方向邀请入群！可添加小助手备注方向加群！",
    "published_time": "2025-05-28T23:00:49.000Z",
    "download_time": "2025-05-30T00:25:10.330509",
    "visual_resource": [
      "screenshot/wechat_wx_8482a433.jpg"
    ],
    "meta-data": "{\"original_metadata\": {\"date_modified\": \"2025-05-28T23:00:49.000Z\", \"image\": \"https://mmbiz.qpic.cn/sz_mmbiz_jpg/mkhictoa3icogrJsxw5f4NIynCF7ds2Cp4NKGW7gic46CW9VlZX87Yn4znQrn5B6JwstAib4dud0bViaH2TnANZPOow/0?wx_fmt=jpeg\", \"id\": \"Lcn4vdU_toUSMSWP-51Ovg\"}, \"extraction_info\": {\"account\": \"AI生成未来\", \"file_path\": \"./database/content/wechat/Lcn4vdU_toUSMSWP-51Ovg.txt\"}}"
  },
  {
    "id": "OWw_xUXhxL7416tzF4c-7A",
    "source": "wechat",
    "url": "https://mp.weixin.qq.com/s/OWw_xUXhxL7416tzF4c-7A",
    "title": "修图模型照妖镜上线！ImgEdit-Bench三维「死亡评测」曝光，谁在裸泳一测便知",
    "summary": "近期，图像编辑领域迎来重大进展，一项名为ImgEdit的统一数据集及其评估基准ImgEdit-Bench正式发布。该数据集包含百万级高保真图像编辑对，涵盖单轮与多轮复杂编辑任务，并利用GPT-4o生成高质量指令。基于此，前沿模型ImgEdit-E1展现出卓越的编辑能力。ImgEdit-Bench则构建了系统性评估框架，通过指令遵循度、编辑质量等维度，全面评测现有图像编辑模型。测试结果显示，闭源模型如GPT-4o-image表现突出，而ImgEdit-E1在开源模型中脱颖而出，显著缩小了与顶尖模型的差距。该研究不仅弥补了现有数据集的不足，更为未来图像编辑模型的数据和架构升级提供了关键洞察，有力推动了整个领域的进步。",
    "keywords": [
      "图像编辑",
      "数据集",
      "评估基准",
      "大模型",
      "多模态",
      "生成式AI",
      "ImgEdit-Bench"
    ],
    "area": [
      "计算机视觉",
      "多模态",
      "生成式AI"
    ],
    "content": "标题：修图模型照妖镜上线！ImgEdit-Bench三维「死亡评测」曝光，谁在裸泳一测便知\n公众号：AI生成未来\n--------------------------------------------------\n\n如您有工作需要分享，欢迎联系：aigc_to_future\n\n作者：Yang Ye等\n\n解读：AI生成未来\n\n文章链接：https://arxiv.org/pdf/2505.20275 Git链接：https://github.com/PKU-YuanGroup/ImgEdit\n\n亮点直击\n\nImgEdit 提供高保真度的编辑对，包含精确、全面的指令，并涵盖更广泛的实用和挑战性编辑类型。先概述单轮和多轮编辑类型，接着详述数据流程。再介绍 ImgEdit-E1，一个基于 ImgEdit 训练的前沿编辑模型。最后展示数据集统计信息。\n\n本文定义两类编辑任务：单轮和多轮。单轮任务侧重于覆盖全面且实用的任务，而多轮任务则整合连续编辑场景中的指令和图像交互。\n\n单轮编辑基于实际编辑需求，将单轮任务分为四类（如下图1所示）：\n\n多轮编辑基于现有多轮理解基准和实际需求，定义多轮编辑的三大挑战（如下图1所示）：\n\n数据准备采用 LAION-Aesthetics 作为主数据集，因其场景多样性、高分辨率和更广的对象覆盖。筛选条件：短边≥1280像素且美学评分>4.75，得到60万张图像子集。使用GPT-4o生成简洁描述并提取可编辑对象及背景名词。\n\n对象定位与分割\n\n数据准备采用LAION-Aesthetics作为核心数据集。该数据集在场景多样性、分辨率以及物体类别的全面性上表现更优。仅保留短边≥1280像素且美学评分>4.75，得到60万张图像子集。使用GPT-4o重新生成简洁的文本描述，并提取可编辑对象及背景名词。每个候选实体通过开放词汇检测器进行定位，生成的边界框再由SAM2优化为分割掩码。由此，每个对象和背景区域均获得边界框与掩码。\n\n由于检测与分割并非完美，通过掩码裁剪每个对象，并计算：\n\n对相似度低或面积可忽略的区域进行剔除，确保剩余目标识别准确且视觉显著性满足后续编辑需求。具体而言，在背景替换任务中，要求编辑区域需占图像总面积40%以上。\n\n针对动态变化编辑任务，额外从内部视频库Open-Sora Plan收集了16万张以人物为主的图像对。通过时间子采样帧并利用GPT-4o标注动作信息，最终构成动态变化编辑子集。\n\n指令生成模块通过原始图像描述、编辑类型、边界框和目标物体作为条件输入生成指令。由于目标物体的精确定位对编辑至关重要，系统要求语言模型在编辑指令中嵌入物体位置和近似尺寸（以边界框为参考）。低性能LLMs易引入知识偏差导致低质量指令，因此采用尖端大语言模型（如GPT-4o），该模型不仅能理解多样化指令格式、生成概念丰富的编辑指令，还能高保真编码空间信息。多轮指令生成时，提供少量上下文示例让模型单次生成完整对话，再拆分为独立轮次，每轮对话限制2-3回合，包含添加、删除、替换、修改四类基础操作。\n\n修复工作流选用FLUX和SDXL作为基础生成模型，结合IP-Adapters、ControlNet等插件实现精准可控编辑。针对不同编辑场景构建定制化数据生产管线，例如：在视觉编辑任务中利用FLUX架构的上下文保持能力，通过FLUX-Redux控制语义一致性。生成图像在审美质量和编辑保真度上均超越现有数据集。\n\n后处理流程在基于物体面积、CLIP分数和美学分数的粗过滤基础上，使用GPT-4o进行精细过滤：为每个编辑对按编辑类型特定的评分标准分配质量分数，并提供详细评分依据供用户筛选。\n\n为评估所收集数据的质量，在ImgEdit数据集上训练了ImgEdit-E1模型。如下图2所示，该模型整合了视觉语言模型(VLM)、视觉编码器以及Diffusion-in-Transformer(DiT)主干网络。编辑指令与原始图像共同输入VLM处理，同时图像经由视觉编码器并行处理。VLM的隐藏状态与视觉编码器的图像特征分别通过多层感知机(MLP)映射后拼接，构成DiT的文本分支输入。训练采用两阶段策略：先优化MLP参数，随后对FLUX模块与MLP进行联合微调。\n\n包含120万高质量图像编辑对（含11万组多轮样本），覆盖13类编辑任务。相比现有数据集，具有更丰富语义、更详细指令、更高分辨率（平均短边1280像素）和更优编辑精度。其8.7k独特词汇量的指令多样性，以及经GPT-4o评估的最高编辑准确率（抽样1000例验证）尤为突出。像素级差异分析显示，局部编辑区域修改幅度显著大于其他数据集，且经专业检测器验证更难定位编辑痕迹，证实其图像质量优势。其物体提取和视觉编辑子集首次实现了高度主体一致性的编辑任务。完整统计数据见下图3与表1。\n\nImgEdit-Bench为单轮和多轮图像编辑任务提供系统性评估框架。先阐述基准数据集的构建原则，接着定义量化评估指标，再提出专用于图像编辑任务评估的模型ImgEdit-Judge。\n\n模型能力划分为‌基础编辑能力‌与‌复杂场景性能‌两类：\n\n基础编辑测试集我评估模型完成常规任务的能力，涵盖添加、删除、修改、替换、风格迁移、背景替换、动态调整、混合编辑、抠图处理9大类任务。所有测试图像均从互联网人工收集。为确保语义多样性，从六大超类别（人物、交通工具、自然、动物、建筑、生活必需品）中每类选取十个代表性概念。\n\n所有指令均由GPT-4o初步生成，并经过人工筛选。最终基准测试集包含734个测试用例，指令长度从简略到详尽不等。\n\n理解-定位-编辑(UGE)测试套件‌：人工精选47张互联网复杂场景图像，涵盖目标局部遮挡、同类多实例、伪装/低显著性物体、罕见编辑对象四大挑战。每图设计需综合空间推理、多目标协同操作、复合细粒度编辑或大规模修改的指令，提升单条指令的理解-定位-执行难度。\n\n多轮交互测试套件‌：从‌内容记忆‌、‌上下文理解‌、‌版本回溯‌三维度评估真实交互场景。每任务选取10张图像人工设计3轮对话流程，形成结构化测试序列。\n\n从‌指令遵循度‌、‌编辑质量‌、‌细节保留度‌三个维度量化模型性能：\n\n指令遵循度‌：衡量对指令语义理解和概念对齐能力，作为基础得分限制其他两项上限（编辑质量与细节保留得分不得超过该值）； 编辑质量‌：量化目标区域操作精度； 细节保留度‌：评估非编辑区域保真程度。 评分采用GPT-4o按1-5分制执行，每类任务配备详细评分细则。多轮场景中由人工评估员基于标准化指南对模型输出进行‌二元判断‌。\n\n真实性量化指标‌：引入‌伪造分数‌评估生成图像伪影可检测性，采用最新开源取证检测器FakeShield定位编辑痕迹。通过计算多类编辑数据集的召回率（以伪造为正类），横向对比结果验证生成图像的视觉真实性与编辑质量。\n\n鉴于视觉语言模型(VLM)评分相较于传统相似性指标更具合理性，且当前缺乏开源的图像编辑专用评估器，我们构建了包含20万条后处理评分记录的‌任务平衡与评分平衡语料库‌，用于微调Qwen2.5-VL-7B模型。通过人工研究验证，每张图像由人工标注员、Qwen2.5-VL-7B、ImgEdit-Judge与GPT-4o-mini并行评分，并选取60张图像进行深度分析。当模型评分与人工评分差异不超过1分时视为有效判定。如下图4所示，ImgEdit-Judge与人工评判一致性接近70%，显著优于GPT-4o-mini和原生Qwen2.5-VL模型。\n\n本节系统评估现有编辑模型与ImgEdit-E1性能：先阐述实验配置，再呈现结果定量与定性分析，最后展开深度讨论。\n\n单轮测试环境‌：闭源模型‌：GPT-4o-Image（Gemini-2.0-Flash未开放API） 开源模型‌：Step1X-Edit、Ultra-Edit、AnySD、MagicBrush、InstructPix2Pix及ImgEdit-E1 架构对比‌：除ImgEdit-E1与Step1X-Edit采用VLM文本编码器+DiT主干网络外，其余模型均基于UNet架构与预训练文本编码器。AnySD额外集成任务感知MoE模块。\n\n参数配置‌：输入分辨率：UltraEdit/AnySD输出512×512像素，其余模型输出1024×1024像素 重复实验：每个模型执行3次独立实验，报告平均得分 多轮测试‌：仅支持GPT-4o-Image与Gemini-2.0-Flash两模型\n\n定量评估首先对不同方法进行了全面的定性评估（结果如下图5所示）。开源模型与闭源模型之间存在显著性能差距：GPT-4o-image在所有维度上均优于开源模型，仅在部分高难度任务中稍显不足。该模型同时获得最高的UGE综合评分，展现出更强的理解能力、定位能力和编辑能力。\n\n在开源模型中，ImgEdit-E1与Step1X-Edit表现最佳，在部分任务上接近闭源模型水平。其中：\n\n值得注意的是，所有模型的编辑输出均获得极高的\"虚假评分\"，表明现有检测模型仍能轻易识别合成内容。\n\n在多轮编辑任务中，仅GPT-4o-Image与Gemini-2.0-flash展现两轮内的版本回溯能力。现有模型普遍存在内容记忆与理解缺陷，时而出现指代误解或前提丢失的情况，总体上对多轮编辑的支持仍不充分。\n\n定性评估‌选取了多种任务的代表性案例进行定性分析，如下图6所示。在改变自行车颜色同时保留积雪的任务中，仅有ImgEdit-E1和GPT-4o-Image成功达成。涉及物体移除的任务中，AnySD和Step1X-Edit生成结果模糊，Gemini错误地将路灯一并移除，其他模型则未能遵循指令。相比之下，ImgEdit-E1和GPT-4o-Image完美完成了任务。在背景修改任务中，ImgEdit-E1和Step1X-Edit在所有开源模型中与提示要求契合度最高。对于物体替换任务，闭源模型的处理结果明显更自然，而多数开源模型未能完成编辑。在色彩修改任务中，只有ImgEdit-E1和闭源模型在保留复杂细节的同时精准遵循了指令。此外，仅GPT-4o-Image和ImgEdit-E1成功完成了物体提取任务。\n\n根据基准测试结果，确定了影响编辑模型性能的三大关键因素：指令理解、区域定位和编辑执行。\n\n指令理解能力 指模型解析编辑指令的能力，主要由文本编码器决定，并显著影响编辑效果。传统模型使用T5或CLIP等编码器，虽能处理简单任务（如风格迁移），但在复杂的区域特定任务上表现欠佳。我们的评估显示，ImgEdit-E1和Step1X-Edit大幅优于其他开源模型，印证了更强文本编码器和更丰富文本特征的重要性。\n\n区域定位能力 指准确识别并定位待编辑区域的能力，既依赖指令理解，也取决于视觉感知水平。在需要精确定位的任务（如属性修改和物体提取）中，ImgEdit-E1的表现远超现有开源编辑模型，凸显了提示信息中空间定位的关键作用。\n\n编辑执行能力 指泛化各类编辑操作的能力，主要取决于训练数据的质量、规模和多样性。由于物体提取任务缺乏高质量数据，包括GPT-4o在内的其他模型在此类任务中表现不佳，这再次证明构建全面、高质量编辑数据集的必要性。\n\nImgEdit框架推动了图像编辑领域的发展：它克服了现有数据集的质量缺陷，引入了实用的编辑任务分类体系，并为未来数据集构建提供了稳健的流程。ImgEdit-E1的优异表现验证了该框架的可靠性。此外，ImgEdit-Bench从创新维度评估模型性能，为图像编辑模型的数据筛选和架构设计提供了重要洞见。通过提供高质量数据集、高效编辑方法和全面评估基准，本文的工作有助于缩小开源方案与顶尖闭源模型之间的差距，并将推动整个图像编辑领域的进步。\n\n[1] ImgEdit: A Unified Image Editing Dataset and Benchmark\n\n如果您觉得这篇文章对你有帮助或启发，请不吝点赞、在看、转发，让更多人受益。同时，欢迎给个星标⭐，以便第一时间收到我的最新推送。每一个互动都是对我最大的鼓励。让我们携手并进，共同探索未知，见证一个充满希望和伟大的未来！\n\n加入「AI生成未来社区」群聊，一起交流讨论，涉及 图像生成、视频生成、3D生成、具身智能等多个不同方向，备注不同方向邀请入群！可添加小助手备注方向加群！",
    "published_time": "2025-05-28T23:00:49.000Z",
    "download_time": "2025-05-30T00:25:22.422431",
    "visual_resource": [
      "screenshot/wechat_wx_36507f16.jpg"
    ],
    "meta-data": "{\"original_metadata\": {\"date_modified\": \"2025-05-28T23:00:49.000Z\", \"image\": \"https://mmbiz.qpic.cn/sz_mmbiz_jpg/mkhictoa3icogrJsxw5f4NIynCF7ds2Cp4Tia9iaYZ02C9hdiaeTp6EiaRnxsRQqOEWdSoQoiaXeibv8pVn4Pd21wEBTTw/0?wx_fmt=jpeg\", \"id\": \"OWw_xUXhxL7416tzF4c-7A\"}, \"extraction_info\": {\"account\": \"AI生成未来\", \"file_path\": \"./database/content/wechat/OWw_xUXhxL7416tzF4c-7A.txt\"}}"
  },
  {
    "id": "WeNdDVENi1DJciGjt1R97Q",
    "source": "wechat",
    "url": "https://mp.weixin.qq.com/s/WeNdDVENi1DJciGjt1R97Q",
    "title": "港科大Apple新研究：Tokens使用量减少，模型推理还更强了！",
    "summary": "港科大等研究团队提出Laser系列方法，旨在提升大语言模型（LLMs）推理任务的效率和准确率。针对现有LLMs在推理时消耗大量冗余Tokens的问题，Laser方法通过统一长度奖励框架、阶跃函数奖励机制及动态难度感知调整，有效平衡并显著提升了模型性能。实验证明，该方法能在大幅减少Tokens使用量的同时，提高模型推理准确率，例如在AIME24基准测试中，Tokens使用降低63%的同时性能提升6.1。研究揭示，Laser引导模型形成更简洁、高效的思考模式，减少冗余自省，实现准确性与简洁性之间的高级智能平衡，为未来高效AI推理奠定基础。",
    "keywords": [
      "大语言模型",
      "推理能力",
      "Tokens效率",
      "准确率",
      "Laser方法",
      "长度奖励",
      "动态调整"
    ],
    "area": [
      "大模型",
      "自然语言处理",
      "机器学习"
    ],
    "content": "标题：港科大Apple新研究：Tokens使用量减少，模型推理还更强了！\n公众号：AI生成未来\n--------------------------------------------------\n\n如您有工作需要分享，欢迎联系：aigc_to_future\n\n转载自：量子位\n\n如有侵权，联系删稿\n\n1+1等于几？\n\n现在的大推理模型（LRMs）已经展现出了非凡的推理能力。但是面对这样最简单的数学问题，现有的LRMs仍需要花费1400+的tokens来思考。\n\n那么有办法让LRMs在推理思考时更快更强吗？\n\n来自港科大、港城、滑铁卢大学和Apple的研究人员，最近提出了Laser系列新方法，实现了更好的模型效率和准确率平衡，做到了两者的共同显著提升。\n\n经过Laser和它的进阶方法Laser-D、Laser-DE训练后的模型，相较于训练前模型或者其他方法训练的模型，在准确率（Accuracy）和Tokens使用效率（Efficiency）上，同时取得了显著的提升。\n\n例如在知名复杂数学推理基准AIME24上，Laser-D和Laser-DE方法能够让模型在减少Tokens使用量63%的情况下，还继续提升6.1的性能。\n\n同时，研究人员还发现，经过训练的模型的思考过程里，冗余的“self-reflection”的比例大大降低，呈现出了一种更加健康的思考模式。\n\n这一研究也在𝕏引起了讨论：\n\n那么，Laser是如何让大模型推理又快又好的呢？\n\nLaser的研究人员首先发现，仅仅通过在强化学习过程中，对模型输出长度进行截断，就可以让训练后的模型的推理效率大幅提升。\n\n但这种方式，只能带来效率的提升，对于模型推理的准确性仍然有不小的损害。\n\n这意味着，推理的准确性和效率其实是一个平衡问题（Trade-off)，用更多的Tokens经常能取得更高的准确率，反之可能准确率就会受到损害。\n\n所以不应该仅仅关注某一指标，而应该将两者一同考虑，将问题的重点放在如何提升它们之间的平衡上面。\n\nLaser主要通过以下三点创新来平衡效率和准确率，以做到双提升：\n\n1、统一视角：提出了一套统一的框架来看待各类基于长度的奖励设计（Length-based Reward），并且将训练时截断这一简单方法也统一进了这一套框架内。\n\n2、Laser（Length-bAsed StEp Reward）：基于这一个统一框架，研究人员提出一种全新的基于目标长度和阶跃函数（Step Function）的奖励设计，规避了之前奖励设计存在的一些问题。\n\n3、动态且带有难度感知的Laser-D、Laser-DE方法：进一步的，研究人员提出了一套自动适配机制，来匹配不同难度下，不同题目的最优目标长度，让Laser达到最优的平衡。\n\n下面分别详细展开下。\n\n研究人员首先将直接截断训练的方法和先前不同的长度奖励设计联系起来，统一成了一套统一的奖励设计框架。\n\n具体而言，所有的这些方法，都可以看做是正确性的奖励C(x)、基于长度的奖励S(x)，以及一个控制开关λ(y)的组合。\n\n表中最右侧的可视化图片，展示了不同的方法对应的奖励函数的不同形状，其中蓝线代表正确的回复对应的奖励函数，红线代表错误的回复对应的奖励函数。\n\n从图上可以看到，训练时直接截断的方法，有一个很大的问题在于，当模型产生的回复很长的时候，正确回复和错误回复的奖励会杂糅在一起，使得模型无法正确区分回复的正确性，影响对对应数据的学习。\n\n为了解决训练截断中“无法区分正确但冗长的回答”这一问题，研究人员提出了Laser奖励函数。\n\nLaser不再“惩罚”所有长回答，而是对在目标长度以内生成的正确回答给予额外的正向奖励。\n\n这种阶跃函数（Step Function）形式的奖励机制，既鼓励简洁，也保留了对准确推理的认可，有效提升了准确率与效率的整体平衡。\n\n在进一步提升准确率与效率的平衡性上，研究人员提出了LASER-D方法：\n\n通过引入动态调整目标长度与题目难度感知机制，模型在训练过程中可以根据题目的难易程度，自适应设定更合适的token使用上限。\n\n这一机制通过监控模型在不同难度题目上的生成表现，动态评估不同难度题目的最优目标长度。\n\n具体来说，这一机制会定期使用一个小规模的监控集，对不同长度设定下的“预期正确回答数量”进行估算，并据此动态更新易/中/难三类题目的目标长度，几乎不增加训练开销，却显著提升了训练时奖励函数的灵活性与适应性。\n\n此外，他们还提出了LASER-DE。即在模型答错时，鼓励模型在更长长度上进行探索，尝试纠正错误、发现更优的推理路径，从而提升在困难题目上的表现。\n\n这一系列改进让LASER系列方法在多个benchmark上，实现了更优的性能-效率双赢效果。\n\n研究人员用DeepSeek-R1-Distill-Qwen的1.5B / 7B / 32B三个不同规模的模型，在MATH500、AIME24、AMC23、Olympiad Bench上进行了广泛实验。\n\n首先，他们通过调整各个方法在训练中的关键参数，绘制出不同方法在准确率（Accuracy）与token使用量（Efficiency）上的帕累托（Pareto）前沿。\n\n如图所示，在AIME2024和所有Benchmarks的平均上，原始模型（蓝色虚线）在token使用上代价巨大。\n\n而其他baselines方法虽然在效率上有所提升，但准确率下降明显。\n\n相比之下，LASER、LASER-D和LASER-DE（橙红色）始终位于原模型的准确率之上——\n\n在显著减少Tokens使用的同时，准确率还明显高于baseline，展现出强大的推理性能和推理效率双提升。\n\n特别是在AIME2024上，LASER-D在只使用原始模型1/3 Tokens的情况下，就能取得+6.1的准确率提升，证明其在复杂数学推理任务中的强大效果。\n\n在7B和32B模型上，LASER-D和LASER-DE相较于其他方法，在准确率和token使用效率上都取得了更优表现。\n\nDeepSeek-R1-Distill-Qwen-7B模型上，例如对于AIME24，LASER-D在7B模型上，在提升5.1的准确率的同时，平均token使用量还能降低60%，再次实现效率准确率双提升。\n\n研究人员还在多个领域外（OOD）测试集（GPQA、LSAT、MMLU）上对他们的方法进行了验证。\n\n实验结果表明，在OOD测试集上，LASER、LASER-D和LASER-DE取得良好的泛化，同样取得了最优的准确率与效率平衡，实现了准确率效率双提升。\n\n为了进一步理解LASER系列方法为何能在保持准确性的同时大幅压缩token使用，研究人员对模型推理行为的变化进行了分析。\n\n结果显示，经过LASER训练后，模型生成中冗余的Backtracking（反复自我否定）显著减少，而Verification（验证）、Subgoal Setting（子目标拆解）等关键推理行为得以保留甚至增强。\n\n这表明LASER不仅压缩了长度，还引导模型学会了更简洁、结构更清晰的思考方式。\n\n这也与文章开头展示的 “1+1等于几” 的案例相呼应——\n\n训练后的模型不再陷入反复的self-reflections，而是能直接识别出问题的关键，做出高效、准确的回应。\n\n团队表示，他们相信“能够准确且精简地表达”是高级智能的重要体现。\n\n真正强大的模型，应在准确性与简洁性之间实现良好平衡，而非只追求其中任何一者。\n\nLASER系列方法正是朝这一目标迈出的关键一步，它不仅压缩了推理长度，更提升了推理质量。\n\n团队也表示，未来将继续探索更灵活、更通用的方法，进一步推高模型的这一高级智能的能力。\n\n论文： https://arxiv.org/abs/2505.15612GitHub仓库： https://github.com/hkust-nlp/Laser\n\n加入「AI生成未来社区」群聊，一起交流讨论，涉及 图像生成、视频生成、3D生成、具身智能等多个不同方向，备注不同方向邀请入群！可添加小助手备注方向加群！",
    "published_time": "2025-05-28T23:00:49.000Z",
    "download_time": "2025-05-30T00:25:35.922775",
    "visual_resource": [
      "screenshot/wechat_wx_e453ed51.jpg"
    ],
    "meta-data": "{\"original_metadata\": {\"date_modified\": \"2025-05-28T23:00:49.000Z\", \"image\": \"https://mmbiz.qpic.cn/sz_mmbiz_jpg/mkhictoa3icogrJsxw5f4NIynCF7ds2Cp4JOK6e4g1icDxGK6mBiciajlM3ibnaFf1Je3k9mb3mSB2noMzjLSpkkNJ3Q/0?wx_fmt=jpeg\", \"id\": \"WeNdDVENi1DJciGjt1R97Q\"}, \"extraction_info\": {\"account\": \"AI生成未来\", \"file_path\": \"./database/content/wechat/WeNdDVENi1DJciGjt1R97Q.txt\"}}"
  },
  {
    "id": "GmHJ9VmoUk0u1ZSfHEbnjw",
    "source": "wechat",
    "url": "https://mp.weixin.qq.com/s/GmHJ9VmoUk0u1ZSfHEbnjw",
    "title": "金融支付 × 实时推荐：Milvus 如何支撑全球百亿交易的“猜你喜欢”",
    "summary": "某全球金融科技巨头通过引入向量数据库Milvus，成功支撑其每年百亿级交易的支付后实时推荐系统。面对海量数据洪流及现有数据库性能瓶颈，该企业发现Milvus在数据导入速度、弹性架构及开发友好性上表现突出，成功满足了高吞吐、低延迟的严苛要求。Milvus的应用显著提升了转化率及用户满意度，并已被扩展至智能客服等其他AI场景。项目复盘指出，企业级AI落地关键在于稳固的系统基础设施而非模型本身，强调了基础设施的战略价值及托管服务对业务创新的推动作用。",
    "keywords": [
      "金融支付",
      "实时推荐",
      "向量数据库",
      "Milvus",
      "人工智能",
      "弹性架构",
      "智能客服"
    ],
    "area": [
      "人工智能",
      "机器学习",
      "生成式AI"
    ],
    "content": "标题：金融支付 × 实时推荐：Milvus 如何支撑全球百亿交易的“猜你喜欢”\n公众号：Zilliz\n--------------------------------------------------\n\n这篇文章来自 Milvus 社区的一位资深用户投稿——他是某跨国金融科技巨头中， AI、ML与平台架构的技术负责人。在文中，他分享了自己在支付后推荐系统的设计实践、数据库选型的技术取舍，以及在大型企业中的一些职场体会与感悟。\n\n做支付的都知道一句老话：不管你背后跑了多少个系统、多少机器，点一下“支付”之后的那 1 秒钟，能再“顺便”给用户精准推荐点什么——才是成败的全部。\n\n作为全球最大的数字支付平台之一，我们公司旗下产品的活跃用户量上亿，系统一年跑上百亿笔交易，钱在后台像电流一样走来走去。\n\n业务上，我们支持 25 种货币跨境清算，覆盖 200 多个国家数千万商家，被上千万网站接入，为他们提供涵盖从个人点对点转账到企业级支付解决方案的全场景服务。\n\n用户量够多、并发够大、业务覆盖的区域文化与习俗隔阂够深，但这一切都还不算最难的——最难的是，在这种地狱级复杂度的系统里上马一套生成式 AI 驱动的智能推荐系统。\n\n这一块任务，主要是我所在的公司AI、ML、平台解决方案团队来负责。\n\n但公司的要求不止是要做一个智能推荐系统，我们还需要考虑在此基础上，构建一个多业务场景可复用的 AI / ML 基础设施，能通过实时事件流处理、生成式 AI（GenAI）等前沿技术，持续优化客户体验、提升运营自动化水平，并开拓创新业务增长点。\n\n一句话总结当时的处境：需求很急，难度不低。\n\n以下是我们的完整项目经历复盘：\n\n2023 年，我们启动了一项战略级项目，希望在用户结账那一刻，利用商户库存、消费上下文、用户行为、语言偏好……等一切可能的信号，用 AI 给出“买这个更划算”的实时推荐。\n\n听起来很简单，就是个平时很常见的“猜你喜欢”。然而项目推进过程中，团队遭遇了两大技术壁垒：\n\n首先是数据洪流快压垮现有平台：每年数百亿级交易、日更商品库存，别说调用模型跑推理，连数据 ingest 都已经爆堆。因为当时市面上的解决方案在性能和扩展性上均无法满足需求 ，为此，我们团队前几年还自己撸了个图数据库。\n\n其次是，现有向量数据库不给力：要实现毫秒级响应的个性化推荐，必须依赖高效的向量检索能力，要但当时的项目启动阶段，市面上的向量数据库产品普遍处于早期发展，既难以支撑高吞吐量的实时数据更新，也无法满足企业级生产环境对稳定性和低延迟的严苛要求，压测时根本过不了我们的生产环境要求。\n\n毕竟体量放在这里，性能、稳定、低延迟、低成本，我们全都要。\n\n那时候，我们一度以为得和之前一样，自己去自研一个向量数据库。\n\n那时候，我们测了不少市面上说得上名的产品，从 Weaviate 到 AlloyDB，结果都或多或少“踩线”了。你说它不行吧，好像也能凑合跑；你说它行吧，跑到后面问题又一个接一个。\n\n但 Milvus是个例外，整体的实测性能表现和横向扩展能力超出预期，成功满足了我们处理积压 AI 项目的各项技术指标。\n\n具体优势，可以从三方面展开讲讲：\n\n性能极限突破：我们每小时更新的商品库存数据会对系统吞吐量提出严苛要求。实测数据显示，Milvus 完成全量数据集导入的速度较其他方案快 5-10 倍。友商需要 8 小时才能完成的任务，Milvus 仅用不到 1 小时的时间即告完成，这种性能优势直接决定了系统的实时性上限。\n\n架构弹性优雅：中国有双十一，全球有黑五，支付系统出现流量洪峰波谷时常见情况。Milvus 的存算分离、动态扩容能力，可以极大提升资源调配效率，帮我们扛过了一个又一个购物狂欢节点。\n\n开发体验出奇地顺：Milvus的社区建设在全球范围内都有目共睹。向量数据库是个新兴产品，但Milvus清晰的文档体系与友好的开发者工具链，以及活跃的社区氛围，大幅降低了我们的学习成本，这种易用性为后续 AI 应用的快速迭代奠定了基础。\n\n解决了这些问题，我们仅剩的唯一顾虑是：一个开源项目，敢上我们的生产链路吗？\n\n后来 Zilliz （Milvus的实际项目开发团队）的工程师一出场，专业程度和企业支持直接把这事定了。\n\n整体推荐系统上线后，效果堪称惊艳。基于实时推荐、库存动态响应、商品池灵活调度，我们不仅提升了转化率，用户满意度指标也有了不小提升。在支付中，别小看任何 1%的指标改善，放在数亿笔交易的体量上，全是真金白银。\n\n前面说了，公司的要求是把智能推荐系统的经验，可以无缝迁移使用在其他业务，构建一个多业务场景可复用的 AI / ML 基础设施。因此，推荐系统成功上线并稳定运行后，我们最近正在将 Milvus 的应用场景拓展至智能客服领域。\n\n相比过去那种答非所问把用户总是惹毛的“智障”机器人，新一代多语言客服机器人可以通过向量语义理解技术自动处理80%以上的常规咨询，比我们原来那套基于关键词的 bot 高出一个维度不止。\n\n与此同时，使用向量数据库的好处是，这个客服系统可以实时对接知识库更新。过去，怎么能把系统更新、业务变化，能同步全球的客服系统，保证所有人都掌握理解信息，是个费时费力且工程量非常庞大的事情。经常会出现，系统已经更新，但客服的回答还是基于上一个版本，导致出现用户理解出现偏差，然后就是层出不穷的投诉。\n\n现在，使用向量数据库，信息对齐，只是一个数据库写入就能搞定的事情。在降低人工成本的同时，将客服响应速度提升至秒级。\n\n再下一步，我们在评估从Milvus迁移到Zilliz Cloud上。当前自建集群没问题，但维护起来说实话也挺花精力，采用全托管服务可减少一定的运维人力投入，让工程师更专注于业务创新而非基础设施维护。\n\n事后复盘，这个项目让我有几个深刻的体会：\n\n感悟一，落地中，模型不是瓶颈，系统才是。很多人谈 AI，都爱谈模型多强、推理多准，但现实是：模型只是一小部分。实际上，AI 项目 80% 的问题，最后都会落到“系统跟不上模型”的坑里，算力、存储、检索、并发——优化要一样一样做。\n\n感悟二，别低估基础设施的战略价值。Milvus 5-10 倍于友商的数据吞吐效率、弹性架构，对我们来说，不只是性能指标好看，而是它能决定整个 AI 项目的上线节奏和上线质量，乃至后续我们这个团队可以拿下的业务量。没有推荐系统又快又好的改造，就抢不到后续客服系统升级的机会。\n\n感悟三，别让工程师绑死在运维上。自建带来自由，但托管能带来速度。如果你在一个有AB Test氛围，或者劲对环绕的企业中，相信我相比于你通过自研给公司省了几块钱，老板更在意，你是不是能最早最快的完成别人干不了的事情。\n\n未来，企业级 AI 的落地速度，会越来越依赖平台基础设施的成熟度。用最好的产品，做可复用的架构，这个逻辑永远成立。\n\n金融交易如此，千行百业同样如此。",
    "published_time": "2025-05-28T11:22:11.000Z",
    "download_time": "2025-05-30T00:24:31.417200",
    "visual_resource": [
      "screenshot/wechat_wx_03c679f2.jpg"
    ],
    "meta-data": "{\"original_metadata\": {\"date_modified\": \"2025-05-28T11:22:11.000Z\", \"image\": \"https://mmbiz.qpic.cn/mmbiz_jpg/MqgA8Ylgeh6yJ4KpzElDOdIFxY3VlrlQZicgQbR2kgJblTvm8RhFgnpYO6Y4NOiba6TroyxDmb1DmjuibRtiaVicfUQ/0?wx_fmt=jpeg\", \"id\": \"GmHJ9VmoUk0u1ZSfHEbnjw\"}, \"extraction_info\": {\"account\": \"Zilliz\", \"file_path\": \"./database/content/wechat/GmHJ9VmoUk0u1ZSfHEbnjw.txt\"}}"
  },
  {
    "id": "56KREcz-xS2s0RCnlnQRYQ",
    "source": "wechat",
    "url": "https://mp.weixin.qq.com/s/56KREcz-xS2s0RCnlnQRYQ",
    "title": "完爆人物“一致性&风格化” | 支持Flux+任意风格LoRA，即插即用，效果媲美商业版GPT-4o!",
    "summary": "OmniConsistency系统旨在解决AI生成图像中人物“一致性”和“风格化”的关键挑战。该系统通过整合独特的风格学习与一致性学习阶段，动态利用预训练LoRA模块，实现了支持Flux及任意LoRA风格的即插即用功能，宣称其生成效果可媲美商用版GPT-4o。文章详细介绍了其核心优势、落地场景及操作指南，并提供了体验链接、代码与论文，展现了在提升专业图像内容生成（AIGC）方面的前沿进展。",
    "keywords": [
      "OmniConsistency",
      "人物一致性",
      "风格化",
      "LoRA",
      "AI生成图像",
      "AIGC",
      "Flux"
    ],
    "area": [
      "人工智能",
      "生成式AI",
      "计算机视觉"
    ],
    "content": "标题：完爆人物“一致性&风格化” | 支持Flux+任意风格LoRA，即插即用，效果媲美商业版GPT-4o!\n公众号：AI产品汇\n--------------------------------------------------\n\n打造一个有温度、有趣味、专业的全栈式AI&AIGC交流社区，\n\n用心写好每一篇文章！\n\n体验链接-https://huggingface.co/spaces/yiren98/OmniConsistency\n\n代码链接-https://github.com/showlab/OmniConsistency\n\n论文链接-https://arxiv.org/pdf/2505.18445\n\n01-OmniC核心优势\n\n02-OmniC落地场景\n\n03-OmniC上手指南\n\n步骤1-访问https://huggingface.co/spaces/yiren98/OmniConsistency链接\n\n步骤2-在上图中的红框中“上传图片/选择样例图片”\n\n步骤3-在上图中的绿框中“输入文本提示词”\n\n步骤4-在上图中的蓝框中“选择不同的生成格式”\n\n步骤5-点击“Generate”按钮，等待片刻即可\n\n04-OmniC基本原理\n\n上图展示了OmniConsistency的整体流程，包括风格学习和一致性学习阶段。\n\n如图a所示，在风格学习阶段，各个LoRA模块在专用数据集上接受训练，从而捕捉独特的风格细节。\n\n如图b所示，随后的一致性学习阶段优化了一致性LoRA，从而实现不同风格之间的结构和细节连贯性，动态整合了预训练的风格LoRA。\n\n05-OmniC性能评估\n\n关注我，AI热点早知道，AI算法早精通，AI产品早上线！\n\n禁止私自转载，需要转载请先征求我的同意！\n\n欢迎你的加入，让我们一起交流、讨论与成长！",
    "published_time": "2025-05-28T23:44:21.000Z",
    "download_time": "2025-05-30T00:24:07.526220",
    "visual_resource": [
      "screenshot/wechat_wx_9d656490.jpg"
    ],
    "meta-data": "{\"original_metadata\": {\"date_modified\": \"2025-05-28T23:44:21.000Z\", \"image\": \"https://mmbiz.qpic.cn/mmbiz_jpg/Qj1jLINT4WibXn9VMnR6rEBQ0OlqicUkXyMgpic0BFxBMNOuIeB1v0JdUpSJiaxGP21sUfJOeDTcXcJwDpc6umich6w/0?wx_fmt=jpeg\", \"id\": \"56KREcz-xS2s0RCnlnQRYQ\"}, \"extraction_info\": {\"account\": \"AI产品汇\", \"file_path\": \"./database/content/wechat/56KREcz-xS2s0RCnlnQRYQ.txt\"}}"
  },
  {
    "id": "2505.19897",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2505.19897",
    "title": "ScienceBoard：评估多模态自主智能体在现实科学工作流中的表现",
    "summary": "大型语言模型（LLMs）已将其影响力扩展到自然语言处理领域之外，极大地促进了跨学科研究的发展。近年来，研究人员开发了各种基于LLM的智能体，以协助跨多个方面和领域的科学发现进展。其中，能够像人类一样与操作系统交互的计算机使用智能体，正在为自动化科学问题解决和处理研究人员工作流中的 routine 任务铺平道路。认识到这些智能体的变革潜力，我们引入了ScienceBoard，它包含两个互补的贡献：（i）一个逼真、多域的环境，具有集成专业软件的动态且视觉丰富的科学工作流，智能体可以通过不同的接口进行自主交互，以加速复杂的科研任务和实验；（ii）一个具有挑战性的基准测试，包含169个由人类策划的高质量、经过严格验证的真实世界任务，涵盖生化、天文、地理信息学等领域的科学发现工作流。对具有最先进骨干模型（如GPT-4o、Claude 3.7、UI-TARS）的智能体进行的广泛评估表明，尽管取得了一些有前景的结果，但它们在可靠地辅助科学家完成复杂工作流方面仍远未达到要求，总体成功率仅为15%。深入分析进一步为解决当前智能体局限性和制定更有效的设计原则提供了宝贵见解，为构建用于科学发现的更强大智能体铺平了道路。我们的代码、环境和基准可在https://qiushisun.github.io/ScienceBoard-Home/获取。",
    "keywords": [
      "ScienceBoard",
      "多模态智能体",
      "自主智能体",
      "科学工作流",
      "评估基准"
    ],
    "area": [
      "人工智能",
      "智能体",
      "多模态"
    ],
    "content": "大型语言模型（LLMs）已将其影响力扩展到自然语言处理领域之外，极大地促进了跨学科研究的发展。近年来，研究人员开发了各种基于LLM的智能体，以协助跨多个方面和领域的科学发现进展。其中，能够像人类一样与操作系统交互的计算机使用智能体，正在为自动化科学问题解决和处理研究人员工作流中的 routine 任务铺平道路。认识到这些智能体的变革潜力，我们引入了ScienceBoard，它包含两个互补的贡献：（i）一个逼真、多域的环境，具有集成专业软件的动态且视觉丰富的科学工作流，智能体可以通过不同的接口进行自主交互，以加速复杂的科研任务和实验；（ii）一个具有挑战性的基准测试，包含169个由人类策划的高质量、经过严格验证的真实世界任务，涵盖生化、天文、地理信息学等领域的科学发现工作流。对具有最先进骨干模型（如GPT-4o、Claude 3.7、UI-TARS）的智能体进行的广泛评估表明，尽管取得了一些有前景的结果，但它们在可靠地辅助科学家完成复杂工作流方面仍远未达到要求，总体成功率仅为15%。深入分析进一步为解决当前智能体局限性和制定更有效的设计原则提供了宝贵见解，为构建用于科学发现的更强大智能体铺平了道路。我们的代码、环境和基准可在https://qiushisun.github.io/ScienceBoard-Home/获取。",
    "published_time": "2025-05-26T12:27:27.000Z",
    "download_time": "2025-05-29 07:03:02",
    "visual_resource": [
      "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.19897.png"
    ],
    "extra": {
      "url": "https://huggingface.co/papers/2505.19897",
      "arxiv_url": "https://arxiv.org/abs/2505.19897"
    }
  },
  {
    "id": "2505.19641",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2505.19641",
    "title": "SynLogic：大规模合成可验证的推理数据，用于学习逻辑推理及更广泛能力",
    "summary": "近期进展，例如 OpenAI-o1 和 DeepSeek R1，已展示了强化学习（RL）增强大型语言模型（LLMs）推理能力的潜力。尽管开源复现工作主要集中在数学和编程领域，但发展通用推理能力的方法和资源仍未得到充分探索。这种差距部分是由于收集适合RL的多样化且可验证推理数据的挑战造成的。我们假设逻辑推理对于发展通用推理能力至关重要，因为逻辑构成了推理的基本组成部分。在这项工作中，我们提出了 SynLogic，一个数据合成框架和数据集，能够大规模生成多样化的逻辑推理数据，涵盖 35 种不同的逻辑推理任务。SynLogic 方法能够对数据进行可控合成，可调节难度和数量。重要的是，所有示例都可以通过简单的规则进行验证，使其非常适合基于可验证奖励的RL训练。在我们的实验中，我们验证了基于 7B 和 32B 模型在 SynLogic 数据集上进行 RL 训练的有效性。SynLogic 在开源数据集中取得了最先进的逻辑推理性能，在 BBEH 基准上比 DeepSeek-R1-Distill-Qwen-32B 高出 6 分。此外，将 SynLogic 数据与数学和编程任务混合训练，提高了这些领域的训练效率，并显著增强了推理的泛化能力。值得注意的是，我们的混合训练模型在多个基准上优于 DeepSeek-R1-Zero-Qwen-32B。这些发现表明 SynLogic 是一个宝贵的资源，有助于提升 LLMs 更广泛的推理能力。我们在 https://github.com/MiniMax-AI/SynLogic 上开源了数据合成管道和 SynLogic 数据集。",
    "keywords": [
      "LLMs",
      "强化学习",
      "逻辑推理",
      "数据合成",
      "可验证推理数据"
    ],
    "area": [
      "人工智能",
      "机器学习",
      "大模型"
    ],
    "content": "近期进展，例如 OpenAI-o1 和 DeepSeek R1，已展示了强化学习（RL）增强大型语言模型（LLMs）推理能力的潜力。尽管开源复现工作主要集中在数学和编程领域，但发展通用推理能力的方法和资源仍未得到充分探索。这种差距部分是由于收集适合RL的多样化且可验证推理数据的挑战造成的。我们假设逻辑推理对于发展通用推理能力至关重要，因为逻辑构成了推理的基本组成部分。在这项工作中，我们提出了 SynLogic，一个数据合成框架和数据集，能够大规模生成多样化的逻辑推理数据，涵盖 35 种不同的逻辑推理任务。SynLogic 方法能够对数据进行可控合成，可调节难度和数量。重要的是，所有示例都可以通过简单的规则进行验证，使其非常适合基于可验证奖励的RL训练。在我们的实验中，我们验证了基于 7B 和 32B 模型在 SynLogic 数据集上进行 RL 训练的有效性。SynLogic 在开源数据集中取得了最先进的逻辑推理性能，在 BBEH 基准上比 DeepSeek-R1-Distill-Qwen-32B 高出 6 分。此外，将 SynLogic 数据与数学和编程任务混合训练，提高了这些领域的训练效率，并显著增强了推理的泛化能力。值得注意的是，我们的混合训练模型在多个基准上优于 DeepSeek-R1-Zero-Qwen-32B。这些发现表明 SynLogic 是一个宝贵的资源，有助于提升 LLMs 更广泛的推理能力。我们在 https://github.com/MiniMax-AI/SynLogic 上开源了数据合成管道和 SynLogic 数据集。",
    "published_time": "2025-05-26T07:59:36.000Z",
    "download_time": "2025-05-29 07:03:19",
    "visual_resource": [
      "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.19641.png"
    ],
    "extra": {
      "url": "https://huggingface.co/papers/2505.19641",
      "arxiv_url": "https://arxiv.org/abs/2505.19641"
    }
  },
  {
    "id": "2505.21189",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2505.21189",
    "title": "探索大型语言模型单步文本生成的潜在能力",
    "summary": "近期一项研究表明，大型语言模型（LLMs）可以通过仅使用一个经过特殊训练的输入嵌入进行自回归生成，重建惊人长度的文本——长达数千个词元。在这项工作中，我们探索了在没有自回归的情况下是否也能实现这种重建。我们发现，当仅提供两个学习到的嵌入时，冻结的LLMs可以在仅一次前向传播中生成数百个准确的词元。这揭示了LLMs一个令人惊讶但尚未得到充分探索的能力——无需迭代解码的多词元生成。我们研究了这些嵌入的行为，并深入探讨了它们编码的信息类型。我们还通过实证表明，尽管这些表示对于给定文本并非独一无二，但它们在嵌入空间中形成相互连接的局部区域——这一特性预示着学习一个专用编码器映射到该空间的潜力。",
    "keywords": [
      "大型语言模型",
      "单步生成",
      "嵌入",
      "非自回归",
      "潜在能力"
    ],
    "area": [
      "大模型",
      "自然语言处理",
      "生成式AI"
    ],
    "content": "近期一项研究表明，大型语言模型（LLMs）可以通过仅使用一个经过特殊训练的输入嵌入进行自回归生成，重建惊人长度的文本——长达数千个词元。在这项工作中，我们探索了在没有自回归的情况下是否也能实现这种重建。我们发现，当仅提供两个学习到的嵌入时，冻结的LLMs可以在仅一次前向传播中生成数百个准确的词元。这揭示了LLMs一个令人惊讶但尚未得到充分探索的能力——无需迭代解码的多词元生成。我们研究了这些嵌入的行为，并深入探讨了它们编码的信息类型。我们还通过实证表明，尽管这些表示对于给定文本并非独一无二，但它们在嵌入空间中形成相互连接的局部区域——这一特性预示着学习一个专用编码器映射到该空间的潜力。",
    "published_time": "2025-05-27T13:39:24.000Z",
    "download_time": "2025-05-29 07:03:26",
    "visual_resource": [
      "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.21189.png"
    ],
    "extra": {
      "url": "https://huggingface.co/papers/2505.21189",
      "arxiv_url": "https://arxiv.org/abs/2505.21189"
    }
  },
  {
    "id": "2505.20325",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2505.20325",
    "title": "凭直觉指引：基于强化内在置信的高效测试时缩放",
    "summary": "用于增强大语言模型 (LLM) 推理能力的测试时缩放 (TTS) 方法通常会产生高昂的计算成本，这主要是由于它们过度依赖外部过程奖励模型 (PRM) 或诸如优中选N (BoN) 之类的采样方法。本文介绍了 Guided by Gut (GG)，这是一种高效的自引导 TTS 框架，它无需昂贵的外部验证器模型即可达到 PRM 级别的性能。我们的方法采用了一种轻量级树搜索，该搜索仅由 LLM 的内在信号——标记级置信度和步骤新颖性——引导。一个关键创新是通过一个有针对性的强化学习微调阶段来提高内部置信度估计的可靠性。在具有挑战性的数学推理基准上的实证评估表明，GG 使小型模型（例如 15亿 参数）能够达到或超越显著更大的模型（例如 320亿-700亿 参数）的准确性，同时将 GPU 内存使用量降低多达 10 倍。与基于 PRM 的方法相比，GG 在实现可比准确性的同时，推理速度提高了 8 倍，内存使用量降低了 4-5 倍。此外，与 BoN 策略相比，GG 将 KV cache 内存使用量减少了大约 50%，从而促进了 TTS 技术的更高效和实际部署。",
    "keywords": [
      "LLM",
      "Test-Time Scaling",
      "强化学习",
      "内在置信",
      "效率"
    ],
    "area": [
      "大模型",
      "自然语言处理",
      "深度学习"
    ],
    "content": "用于增强大语言模型 (LLM) 推理能力的测试时缩放 (TTS) 方法通常会产生高昂的计算成本，这主要是由于它们过度依赖外部过程奖励模型 (PRM) 或诸如优中选N (BoN) 之类的采样方法。本文介绍了 Guided by Gut (GG)，这是一种高效的自引导 TTS 框架，它无需昂贵的外部验证器模型即可达到 PRM 级别的性能。我们的方法采用了一种轻量级树搜索，该搜索仅由 LLM 的内在信号——标记级置信度和步骤新颖性——引导。一个关键创新是通过一个有针对性的强化学习微调阶段来提高内部置信度估计的可靠性。在具有挑战性的数学推理基准上的实证评估表明，GG 使小型模型（例如 15亿 参数）能够达到或超越显著更大的模型（例如 320亿-700亿 参数）的准确性，同时将 GPU 内存使用量降低多达 10 倍。与基于 PRM 的方法相比，GG 在实现可比准确性的同时，推理速度提高了 8 倍，内存使用量降低了 4-5 倍。此外，与 BoN 策略相比，GG 将 KV cache 内存使用量减少了大约 50%，从而促进了 TTS 技术的更高效和实际部署。",
    "published_time": "2025-05-23T18:19:09.000Z",
    "download_time": "2025-05-29 07:03:44",
    "visual_resource": [
      "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.20325.png"
    ],
    "extra": {
      "url": "https://huggingface.co/papers/2505.20325",
      "arxiv_url": "https://arxiv.org/abs/2505.20325"
    }
  },
  {
    "id": "2505.21496",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2505.21496",
    "title": "UI-Genie：一种迭代提升基于多模态大语言模型的移动图形界面智能体的自改进方法",
    "summary": "本文介绍了 UI-Genie，这是一个自改进框架，旨在解决图形界面（GUI）智能体面临的两个关键挑战：轨迹结果验证困难和高质量训练数据难以扩展。这些挑战分别通过一个奖励模型和一个自改进流程来解决。奖励模型 UI-Genie-RM 采用图文交错架构，能够高效处理历史上下文，并统一了动作级和任务级奖励。为了支持 UI-Genie-RM 的训练，我们开发了精心设计的数据生成策略，包括基于规则的验证、受控轨迹破坏和难负例挖掘。为了解决第二个挑战，一个自改进流程通过在动态环境中进行奖励引导的探索和结果验证，逐步增强智能体和奖励模型，从而扩展了可解决的复杂 GUI 任务范围。为了训练模型，我们生成了 UI-Genie-RM-517k 和 UI-Genie-Agent-16k 数据集，建立了首个针对 GUI 智能体的奖励专用数据集，同时展示了无需人工标注即可生成高质量合成轨迹的能力。实验结果表明，通过三代数据-模型自改进，UI-Genie 在多个 GUI 智能体基准测试中取得了最先进的性能。我们开源了完整的框架代码和生成的数据集，以促进进一步研究，地址为 https://github.com/Euphoria16/UI-Genie。",
    "keywords": [
      "Mobile GUI Agents",
      "Self-improving",
      "MLLM",
      "Reward Model",
      "Data Generation"
    ],
    "area": [
      "智能体",
      "机器学习",
      "多模态"
    ],
    "content": "本文介绍了 UI-Genie，这是一个自改进框架，旨在解决图形界面（GUI）智能体面临的两个关键挑战：轨迹结果验证困难和高质量训练数据难以扩展。这些挑战分别通过一个奖励模型和一个自改进流程来解决。奖励模型 UI-Genie-RM 采用图文交错架构，能够高效处理历史上下文，并统一了动作级和任务级奖励。为了支持 UI-Genie-RM 的训练，我们开发了精心设计的数据生成策略，包括基于规则的验证、受控轨迹破坏和难负例挖掘。为了解决第二个挑战，一个自改进流程通过在动态环境中进行奖励引导的探索和结果验证，逐步增强智能体和奖励模型，从而扩展了可解决的复杂 GUI 任务范围。为了训练模型，我们生成了 UI-Genie-RM-517k 和 UI-Genie-Agent-16k 数据集，建立了首个针对 GUI 智能体的奖励专用数据集，同时展示了无需人工标注即可生成高质量合成轨迹的能力。实验结果表明，通过三代数据-模型自改进，UI-Genie 在多个 GUI 智能体基准测试中取得了最先进的性能。我们开源了完整的框架代码和生成的数据集，以促进进一步研究，地址为 https://github.com/Euphoria16/UI-Genie。",
    "published_time": "2025-05-27T17:58:06.000Z",
    "download_time": "2025-05-29 07:03:58",
    "visual_resource": [
      "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.21496.png"
    ],
    "extra": {
      "url": "https://huggingface.co/papers/2505.21496",
      "arxiv_url": "https://arxiv.org/abs/2505.21496"
    }
  },
  {
    "id": "2505.21493",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2505.21493",
    "title": "无需验证器的通用推理强化",
    "summary": "近期，利用DeepSeek-R1-Zero式、基于可验证奖励的强化学习（RL）来训练大型语言模型（LLMs）的新范式，已在代码和数学推理方面取得了令人瞩目的进展。然而，这种方法仅限于那些规则化回答验证可能的任务，并不能自然地推广到化学、医疗、工程、法律、生物、商业和经济等现实世界领域。当前实际的变通方法是使用额外的LLM作为基于模型的验证器；但这带来了对强大验证器LLM的依赖、易受奖励欺骗（reward hacking）以及训练期间在内存中维护验证器模型的实际负担等问题。为了解决这些问题并将DeepSeek-R1-Zero式训练扩展到通用推理领域，我们提出了一种无需验证器的方法（VeriFree），该方法绕过回答验证，转而使用RL直接最大化生成参考答案的概率。我们将VeriFree与基于验证器的方法进行比较，并证明了VeriFree除了具有显著的实际益处和降低的计算需求外，在MMLU-Pro、GPQA、SuperGPQA和数学相关基准上的广泛评估中达到甚至超越了基于验证器的方法。此外，我们从多个角度提供了对这种方法的见解：它是一个将策略和隐式验证器统一整合到单个模型中的优雅方法，也是一种变分优化方法。代码可在https://github.com/sail-sg/VeriFree获取。",
    "keywords": [
      "大型语言模型",
      "强化学习",
      "General Reasoning",
      "Verifier-Free",
      "变分优化"
    ],
    "area": [
      "大模型",
      "机器学习",
      "自然语言处理"
    ],
    "content": "近期，利用DeepSeek-R1-Zero式、基于可验证奖励的强化学习（RL）来训练大型语言模型（LLMs）的新范式，已在代码和数学推理方面取得了令人瞩目的进展。然而，这种方法仅限于那些规则化回答验证可能的任务，并不能自然地推广到化学、医疗、工程、法律、生物、商业和经济等现实世界领域。当前实际的变通方法是使用额外的LLM作为基于模型的验证器；但这带来了对强大验证器LLM的依赖、易受奖励欺骗（reward hacking）以及训练期间在内存中维护验证器模型的实际负担等问题。为了解决这些问题并将DeepSeek-R1-Zero式训练扩展到通用推理领域，我们提出了一种无需验证器的方法（VeriFree），该方法绕过回答验证，转而使用RL直接最大化生成参考答案的概率。我们将VeriFree与基于验证器的方法进行比较，并证明了VeriFree除了具有显著的实际益处和降低的计算需求外，在MMLU-Pro、GPQA、SuperGPQA和数学相关基准上的广泛评估中达到甚至超越了基于验证器的方法。此外，我们从多个角度提供了对这种方法的见解：它是一个将策略和隐式验证器统一整合到单个模型中的优雅方法，也是一种变分优化方法。代码可在https://github.com/sail-sg/VeriFree获取。",
    "published_time": "2025-05-27T17:56:27.000Z",
    "download_time": "2025-05-29 07:04:06",
    "visual_resource": [
      "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.21493.png"
    ],
    "extra": {
      "url": "https://huggingface.co/papers/2505.21493",
      "arxiv_url": "https://arxiv.org/abs/2505.21493"
    }
  },
  {
    "id": "2505.17952",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2505.17952",
    "title": "超越蒸馏：采用简约规则基强化学习拓展医疗大模型推理能力的极限",
    "summary": "提高大型语言模型（LLMs）在复杂任务上的表现并使其具备可解释的决策能力，尤其是在临床应用中，需要有效的推理能力。然而，这在没有通过对从闭源模型（如 GPT-4o）蒸馏出的昂贵的思维链（CoT）数据进行监督微调（SFT）的情况下仍然具有挑战性。在 G 工作中，我们提出了 AlphaMed，这是第一个医疗大模型，证明了推理能力可以完全通过强化学习（RL）产生，使用公共多项选择问答数据集上的简约规则基奖励，而无需依赖 SFT 或蒸馏的 CoT 数据。AlphaMed 在六个医疗问答基准测试上取得了最先进的结果，优于采用传统 SFT+RL 管线训练的模型。在有挑战性的基准测试（如 MedXpert）上，AlphaMed 甚至超过了更大的或闭源模型，例如 DeepSeek-V3-671B 和 Claude-3.5-Sonnet。为了理解成功的因素，我们进行了全面的以数据为中心的分析，由三个问题指导：(i) 简约规则基 RL 是否能在没有蒸馏 CoT 监督的情况下激励推理？(ii) 数据集的数量和多样性如何影响推理？(iii) 问题难度如何塑造推理的产生和泛化？我们的发现表明，数据集的信息量是推理表现的关键驱动因素，并且在信息丰富的多项选择问答数据上应用的简约 RL 能有效诱导推理，而无需 CoT 监督。我们还观察到不同基准测试之间存在差异趋势，突显了当前评估的局限性以及需要更具挑战性、面向推理的医疗问答基准测试的需求。",
    "keywords": [
      "医疗大模型",
      "推理",
      "强化学习",
      "简约规则基奖励",
      "医疗问答"
    ],
    "area": [
      "大模型",
      "自然语言处理",
      "机器学习"
    ],
    "content": "提高大型语言模型（LLMs）在复杂任务上的表现并使其具备可解释的决策能力，尤其是在临床应用中，需要有效的推理能力。然而，这在没有通过对从闭源模型（如 GPT-4o）蒸馏出的昂贵的思维链（CoT）数据进行监督微调（SFT）的情况下仍然具有挑战性。在 G 工作中，我们提出了 AlphaMed，这是第一个医疗大模型，证明了推理能力可以完全通过强化学习（RL）产生，使用公共多项选择问答数据集上的简约规则基奖励，而无需依赖 SFT 或蒸馏的 CoT 数据。AlphaMed 在六个医疗问答基准测试上取得了最先进的结果，优于采用传统 SFT+RL 管线训练的模型。在有挑战性的基准测试（如 MedXpert）上，AlphaMed 甚至超过了更大的或闭源模型，例如 DeepSeek-V3-671B 和 Claude-3.5-Sonnet。为了理解成功的因素，我们进行了全面的以数据为中心的分析，由三个问题指导：(i) 简约规则基 RL 是否能在没有蒸馏 CoT 监督的情况下激励推理？(ii) 数据集的数量和多样性如何影响推理？(iii) 问题难度如何塑造推理的产生和泛化？我们的发现表明，数据集的信息量是推理表现的关键驱动因素，并且在信息丰富的多项选择问答数据上应用的简约 RL 能有效诱导推理，而无需 CoT 监督。我们还观察到不同基准测试之间存在差异趋势，突显了当前评估的局限性以及需要更具挑战性、面向推理的医疗问答基准测试的需求。",
    "published_time": "2025-05-23T14:27:37.000Z",
    "download_time": "2025-05-29 07:04:21",
    "visual_resource": [
      "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.17952.png"
    ],
    "extra": {
      "url": "https://huggingface.co/papers/2505.17952",
      "arxiv_url": "https://arxiv.org/abs/2505.17952"
    }
  },
  {
    "id": "2505.16901",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2505.16901",
    "title": "代码图模型（CGM）：一种用于仓库级软件工程任务的图集成大语言模型",
    "summary": "近年来大语言模型（LLM）在函数级代码生成方面展现出潜力，然而仓库级软件工程任务仍然充满挑战。当前解决方案主要依赖于专有的LLM智能体，这带来了不可预测性和可访问性限制，并引发了对数据隐私和模型定制的担忧。本文探讨了开源LLM是否能在不依赖智能体方法的情况下有效解决仓库级任务。我们通过使LLM能够借助代码库中函数和文件的语义信息和结构依赖关系来理解它们，证明这是可能的。为此，我们引入了代码图模型（CGM），它将仓库代码图结构集成到LLM的注意力机制中，并使用专门的适配器将节点属性映射到LLM的输入空间。当与无智能体的图增强生成（RAG）框架结合时，我们的方法在使用开源Qwen2.5-72B模型在SWE-bench Lite基准测试上达到了43.00%的解决率。这一性能在开源权重模型中排名第一，在包含开源系统的系统方法中排名第二，整体排名第八，超过了先前最佳的基于开源模型的方法12.33%。",
    "keywords": [
      "大语言模型",
      "仓库级软件工程",
      "代码图",
      "图集成LLM",
      "RAG"
    ],
    "area": [
      "大模型",
      "深度学习",
      "生成式AI"
    ],
    "content": "近年来大语言模型（LLM）在函数级代码生成方面展现出潜力，然而仓库级软件工程任务仍然充满挑战。当前解决方案主要依赖于专有的LLM智能体，这带来了不可预测性和可访问性限制，并引发了对数据隐私和模型定制的担忧。本文探讨了开源LLM是否能在不依赖智能体方法的情况下有效解决仓库级任务。我们通过使LLM能够借助代码库中函数和文件的语义信息和结构依赖关系来理解它们，证明这是可能的。为此，我们引入了代码图模型（CGM），它将仓库代码图结构集成到LLM的注意力机制中，并使用专门的适配器将节点属性映射到LLM的输入空间。当与无智能体的图增强生成（RAG）框架结合时，我们的方法在使用开源Qwen2.5-72B模型在SWE-bench Lite基准测试上达到了43.00%的解决率。这一性能在开源权重模型中排名第一，在包含开源系统的系统方法中排名第二，整体排名第八，超过了先前最佳的基于开源模型的方法12.33%。",
    "published_time": "2025-05-22T17:00:55.000Z",
    "download_time": "2025-05-29 07:04:39",
    "visual_resource": [
      "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.16901.png"
    ],
    "extra": {
      "url": "https://huggingface.co/papers/2505.16901",
      "arxiv_url": "https://arxiv.org/abs/2505.16901"
    }
  },
  {
    "id": "2505.21334",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2505.21334",
    "title": "HoliTom：面向快速视频大语言模型的整体 Token 合并",
    "summary": "视频大语言模型 (video LLMs) 在视频理解方面表现出色，但由于冗余的视频 Token，面临显著的计算效率问题。现有的 Token 剪枝方法提供了一些解决方案。然而，在 LLM 内部进行处理的方法 (inner-LLM 剪枝)，如 FastV，在浅层会产生固有的计算开销。相比之下，在 LLM 之前执行 Token 剪枝的方法 (outer-LLM 剪枝) 主要解决单个帧内或有限时间窗口内的空间冗余，而忽略了长视频序列中关键的全局时间动态和关联性。这导致次优的时空冗余减少，并且未能充分利用视频的可压缩性。至关重要的是，结合这些策略的协同潜力及相互影响尚未得到探索。为了进一步减少冗余，我们引入了 HoliTom，一种新颖的、无需训练的整体 Token 合并框架。HoliTom 通过全局冗余感知的时序分割实现 outer-LLM 剪枝，随后进行时空合并，将视觉 Token 减少超过 90%，显著减轻了 LLM 的计算负担。作为补充，我们引入了一种基于 Token 相似性的鲁棒 inner-LLM 合并方法，旨在实现优异的性能并与 outer-LLM 剪枝兼容。评估表明，我们的方法在 LLaVA-OneVision-7B 上展现出良好的效率-性能权衡，将计算成本降低到原始 FLOPs 的 6.9%，同时保持了 99.1% 的原始性能。此外，我们在 Time-To-First-Token (TTFT) 上实现了 2.28 倍的减少，并在解码吞吐量上加速了 1.32 倍，突显了我们集成剪枝方法对高效视频 LLMs 推理的实际益处。",
    "keywords": [
      "Video LLMs",
      "Token Merging",
      "Computational Efficiency",
      "Outer-LLM",
      "Inner-LLM"
    ],
    "area": [
      "视频理解",
      "大模型",
      "多模态"
    ],
    "content": "视频大语言模型 (video LLMs) 在视频理解方面表现出色，但由于冗余的视频 Token，面临显著的计算效率问题。现有的 Token 剪枝方法提供了一些解决方案。然而，在 LLM 内部进行处理的方法 (inner-LLM 剪枝)，如 FastV，在浅层会产生固有的计算开销。相比之下，在 LLM 之前执行 Token 剪枝的方法 (outer-LLM 剪枝) 主要解决单个帧内或有限时间窗口内的空间冗余，而忽略了长视频序列中关键的全局时间动态和关联性。这导致次优的时空冗余减少，并且未能充分利用视频的可压缩性。至关重要的是，结合这些策略的协同潜力及相互影响尚未得到探索。为了进一步减少冗余，我们引入了 HoliTom，一种新颖的、无需训练的整体 Token 合并框架。HoliTom 通过全局冗余感知的时序分割实现 outer-LLM 剪枝，随后进行时空合并，将视觉 Token 减少超过 90%，显著减轻了 LLM 的计算负担。作为补充，我们引入了一种基于 Token 相似性的鲁棒 inner-LLM 合并方法，旨在实现优异的性能并与 outer-LLM 剪枝兼容。评估表明，我们的方法在 LLaVA-OneVision-7B 上展现出良好的效率-性能权衡，将计算成本降低到原始 FLOPs 的 6.9%，同时保持了 99.1% 的原始性能。此外，我们在 Time-To-First-Token (TTFT) 上实现了 2.28 倍的减少，并在解码吞吐量上加速了 1.32 倍，突显了我们集成剪枝方法对高效视频 LLMs 推理的实际益处。",
    "published_time": "2025-05-27T15:28:45.000Z",
    "download_time": "2025-05-29 07:04:53",
    "visual_resource": [
      "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.21334.png"
    ],
    "extra": {
      "url": "https://huggingface.co/papers/2505.21334",
      "arxiv_url": "https://arxiv.org/abs/2505.21334"
    }
  },
  {
    "id": "2505.20287",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2505.20287",
    "title": "MotionPro：一个用于图到视频生成的精确运动控制器",
    "summary": "利用交互式运动控制对图像进行动画处理已在图到视频（I2V）生成领域越来越受欢迎。现代方法通常依赖大型高斯核来扩展运动轨迹作为条件，但没有明确定义运动区域，这导致运动控制粗糙，并且无法区分物体和相机的移动。为了缓解这些问题，我们提出了 MotionPro，一个精确的运动控制器，它创新地利用区域轨迹和运动掩码来分别调节细粒度运动合成和识别目标运动类别（即物体或相机移动）。技术上，MotionPro 首先通过跟踪模型估计每个训练视频上的光流图，然后采样区域轨迹来模拟推理场景。与通过大型高斯核扩展光流不同，我们的区域轨迹方法通过直接利用局部区域内的轨迹实现更精确的控制，从而有效表征细粒度运动。同时，从预测的光流图导出运动掩码，以捕捉运动区域的整体运动动态。为了追求自然的运动控制，MotionPro 通过特征调制结合区域轨迹和运动掩码，进一步增强了视频去噪能力。更值得注意的是，我们精心构建了一个基准，即 MC-Bench，包含 1.1K 对用户标注的图像-轨迹对，用于评估细粒度和物体级别的 I2V 运动控制。在 WebVid-10M 和 MC-Bench 上进行的广泛实验证明了 MotionPro 的有效性。请参阅我们的项目页面以获取更多结果：https://zhw-zhang.github.io/MotionPro-page/。",
    "keywords": [
      "Image-to-Video Generation",
      "Precise Motion Control",
      "Region-wise Trajectory",
      "Motion Mask",
      "MC-Bench"
    ],
    "area": [
      "生成式AI",
      "计算机视觉",
      "深度学习"
    ],
    "content": "利用交互式运动控制对图像进行动画处理已在图到视频（I2V）生成领域越来越受欢迎。现代方法通常依赖大型高斯核来扩展运动轨迹作为条件，但没有明确定义运动区域，这导致运动控制粗糙，并且无法区分物体和相机的移动。为了缓解这些问题，我们提出了 MotionPro，一个精确的运动控制器，它创新地利用区域轨迹和运动掩码来分别调节细粒度运动合成和识别目标运动类别（即物体或相机移动）。技术上，MotionPro 首先通过跟踪模型估计每个训练视频上的光流图，然后采样区域轨迹来模拟推理场景。与通过大型高斯核扩展光流不同，我们的区域轨迹方法通过直接利用局部区域内的轨迹实现更精确的控制，从而有效表征细粒度运动。同时，从预测的光流图导出运动掩码，以捕捉运动区域的整体运动动态。为了追求自然的运动控制，MotionPro 通过特征调制结合区域轨迹和运动掩码，进一步增强了视频去噪能力。更值得注意的是，我们精心构建了一个基准，即 MC-Bench，包含 1.1K 对用户标注的图像-轨迹对，用于评估细粒度和物体级别的 I2V 运动控制。在 WebVid-10M 和 MC-Bench 上进行的广泛实验证明了 MotionPro 的有效性。请参阅我们的项目页面以获取更多结果：https://zhw-zhang.github.io/MotionPro-page/。",
    "published_time": "2025-05-26T17:59:03.000Z",
    "download_time": "2025-05-29 07:05:08",
    "visual_resource": [
      "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.20287.png"
    ],
    "extra": {
      "url": "https://huggingface.co/papers/2505.20287",
      "arxiv_url": "https://arxiv.org/abs/2505.20287"
    }
  },
  {
    "id": "2505.21505",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2505.21505",
    "title": "对齐如何增强大语言模型的多语言能力？基于语言神经元的视角",
    "summary": "多语言对齐是一种有效且具有代表性的范式，用于增强大语言模型的多语言能力，它将高资源语言的能力迁移到低资源语言。同时，一些关于特定语言神经元的研究表明，当处理不同语言时，大语言模型中存在选择性激活的特定语言神经元。这为在多语言场景中更具体地分析和理解大语言模型的机制提供了新视角。在这项工作中，我们提出了一种新的更精细粒度的神经元识别算法，该算法可以检测语言神经元（包括特定语言神经元和语言相关神经元）以及语言无关神经元。此外，基于不同类型神经元的分布特性，我们将大语言模型的多语言推理内部过程划分为四个部分： (1) 多语言理解，(2) 共享语义空间推理， (3) 多语言输出空间转换，和 (4) 词汇空间输出。此外，我们系统地分析了对齐前后模型的不同类型神经元。我们还分析了“自发多语言对齐”现象。总的来说，本工作基于不同类型的神经元进行了全面研究，为更好地理解多语言对齐和大语言模型的多语言能力提供了实证结果和有价值的见解。",
    "keywords": [
      "大语言模型",
      "多语言能力",
      "对齐",
      "语言神经元",
      "神经元分析"
    ],
    "area": [
      "大模型",
      "自然语言处理",
      "深度学习"
    ],
    "content": "多语言对齐是一种有效且具有代表性的范式，用于增强大语言模型的多语言能力，它将高资源语言的能力迁移到低资源语言。同时，一些关于特定语言神经元的研究表明，当处理不同语言时，大语言模型中存在选择性激活的特定语言神经元。这为在多语言场景中更具体地分析和理解大语言模型的机制提供了新视角。在这项工作中，我们提出了一种新的更精细粒度的神经元识别算法，该算法可以检测语言神经元（包括特定语言神经元和语言相关神经元）以及语言无关神经元。此外，基于不同类型神经元的分布特性，我们将大语言模型的多语言推理内部过程划分为四个部分： (1) 多语言理解，(2) 共享语义空间推理， (3) 多语言输出空间转换，和 (4) 词汇空间输出。此外，我们系统地分析了对齐前后模型的不同类型神经元。我们还分析了“自发多语言对齐”现象。总的来说，本工作基于不同类型的神经元进行了全面研究，为更好地理解多语言对齐和大语言模型的多语言能力提供了实证结果和有价值的见解。",
    "published_time": "2025-05-27T17:59:52.000Z",
    "download_time": "2025-05-29 07:05:25",
    "visual_resource": [
      "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.21505.png"
    ],
    "extra": {
      "url": "https://huggingface.co/papers/2505.21505",
      "arxiv_url": "https://arxiv.org/abs/2505.21505"
    }
  },
  {
    "id": "2505.14064",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2505.14064",
    "title": "NOVA：一项脑部MRI异常定位与临床推理的基准测试",
    "summary": "在许多实际应用中，部署的模型会遇到与训练数据不同的输入。分布外检测（Out-of-distribution detection）用于识别输入是否源于一个未曾见的分布，而开放世界识别（open-world recognition）则标记此类输入，以确保系统在不断出现先前未知的类别并需要处理时保持鲁棒性，而无需重新训练。基础模型和视觉-语言模型（Foundation and vision-language models）在庞大且多样化的数据集上进行预训练，期望在包括医学影像在内的各个领域实现广泛泛化。然而，仅使用少数常见异常类型对这些模型进行基准测试，会使得评估悄然退化为封闭集问题（closed-set problem），掩盖了在临床应用中遇到的罕见或真正新颖病症上的失效。\n因此，我们提出了 NOVA，这是一个具有挑战性的、源于真实世界、仅用于评估的基准数据集，包含大约900例脑部MRI扫描，涵盖281种罕见病理和异构采集协议。每个病例都包含丰富的临床描述和双盲专家标注的边界框。这些资源共同支持对异常定位、视觉描述和诊断推理进行联合评估。由于 NOVA 从未用于训练，它充当了分布外泛化的极端压力测试：模型必须弥合样本外观和语义空间上的分布差异。使用领先的视觉-语言模型（GPT-4o、Gemini 2.0 Flash和Qwen2.5-VL-72B）进行的基线测试结果显示，在所有任务上均出现显著的性能下降，从而将 NOVA 确立为一个严苛的测试平台，可用于推进能够检测、定位和推理真正未知异常的模型。",
    "keywords": [
      "脑部MRI",
      "异常定位",
      "临床推理",
      "分布外泛化",
      "NOVA 基准"
    ],
    "area": [
      "多模态",
      "计算机视觉",
      "大模型"
    ],
    "content": "在许多实际应用中，部署的模型会遇到与训练数据不同的输入。分布外检测（Out-of-distribution detection）用于识别输入是否源于一个未曾见的分布，而开放世界识别（open-world recognition）则标记此类输入，以确保系统在不断出现先前未知的类别并需要处理时保持鲁棒性，而无需重新训练。基础模型和视觉-语言模型（Foundation and vision-language models）在庞大且多样化的数据集上进行预训练，期望在包括医学影像在内的各个领域实现广泛泛化。然而，仅使用少数常见异常类型对这些模型进行基准测试，会使得评估悄然退化为封闭集问题（closed-set problem），掩盖了在临床应用中遇到的罕见或真正新颖病症上的失效。\n因此，我们提出了 NOVA，这是一个具有挑战性的、源于真实世界、仅用于评估的基准数据集，包含大约900例脑部MRI扫描，涵盖281种罕见病理和异构采集协议。每个病例都包含丰富的临床描述和双盲专家标注的边界框。这些资源共同支持对异常定位、视觉描述和诊断推理进行联合评估。由于 NOVA 从未用于训练，它充当了分布外泛化的极端压力测试：模型必须弥合样本外观和语义空间上的分布差异。使用领先的视觉-语言模型（GPT-4o、Gemini 2.0 Flash和Qwen2.5-VL-72B）进行的基线测试结果显示，在所有任务上均出现显著的性能下降，从而将 NOVA 确立为一个严苛的测试平台，可用于推进能够检测、定位和推理真正未知异常的模型。",
    "published_time": "2025-05-20T08:10:57.000Z",
    "download_time": "2025-05-29 07:05:46",
    "visual_resource": [
      "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.14064.png"
    ],
    "extra": {
      "url": "https://huggingface.co/papers/2505.14064",
      "arxiv_url": "https://arxiv.org/abs/2505.14064"
    }
  },
  {
    "id": "2505.17332",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2505.17332",
    "title": "SweEval：LLM真的会说脏话吗？一项面向企业应用的安全性测试基准",
    "summary": "企业客户越来越多地采用大型语言模型（LLM）执行关键的通信任务，例如撰写电子邮件、准备销售说辞和编写非正式消息。在不同区域部署此类模型需要它们理解多样化的文化和语言背景，并生成安全且尊重的回复。对于企业应用而言，通过有效识别和处理不安全或冒犯性语言，规避声誉风险、维护信任和确保合规性至关重要。为解决这一问题，我们引入了 SweEval，这是一个模拟真实世界场景的基准，场景涵盖了不同语气（积极或消极）和语境（正式或非正式）。提示会明确指示模型在完成任务时包含特定的脏话。该基准评估 LLM 是遵守还是抵制此类不恰当的指令，并评估它们在道德框架、文化细微差异和语言理解能力方面的对齐情况。为了推进构建面向企业应用及其他领域的道德对齐的 AI 系统的研究，我们发布了数据集和代码：https://github.com/amitbcp/multilingual_profanity。",
    "keywords": [
      "LLM",
      "企业应用",
      "安全基准",
      "冒犯性语言",
      "道德对齐"
    ],
    "area": [
      "人工智能",
      "大模型",
      "自然语言处理"
    ],
    "content": "企业客户越来越多地采用大型语言模型（LLM）执行关键的通信任务，例如撰写电子邮件、准备销售说辞和编写非正式消息。在不同区域部署此类模型需要它们理解多样化的文化和语言背景，并生成安全且尊重的回复。对于企业应用而言，通过有效识别和处理不安全或冒犯性语言，规避声誉风险、维护信任和确保合规性至关重要。为解决这一问题，我们引入了 SweEval，这是一个模拟真实世界场景的基准，场景涵盖了不同语气（积极或消极）和语境（正式或非正式）。提示会明确指示模型在完成任务时包含特定的脏话。该基准评估 LLM 是遵守还是抵制此类不恰当的指令，并评估它们在道德框架、文化细微差异和语言理解能力方面的对齐情况。为了推进构建面向企业应用及其他领域的道德对齐的 AI 系统的研究，我们发布了数据集和代码：https://github.com/amitbcp/multilingual_profanity。",
    "published_time": "2025-05-22T22:56:58.000Z",
    "download_time": "2025-05-29 07:06:02",
    "visual_resource": [
      "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.17332.png"
    ],
    "extra": {
      "url": "https://huggingface.co/papers/2505.17332",
      "arxiv_url": "https://arxiv.org/abs/2505.17332"
    }
  },
  {
    "id": "2505.20650",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2505.20650",
    "title": "FinTagging：一个面向大语言模型的财务信息提取与结构化基准测试",
    "summary": "我们引入FinTagging，这是首个全面的、表格感知的XBRL基准测试，旨在评估大语言模型（LLMs）在基于XBRL的财务报告背景下结构化信息提取和语义对齐的能力。与先前将XBRL标注过度简化为平面多类别分类且仅关注叙述性文本的基准测试不同，FinTagging将XBRL标注问题分解为两个子任务：FinNI用于财务实体提取，以及FinCL用于分类体系驱动的概念对齐。它要求模型联合提取事实并将其与完整的10k+ US-GAAP分类体系对齐，覆盖非结构化文本和结构化表格，从而实现真实、细粒度的评估。我们在零样本设置下评估了一系列多样化的大语言模型，系统分析了它们在两个子任务和整体标注准确性上的表现。我们的结果表明，虽然大语言模型在信息提取方面表现出强大的泛化能力，但在细粒度的概念对齐方面存在困难，尤其是在区分密切相关的分类体系条目时。这些发现突出了现有大语言模型在完全自动化XBRL标注方面的局限性，并强调需要改进语义推理和模式感知建模，以满足准确财务披露的需求。代码已在我们的GitHub仓库中提供，数据在我们的Hugging Face仓库中提供。",
    "keywords": [
      "FinTagging",
      "XBRL",
      "大语言模型 (LLM)",
      "财务信息提取",
      "语义对齐"
    ],
    "area": [
      "自然语言处理",
      "大模型",
      "机器学习"
    ],
    "content": "我们引入FinTagging，这是首个全面的、表格感知的XBRL基准测试，旨在评估大语言模型（LLMs）在基于XBRL的财务报告背景下结构化信息提取和语义对齐的能力。与先前将XBRL标注过度简化为平面多类别分类且仅关注叙述性文本的基准测试不同，FinTagging将XBRL标注问题分解为两个子任务：FinNI用于财务实体提取，以及FinCL用于分类体系驱动的概念对齐。它要求模型联合提取事实并将其与完整的10k+ US-GAAP分类体系对齐，覆盖非结构化文本和结构化表格，从而实现真实、细粒度的评估。我们在零样本设置下评估了一系列多样化的大语言模型，系统分析了它们在两个子任务和整体标注准确性上的表现。我们的结果表明，虽然大语言模型在信息提取方面表现出强大的泛化能力，但在细粒度的概念对齐方面存在困难，尤其是在区分密切相关的分类体系条目时。这些发现突出了现有大语言模型在完全自动化XBRL标注方面的局限性，并强调需要改进语义推理和模式感知建模，以满足准确财务披露的需求。代码已在我们的GitHub仓库中提供，数据在我们的Hugging Face仓库中提供。",
    "published_time": "2025-05-27T02:55:53.000Z",
    "download_time": "2025-05-29 07:06:21",
    "visual_resource": [
      "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.20650.png"
    ],
    "extra": {
      "url": "https://huggingface.co/papers/2505.20650",
      "arxiv_url": "https://arxiv.org/abs/2505.20650"
    }
  },
  {
    "id": "2505.21097",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2505.21097",
    "title": "思考者：学习快思与慢想",
    "summary": "近期研究表明，通过将强化学习（RL）应用于数学和编程等领域的问答（QA）任务，可以提升大型语言模型（LLMs）的推理能力。在长上下文长度下，LLMs 可能会学习执行搜索行为，DeepSeek R1 中观察到的自我修正行为即是例证。然而，这种搜索行为往往不够精确且缺乏信心，导致冗长冗余的回复，并突显出在直觉和验证方面的不足。受心理学中双过程理论的启发，我们对问答任务进行了简单修改，纳入了四个阶段：快思（Fast Thinking），要求 LLM 在严格的 token 预算内作答；验证（Verification），模型评估其初始回复；慢想（Slow Thinking），更审慎地细化初始回复；以及总结（Summarization），将前一阶段的细化提炼为精确的步骤。我们提出的任务将 Qwen2.5-1.5B 的平均准确率从 24.9% 提高到 27.9%，将 DeepSeek-R1-Qwen-1.5B 的平均准确率从 45.9% 提高到 49.8%。值得注意的是，对于 Qwen2.5-1.5B，仅快思模式就在使用少于 1000 个 token 的情况下达到了 26.8% 的准确率，显示出显著的推理效率提升。这些发现表明，直觉和审慎推理是不同的、互补的系统，可以通过有针对性的训练来获益。",
    "keywords": [
      "大型语言模型",
      "推理",
      "强化学习",
      "双过程理论",
      "快思慢想"
    ],
    "area": [
      "人工智能",
      "自然语言处理",
      "大模型"
    ],
    "content": "近期研究表明，通过将强化学习（RL）应用于数学和编程等领域的问答（QA）任务，可以提升大型语言模型（LLMs）的推理能力。在长上下文长度下，LLMs 可能会学习执行搜索行为，DeepSeek R1 中观察到的自我修正行为即是例证。然而，这种搜索行为往往不够精确且缺乏信心，导致冗长冗余的回复，并突显出在直觉和验证方面的不足。受心理学中双过程理论的启发，我们对问答任务进行了简单修改，纳入了四个阶段：快思（Fast Thinking），要求 LLM 在严格的 token 预算内作答；验证（Verification），模型评估其初始回复；慢想（Slow Thinking），更审慎地细化初始回复；以及总结（Summarization），将前一阶段的细化提炼为精确的步骤。我们提出的任务将 Qwen2.5-1.5B 的平均准确率从 24.9% 提高到 27.9%，将 DeepSeek-R1-Qwen-1.5B 的平均准确率从 45.9% 提高到 49.8%。值得注意的是，对于 Qwen2.5-1.5B，仅快思模式就在使用少于 1000 个 token 的情况下达到了 26.8% 的准确率，显示出显著的推理效率提升。这些发现表明，直觉和审慎推理是不同的、互补的系统，可以通过有针对性的训练来获益。",
    "published_time": "2025-05-27T12:22:46.000Z",
    "download_time": "2025-05-29 07:06:34",
    "visual_resource": [
      "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.21097.png"
    ],
    "extra": {
      "url": "https://huggingface.co/papers/2505.21097",
      "arxiv_url": "https://arxiv.org/abs/2505.21097"
    }
  },
  {
    "id": "2505.20793",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2505.20793",
    "title": "渲染感知型强化学习用于矢量图形生成",
    "summary": "可缩放矢量图形（SVG）提供了一种强大的格式，用于将视觉设计表示为可解释的代码。视觉-语言模型（VLMs）的最新进展通过将问题框架为代码生成任务并利用大规模预训练，实现了高质量的SVG生成。VLMs特别适合此任务，因为它们能够捕捉全局语义和细粒度视觉模式，同时在视觉、自然语言和代码领域之间迁移知识。然而，现有的VLMs方法通常难以生成忠实且高效的SVG，因为它们在训练过程中从未观察过渲染后的图像。尽管自回归SVG代码生成的微分渲染目前尚不可用，但渲染后的输出仍可以与原始输入进行比较，从而提供适合强化学习（RL）的评估反馈。我们引入了RLRF（基于渲染反馈的强化学习），这是一种RL方法，通过利用渲染后的SVG输出反馈来增强自回归VLMs中的SVG生成。给定输入图像，模型生成SVG序列，这些序列被渲染并与原始图像进行比较，以计算奖励。这种视觉保真度反馈指导模型生成更准确、高效且语义连贯的SVG。RLRF显著优于监督微调方法，解决了常见的失败模式，并实现了具有强大结构理解和泛化能力的高精度、高质量SVG生成。",
    "keywords": [
      "强化学习",
      "矢量图形生成",
      "视觉-语言模型",
      "渲染反馈",
      "SVG"
    ],
    "area": [
      "多模态",
      "计算机视觉",
      "生成式AI"
    ],
    "content": "可缩放矢量图形（SVG）提供了一种强大的格式，用于将视觉设计表示为可解释的代码。视觉-语言模型（VLMs）的最新进展通过将问题框架为代码生成任务并利用大规模预训练，实现了高质量的SVG生成。VLMs特别适合此任务，因为它们能够捕捉全局语义和细粒度视觉模式，同时在视觉、自然语言和代码领域之间迁移知识。然而，现有的VLMs方法通常难以生成忠实且高效的SVG，因为它们在训练过程中从未观察过渲染后的图像。尽管自回归SVG代码生成的微分渲染目前尚不可用，但渲染后的输出仍可以与原始输入进行比较，从而提供适合强化学习（RL）的评估反馈。我们引入了RLRF（基于渲染反馈的强化学习），这是一种RL方法，通过利用渲染后的SVG输出反馈来增强自回归VLMs中的SVG生成。给定输入图像，模型生成SVG序列，这些序列被渲染并与原始图像进行比较，以计算奖励。这种视觉保真度反馈指导模型生成更准确、高效且语义连贯的SVG。RLRF显著优于监督微调方法，解决了常见的失败模式，并实现了具有强大结构理解和泛化能力的高精度、高质量SVG生成。",
    "published_time": "2025-05-27T06:56:00.000Z",
    "download_time": "2025-05-29 07:06:49",
    "visual_resource": [
      "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.20793.png"
    ],
    "extra": {
      "url": "https://huggingface.co/papers/2505.20793",
      "arxiv_url": "https://arxiv.org/abs/2505.20793"
    }
  },
  {
    "id": "2505.17613",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2505.17613",
    "title": "MMMG：面向多任务多模态生成的综合可靠评估基准",
    "summary": "自动评估多模态生成是一个重大挑战，因为自动化指标往往难以可靠地与人类评估保持一致，特别是对于涉及多种模态的复杂任务。为解决此问题，我们提出了 MMMG，一个面向多模态生成的综合且与人类评估高度一致的基准，涵盖图像、音频、图文交错、音文交错等 4 种模态组合。该基准侧重于对生成模型构成重大挑战的任务，同时通过结合模型和程序实现了可靠的自动评估。MMMG 包含 49 项任务（其中 29 项为新开发），每项任务都设计了精心构建的评估流程，并包含 937 条指令，系统地评估多模态生成模型的推理、可控性以及其他关键能力。大量验证表明，MMMG 与人类评估高度一致，平均一致性达到 94.3%。对 24 个多模态生成模型的基准测试结果显示，尽管当前最先进的模型 GPT Image 在图像生成方面达到了 78.3% 的准确率，但在多模态推理和交错生成方面表现不足。此外，结果表明音频生成有很大的改进空间，这凸显了未来研究的一个重要方向。",
    "keywords": [
      "多模态生成",
      "评估基准",
      "多任务",
      "人类一致性",
      "自动评估"
    ],
    "area": [
      "多模态",
      "生成式AI",
      "人工智能"
    ],
    "content": "自动评估多模态生成是一个重大挑战，因为自动化指标往往难以可靠地与人类评估保持一致，特别是对于涉及多种模态的复杂任务。为解决此问题，我们提出了 MMMG，一个面向多模态生成的综合且与人类评估高度一致的基准，涵盖图像、音频、图文交错、音文交错等 4 种模态组合。该基准侧重于对生成模型构成重大挑战的任务，同时通过结合模型和程序实现了可靠的自动评估。MMMG 包含 49 项任务（其中 29 项为新开发），每项任务都设计了精心构建的评估流程，并包含 937 条指令，系统地评估多模态生成模型的推理、可控性以及其他关键能力。大量验证表明，MMMG 与人类评估高度一致，平均一致性达到 94.3%。对 24 个多模态生成模型的基准测试结果显示，尽管当前最先进的模型 GPT Image 在图像生成方面达到了 78.3% 的准确率，但在多模态推理和交错生成方面表现不足。此外，结果表明音频生成有很大的改进空间，这凸显了未来研究的一个重要方向。",
    "published_time": "2025-05-23T08:21:28.000Z",
    "download_time": "2025-05-29 07:07:07",
    "visual_resource": [
      "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.17613.png"
    ],
    "extra": {
      "url": "https://huggingface.co/papers/2505.17613",
      "arxiv_url": "https://arxiv.org/abs/2505.17613"
    }
  },
  {
    "id": "2505.20426",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2505.20426",
    "title": "MMPerspective：MLLM 理解透视吗？一个关于透视感知、推理和鲁棒性的综合基准测试",
    "summary": "理解透视是人类视觉感知的基本能力，然而，多模态大型语言模型（MLLM）在多大程度上内化了透视几何仍然不明确。我们引入了 MMPerspective，这是首个专门设计用于系统评估 MLLM 透视理解能力的基准测试，通过覆盖透视感知、推理和鲁棒性这三个互补维度的 10 个精心设计的任务来实现。我们的基准测试包含 2,711 个真实世界和合成的图像实例，以及 5,083 个问答对，旨在探测量点感知和计数、透视类型推理、三维空间中的直线关系理解、透视保持变换下的不变性等关键能力。通过对 43 个最先进的 MLLM 进行全面评估，我们揭示了显著的局限性：虽然模型在表层感知任务上表现出能力，但在组合推理和扰动下保持空间一致性方面仍面临困难。我们的分析进一步揭示了模型架构、规模与透视能力之间有趣的模式，突出了鲁棒性瓶颈以及思维链提示（chain-of-thought prompting）的益处。MMPerspective 为诊断和提升视觉-语言系统中的空间理解能力提供了一个有价值的测试平台。",
    "keywords": [
      "MLLM",
      "透视理解",
      "基准测试",
      "鲁棒性",
      "空间理解"
    ],
    "area": [
      "多模态",
      "大模型",
      "计算机视觉"
    ],
    "content": "理解透视是人类视觉感知的基本能力，然而，多模态大型语言模型（MLLM）在多大程度上内化了透视几何仍然不明确。我们引入了 MMPerspective，这是首个专门设计用于系统评估 MLLM 透视理解能力的基准测试，通过覆盖透视感知、推理和鲁棒性这三个互补维度的 10 个精心设计的任务来实现。我们的基准测试包含 2,711 个真实世界和合成的图像实例，以及 5,083 个问答对，旨在探测量点感知和计数、透视类型推理、三维空间中的直线关系理解、透视保持变换下的不变性等关键能力。通过对 43 个最先进的 MLLM 进行全面评估，我们揭示了显著的局限性：虽然模型在表层感知任务上表现出能力，但在组合推理和扰动下保持空间一致性方面仍面临困难。我们的分析进一步揭示了模型架构、规模与透视能力之间有趣的模式，突出了鲁棒性瓶颈以及思维链提示（chain-of-thought prompting）的益处。MMPerspective 为诊断和提升视觉-语言系统中的空间理解能力提供了一个有价值的测试平台。",
    "published_time": "2025-05-26T18:20:22.000Z",
    "download_time": "2025-05-29 07:07:22",
    "visual_resource": [
      "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.20426.png"
    ],
    "extra": {
      "url": "https://huggingface.co/papers/2505.20426",
      "arxiv_url": "https://arxiv.org/abs/2505.20426"
    }
  },
  {
    "id": "2505.18134",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2505.18134",
    "title": "VideoGameBench：视频-语言模型能否完成流行的电子游戏？",
    "summary": "视觉-语言模型（VLM）在对人类具有挑战性的编程和数学基准测试中取得了显著成果，但它们执行对人类而言自然而然的任务（如感知、空间导航和记忆管理）的能力仍未得到充分研究。真实的电子游戏利用人类固有的归纳偏置，旨在让人们直观地学习和掌握，这使得它们成为评估VLM此类能力的理想测试平台。为此，我们引入了VideoGameBench，这是一个包含10款20世纪90年代流行电子游戏的基准测试，VLM可以直接与这些游戏进行实时交互。VideoGameBench挑战模型仅依靠原始视觉输入以及对目标和控制的高级描述来完成整个游戏，这与依赖于游戏特定脚手架和辅助信息的现有设置显著不同。我们将其中三款游戏保密，以鼓励开发能够泛化到未知环境的解决方案。我们的实验表明，前沿的视频-语言模型难以在每款游戏中取得进展，往往止步于开局阶段。我们发现推理延迟是前沿模型在实时设置下的主要限制；因此，我们引入了VideoGameBench Lite，在这种设置下，游戏会在等待语言模型执行下一步动作时暂停。表现最好的模型 Gemini 2.5 Pro 仅完成了 VideoGameBench 的 0.48% 和 VideoGameBench Lite 的 1.6%。我们希望将上述人类技能形式化为这一基准测试，能够推动这些研究方向的进展。",
    "keywords": [
      "Vision-Language Models",
      "VideoGameBench",
      "电子游戏",
      "基准测试",
      "智能体"
    ],
    "area": [
      "多模态",
      "智能体",
      "视频理解"
    ],
    "content": "视觉-语言模型（VLM）在对人类具有挑战性的编程和数学基准测试中取得了显著成果，但它们执行对人类而言自然而然的任务（如感知、空间导航和记忆管理）的能力仍未得到充分研究。真实的电子游戏利用人类固有的归纳偏置，旨在让人们直观地学习和掌握，这使得它们成为评估VLM此类能力的理想测试平台。为此，我们引入了VideoGameBench，这是一个包含10款20世纪90年代流行电子游戏的基准测试，VLM可以直接与这些游戏进行实时交互。VideoGameBench挑战模型仅依靠原始视觉输入以及对目标和控制的高级描述来完成整个游戏，这与依赖于游戏特定脚手架和辅助信息的现有设置显著不同。我们将其中三款游戏保密，以鼓励开发能够泛化到未知环境的解决方案。我们的实验表明，前沿的视频-语言模型难以在每款游戏中取得进展，往往止步于开局阶段。我们发现推理延迟是前沿模型在实时设置下的主要限制；因此，我们引入了VideoGameBench Lite，在这种设置下，游戏会在等待语言模型执行下一步动作时暂停。表现最好的模型 Gemini 2.5 Pro 仅完成了 VideoGameBench 的 0.48% 和 VideoGameBench Lite 的 1.6%。我们希望将上述人类技能形式化为这一基准测试，能够推动这些研究方向的进展。",
    "published_time": "2025-05-23T17:43:27.000Z",
    "download_time": "2025-05-29 07:07:43",
    "visual_resource": [
      "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.18134.png"
    ],
    "extra": {
      "url": "https://huggingface.co/papers/2505.18134",
      "arxiv_url": "https://arxiv.org/abs/2505.18134"
    }
  },
  {
    "id": "2505.21471",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2505.21471",
    "title": "通过多智能体协作扩展LLM的外部知识输入超越上下文窗口限制",
    "summary": "随着推理和信息检索后训练技术的快速发展，大语言模型（LLMs）可以整合大量检索到的知识来解决复杂任务。然而，LLM有限的上下文窗口阻碍了外部知识输入的规模扩展，限制了进一步的性能提升，尤其对于需要大量外部知识的任务。现有的上下文窗口扩展方法不可避免地会导致信息丢失。基于LLM的多智能体方法作为一种新的范式出现，以分布式方式处理海量输入，在现有知识同步和推理过程中，我们发现了两个核心瓶颈。在这项工作中，我们开发了一个多智能体框架ExtAgents，以克服这些瓶颈并在无需长上下文训练的情况下，实现推理时知识集成的更好的可扩展性。通过我们增强的多跳问答测试$inftyBench+$以及包括长问卷生成在内的其他公共测试集进行基准测试，无论外部知识输入是否在上下文窗口内或超出，ExtAgents在相同外部知识输入量下，与现有非训练方法相比，显著提升了性能。此外，由于高度并行性，该方法保持了高效率。对LLM智能体在处理增加的外部知识输入方面的协作进行进一步研究，有望使实际应用受益。",
    "keywords": [
      "大语言模型",
      "外部知识",
      "多智能体协作",
      "上下文窗口",
      "可扩展性"
    ],
    "area": [
      "大模型",
      "智能体",
      "自然语言处理"
    ],
    "content": "随着推理和信息检索后训练技术的快速发展，大语言模型（LLMs）可以整合大量检索到的知识来解决复杂任务。然而，LLM有限的上下文窗口阻碍了外部知识输入的规模扩展，限制了进一步的性能提升，尤其对于需要大量外部知识的任务。现有的上下文窗口扩展方法不可避免地会导致信息丢失。基于LLM的多智能体方法作为一种新的范式出现，以分布式方式处理海量输入，在现有知识同步和推理过程中，我们发现了两个核心瓶颈。在这项工作中，我们开发了一个多智能体框架ExtAgents，以克服这些瓶颈并在无需长上下文训练的情况下，实现推理时知识集成的更好的可扩展性。通过我们增强的多跳问答测试$inftyBench+$以及包括长问卷生成在内的其他公共测试集进行基准测试，无论外部知识输入是否在上下文窗口内或超出，ExtAgents在相同外部知识输入量下，与现有非训练方法相比，显著提升了性能。此外，由于高度并行性，该方法保持了高效率。对LLM智能体在处理增加的外部知识输入方面的协作进行进一步研究，有望使实际应用受益。",
    "published_time": "2025-05-27T17:45:04.000Z",
    "download_time": "2025-05-29 07:08:02",
    "visual_resource": [
      "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.21471.png"
    ],
    "extra": {
      "url": "https://huggingface.co/papers/2505.21471",
      "arxiv_url": "https://arxiv.org/abs/2505.21471"
    }
  },
  {
    "id": "2505.21178",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2505.21178",
    "title": "先学走路再学跑！通过强化学习实现大型语言模型简洁推理",
    "summary": "随着测试时扩展成为大型语言模型（LLMs）发展的关键研究前沿，当代先进的后训练方法日益关注延长长链式思维（CoT）响应的生成长度，以增强推理能力，使其达到类似DeepSeek R1的表现。然而，最近的研究揭示了最先进的推理模型中存在一种持续的“过度思考”现象，表现为长CoT响应中出现过度的冗余或重复的思维模式。为了解决这个问题，本文提出了一个简单而有效的两阶段强化学习框架，用于实现LLMs的简洁推理，名为ConciseR。具体而言，第一阶段使用更多训练步数，旨在通过具有clip-higher和动态采样组件的群组相对策略优化（GRPO++）来激发模型的推理能力；第二阶段使用较少训练步数，通过长度感知群组相对策略优化（L-GRPO）明确增强简洁性并提高效率。值得注意的是，ConciseR遵循“先学走路再学跑”的原则，只有当一个样本的所有推演步骤都正确时，才会优化响应长度。大量实验结果表明，我们的ConciseR模型能生成更简洁的CoT推理响应，在AIME 2024、MATH-500、AMC 2023、Minerva和Olympiad等基准测试中，其性能优于近期零强化学习范式的最先进推理模型。",
    "keywords": [
      "大型语言模型",
      "强化学习",
      "链式思维",
      "推理",
      "简洁性"
    ],
    "area": [
      "大模型",
      "自然语言处理",
      "机器学习"
    ],
    "content": "随着测试时扩展成为大型语言模型（LLMs）发展的关键研究前沿，当代先进的后训练方法日益关注延长长链式思维（CoT）响应的生成长度，以增强推理能力，使其达到类似DeepSeek R1的表现。然而，最近的研究揭示了最先进的推理模型中存在一种持续的“过度思考”现象，表现为长CoT响应中出现过度的冗余或重复的思维模式。为了解决这个问题，本文提出了一个简单而有效的两阶段强化学习框架，用于实现LLMs的简洁推理，名为ConciseR。具体而言，第一阶段使用更多训练步数，旨在通过具有clip-higher和动态采样组件的群组相对策略优化（GRPO++）来激发模型的推理能力；第二阶段使用较少训练步数，通过长度感知群组相对策略优化（L-GRPO）明确增强简洁性并提高效率。值得注意的是，ConciseR遵循“先学走路再学跑”的原则，只有当一个样本的所有推演步骤都正确时，才会优化响应长度。大量实验结果表明，我们的ConciseR模型能生成更简洁的CoT推理响应，在AIME 2024、MATH-500、AMC 2023、Minerva和Olympiad等基准测试中，其性能优于近期零强化学习范式的最先进推理模型。",
    "published_time": "2025-05-27T13:29:51.000Z",
    "download_time": "2025-05-29 07:08:13",
    "visual_resource": [
      "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.21178.png"
    ],
    "extra": {
      "url": "https://huggingface.co/papers/2505.21178",
      "arxiv_url": "https://arxiv.org/abs/2505.21178"
    }
  },
  {
    "id": "2505.20561",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2505.20561",
    "title": "超越马尔可夫：基于贝叶斯自适应强化学习的大语言模型反思性探索",
    "summary": "通过强化学习（RL）训练的大语言模型（LLM）展现出强大的推理能力和涌现的反思性行为，例如回溯和纠错。然而，传统的马尔可夫强化学习将探索限于训练阶段，以学习最优确定性策略，并且仅通过当前状态依赖于历史上下文。因此，在马尔可夫强化学习训练过程中是否会涌现反思性推理，以及为什么它们在测试时有益，仍然不清楚。为了解决这个问题，我们将反思性探索重新构建在贝叶斯自适应强化学习框架内，该框架明确优化了在马尔可夫决策过程后验分布下的预期回报。这种贝叶斯公式通过信仰更新内在激励了最大化回报的利用和收集信息的探索。我们由此产生的算法BARL，指导LLM根据观察到的结果拼接和切换策略，为模型何时以及如何进行反思性探索提供了原则性指导。在合成任务和数学推理任务上的实验结果表明，BARL在测试时优于标准的马尔可夫强化学习方法，通过提高探索效率实现了卓越的标记效率。我们的代码可在 https://github.com/shenao-zhang/BARL 获取。",
    "keywords": [
      "大语言模型",
      "贝叶斯自适应强化学习",
      "反思性探索",
      "强化学习",
      "推理"
    ],
    "area": [
      "大模型",
      "强化学习",
      "自然语言处理"
    ],
    "content": "通过强化学习（RL）训练的大语言模型（LLM）展现出强大的推理能力和涌现的反思性行为，例如回溯和纠错。然而，传统的马尔可夫强化学习将探索限于训练阶段，以学习最优确定性策略，并且仅通过当前状态依赖于历史上下文。因此，在马尔可夫强化学习训练过程中是否会涌现反思性推理，以及为什么它们在测试时有益，仍然不清楚。为了解决这个问题，我们将反思性探索重新构建在贝叶斯自适应强化学习框架内，该框架明确优化了在马尔可夫决策过程后验分布下的预期回报。这种贝叶斯公式通过信仰更新内在激励了最大化回报的利用和收集信息的探索。我们由此产生的算法BARL，指导LLM根据观察到的结果拼接和切换策略，为模型何时以及如何进行反思性探索提供了原则性指导。在合成任务和数学推理任务上的实验结果表明，BARL在测试时优于标准的马尔可夫强化学习方法，通过提高探索效率实现了卓越的标记效率。我们的代码可在 https://github.com/shenao-zhang/BARL 获取。",
    "published_time": "2025-05-26T22:51:00.000Z",
    "download_time": "2025-05-29 07:08:32",
    "visual_resource": [
      "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.20561.png"
    ],
    "extra": {
      "url": "https://huggingface.co/papers/2505.20561",
      "arxiv_url": "https://arxiv.org/abs/2505.20561"
    }
  },
  {
    "id": "2505.20286",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2505.20286",
    "title": "Alita：实现可扩展智能体推理的通用智能体，具有最小预定义与最大自演化能力",
    "summary": "大型语言模型（LLMs）的最新进展使得智能体能够自主执行复杂的、开放式的任务。然而，许多现有框架过度依赖手动预定义的工具和工作流程，这阻碍了它们跨领域的适应性、可扩展性和泛化能力。在这项工作中，我们引入了 Alita——一款遵循“大道至简”（Simplicity is the ultimate sophistication）原则设计的通用智能体，通过最少的预定义和最大的自演化来实现可扩展的智能体推理。为了实现最小预定义，Alita 只配备了一个直接解决问题的组件，这比以往依赖大量手工制作的复杂工具和工作流程的方法要简单得多、整洁得多。这种简洁的设计增强了其泛化到具有挑战性问题的潜力，不受工具的限制。为了实现最大自演化，我们通过提供一套通用的组件来增强 Alita 的创造力，使其能够自主构建、完善和重用外部能力，方法是从开源生成与任务相关的模型上下文协议（MCPs），这有助于实现可扩展的智能体推理。值得注意的是，在 GAIA 基准测试验证数据集上，Alita 在通用智能体中取得了领先地位，pass@1 准确率达到 75.15%，pass@3 达到 87.27%；在 Mathvista 和 PathVQA 上，pass@1 准确率分别为 74.00% 和 52.00%，优于许多复杂度远高于它的智能体系统。更多详情将更新至 https://github.com/CharlesQ9/Alita。",
    "keywords": [
      "通用智能体",
      "智能体推理",
      "大模型",
      "自演化",
      "可扩展性"
    ],
    "area": [
      "人工智能",
      "大模型",
      "智能体"
    ],
    "content": "大型语言模型（LLMs）的最新进展使得智能体能够自主执行复杂的、开放式的任务。然而，许多现有框架过度依赖手动预定义的工具和工作流程，这阻碍了它们跨领域的适应性、可扩展性和泛化能力。在这项工作中，我们引入了 Alita——一款遵循“大道至简”（Simplicity is the ultimate sophistication）原则设计的通用智能体，通过最少的预定义和最大的自演化来实现可扩展的智能体推理。为了实现最小预定义，Alita 只配备了一个直接解决问题的组件，这比以往依赖大量手工制作的复杂工具和工作流程的方法要简单得多、整洁得多。这种简洁的设计增强了其泛化到具有挑战性问题的潜力，不受工具的限制。为了实现最大自演化，我们通过提供一套通用的组件来增强 Alita 的创造力，使其能够自主构建、完善和重用外部能力，方法是从开源生成与任务相关的模型上下文协议（MCPs），这有助于实现可扩展的智能体推理。值得注意的是，在 GAIA 基准测试验证数据集上，Alita 在通用智能体中取得了领先地位，pass@1 准确率达到 75.15%，pass@3 达到 87.27%；在 Mathvista 和 PathVQA 上，pass@1 准确率分别为 74.00% 和 52.00%，优于许多复杂度远高于它的智能体系统。更多详情将更新至 https://github.com/CharlesQ9/Alita。",
    "published_time": "2025-05-26T17:58:53.000Z",
    "download_time": "2025-05-29 07:08:51",
    "visual_resource": [
      "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.20286.png"
    ],
    "extra": {
      "url": "https://huggingface.co/papers/2505.20286",
      "arxiv_url": "https://arxiv.org/abs/2505.20286"
    }
  },
  {
    "id": "2505.19433",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2505.19433",
    "title": "压缩后的大语言模型能真正具备智能体能力吗？LLM压缩中智能体能力的实证评估",
    "summary": "训练后压缩降低了大语言模型（LLMs）的计算和内存成本，从而实现资源高效部署。然而，现有的压缩基准仅关注语言建模（例如困惑度）和自然语言理解任务（例如GLUE准确率），忽略了智能体能力——工作流、工具使用/函数调用、长上下文理解以及真实世界应用。我们引入了智能体压缩基准测试（ACBench），这是第一个用于评估压缩如何影响LLM智能体能力的综合基准测试。ACBench涵盖 (1) 跨越4种能力的12项任务（例如，用于工作流生成的WorfBench，用于长上下文检索的Needle-in-Haystack），(2) 量化（GPTQ, AWQ）和剪枝（Wanda, SparseGPT）等压缩方法，以及 (3) 15种模型，包括小型模型（Gemma-2B）、标准模型（Qwen2.5 7B-32B）和知识蒸馏推理型LLMs（DeepSeek-R1-Distill）。我们的实验揭示了压缩的权衡：4比特量化保留了工作流生成和工具使用能力（下降1%-3%），但使真实世界应用准确率下降了10%-15%。我们引入了ERank、Top-k排序相关性（Top-k Ranking Correlation）和能量（Energy）等指标来系统化分析。ACBench为在智能体场景中优化LLM压缩提供了可操作的见解。代码可在 https://github.com/pprp/ACBench 获取。",
    "keywords": [
      "大语言模型",
      "压缩",
      "智能体能力",
      "基准测试",
      "量化"
    ],
    "area": [
      "大模型",
      "自然语言处理",
      "智能体"
    ],
    "content": "训练后压缩降低了大语言模型（LLMs）的计算和内存成本，从而实现资源高效部署。然而，现有的压缩基准仅关注语言建模（例如困惑度）和自然语言理解任务（例如GLUE准确率），忽略了智能体能力——工作流、工具使用/函数调用、长上下文理解以及真实世界应用。我们引入了智能体压缩基准测试（ACBench），这是第一个用于评估压缩如何影响LLM智能体能力的综合基准测试。ACBench涵盖 (1) 跨越4种能力的12项任务（例如，用于工作流生成的WorfBench，用于长上下文检索的Needle-in-Haystack），(2) 量化（GPTQ, AWQ）和剪枝（Wanda, SparseGPT）等压缩方法，以及 (3) 15种模型，包括小型模型（Gemma-2B）、标准模型（Qwen2.5 7B-32B）和知识蒸馏推理型LLMs（DeepSeek-R1-Distill）。我们的实验揭示了压缩的权衡：4比特量化保留了工作流生成和工具使用能力（下降1%-3%），但使真实世界应用准确率下降了10%-15%。我们引入了ERank、Top-k排序相关性（Top-k Ranking Correlation）和能量（Energy）等指标来系统化分析。ACBench为在智能体场景中优化LLM压缩提供了可操作的见解。代码可在 https://github.com/pprp/ACBench 获取。",
    "published_time": "2025-05-26T02:49:07.000Z",
    "download_time": "2025-05-29 07:09:07",
    "visual_resource": [
      "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.19433.png"
    ],
    "extra": {
      "url": "https://huggingface.co/papers/2505.19433",
      "arxiv_url": "https://arxiv.org/abs/2505.19433"
    }
  },
  {
    "id": "2505.20321",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2505.20321",
    "title": "BiomedSQL：面向生物医学知识库的科学推理文本到SQL系统",
    "summary": "生物医学研究人员日益依赖大规模结构化数据库进行复杂的分析任务。然而，当前的文本到SQL系统在将定性科学问题映射到可执行SQL时往往遇到困难，尤其是在需要隐式领域推理的情况下。我们引入了BiomedSQL，这是第一个明确设计用于评估真实世界生物医学知识库上文本到SQL生成中科学推理能力的基准。BiomedSQL包含68,000个问题/SQL查询/答案三元组，这些三元组基于整合了基因-疾病关联、组学数据的因果推理和药物审批记录的统一BigQuery知识库。每个问题都需要模型推理特定领域的标准，例如全基因组显著性阈值、效应方向性或试验阶段过滤，而不是仅仅依赖于语法翻译。我们评估了多种开放和闭源大型语言模型（LLMs）在不同提示策略和交互范式下的表现。结果显示存在显著的性能差距：GPT-o3-mini实现了59.0%的执行准确率，而我们定制的多步智能体BMSQL达到了62.6%，两者都远低于90.0%的专家基线。BiomedSQL为推进能够通过对结构化生物医学知识库进行鲁棒推理来支持科学发现的文本到SQL系统奠定了新的基础。我们的数据集可在https://huggingface.co/datasets/NIH-CARD/BiomedSQL 公开获取，我们的代码在https://github.com/NIH-CARD/biomedsql 开源。",
    "keywords": [
      "BiomedSQL",
      "Text-to-SQL",
      "生物医学知识库",
      "科学推理",
      "Benchmark"
    ],
    "area": [
      "自然语言处理",
      "大模型",
      "人工智能"
    ],
    "content": "生物医学研究人员日益依赖大规模结构化数据库进行复杂的分析任务。然而，当前的文本到SQL系统在将定性科学问题映射到可执行SQL时往往遇到困难，尤其是在需要隐式领域推理的情况下。我们引入了BiomedSQL，这是第一个明确设计用于评估真实世界生物医学知识库上文本到SQL生成中科学推理能力的基准。BiomedSQL包含68,000个问题/SQL查询/答案三元组，这些三元组基于整合了基因-疾病关联、组学数据的因果推理和药物审批记录的统一BigQuery知识库。每个问题都需要模型推理特定领域的标准，例如全基因组显著性阈值、效应方向性或试验阶段过滤，而不是仅仅依赖于语法翻译。我们评估了多种开放和闭源大型语言模型（LLMs）在不同提示策略和交互范式下的表现。结果显示存在显著的性能差距：GPT-o3-mini实现了59.0%的执行准确率，而我们定制的多步智能体BMSQL达到了62.6%，两者都远低于90.0%的专家基线。BiomedSQL为推进能够通过对结构化生物医学知识库进行鲁棒推理来支持科学发现的文本到SQL系统奠定了新的基础。我们的数据集可在https://huggingface.co/datasets/NIH-CARD/BiomedSQL 公开获取，我们的代码在https://github.com/NIH-CARD/biomedsql 开源。",
    "published_time": "2025-05-23T17:58:07.000Z",
    "download_time": "2025-05-29 07:09:18",
    "visual_resource": [
      "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.20321.png"
    ],
    "extra": {
      "url": "https://huggingface.co/papers/2505.20321",
      "arxiv_url": "https://arxiv.org/abs/2505.20321"
    }
  },
  {
    "id": "2505.17005",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2505.17005",
    "title": "R1-Searcher++：通过强化学习激励大模型的动态知识获取",
    "summary": "大型语言模型（LLMs）功能强大，但由于知识静态而容易产生幻觉。检索增强生成（RAG）通过注入外部信息提供了帮助，但现有方法通常成本较高、泛化性差，或忽略了模型的内部知识。在本文中，我们提出了 R1-Searcher++，一个旨在训练大型语言模型自适应地利用内部和外部知识源的新颖框架。R1-Searcher++ 采用两阶段训练策略：首先进行用于初步格式学习的初始 SFT 冷启动阶段，随后通过强化学习进行动态知识获取。强化学习阶段使用结果监督来鼓励探索，引入奖励机制以利用内部知识，并融合记忆机制来持续吸收检索到的信息，从而丰富模型的内部知识。通过利用内部知识和外部搜索引擎，模型不断提升其能力，实现高效的检索增强推理。我们的实验表明，R1-Searcher++ 在性能上优于先前的检索增强生成和推理方法，并实现了高效的检索。代码可在 https://github.com/RUCAIBox/R1-Searcher-plus 获取。",
    "keywords": [
      "大模型 LLMs",
      "强化学习 RL",
      "检索增强生成 RAG",
      "动态知识获取",
      "内外部知识协同"
    ],
    "area": [
      "大模型",
      "自然语言处理",
      "机器学习"
    ],
    "content": "大型语言模型（LLMs）功能强大，但由于知识静态而容易产生幻觉。检索增强生成（RAG）通过注入外部信息提供了帮助，但现有方法通常成本较高、泛化性差，或忽略了模型的内部知识。在本文中，我们提出了 R1-Searcher++，一个旨在训练大型语言模型自适应地利用内部和外部知识源的新颖框架。R1-Searcher++ 采用两阶段训练策略：首先进行用于初步格式学习的初始 SFT 冷启动阶段，随后通过强化学习进行动态知识获取。强化学习阶段使用结果监督来鼓励探索，引入奖励机制以利用内部知识，并融合记忆机制来持续吸收检索到的信息，从而丰富模型的内部知识。通过利用内部知识和外部搜索引擎，模型不断提升其能力，实现高效的检索增强推理。我们的实验表明，R1-Searcher++ 在性能上优于先前的检索增强生成和推理方法，并实现了高效的检索。代码可在 https://github.com/RUCAIBox/R1-Searcher-plus 获取。",
    "published_time": "2025-05-22T17:58:26.000Z",
    "download_time": "2025-05-29 07:09:30",
    "visual_resource": [
      "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.17005.png"
    ],
    "extra": {
      "url": "https://huggingface.co/papers/2505.17005",
      "arxiv_url": "https://arxiv.org/abs/2505.17005"
    }
  },
  {
    "id": "2505.11277",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2505.11277",
    "title": "思考过程中的搜索与精炼：大语言模型的自主检索增强推理",
    "summary": "大语言模型展示了令人印象深刻的推理能力，但其固有的知识储备存在局限性。检索增强推理通过允许大语言模型查询外部资源来缓解这一局限性，但现有方法经常检索到不相关或噪声信息，阻碍了准确推理。在本文中，我们提出了 AutoRefine，这是一个采用全新“在思考过程中搜索与精炼”范式的强化学习后训练框架。AutoRefine 在连续的搜索调用之间引入了显式的知识精炼步骤，使模型能够在生成答案之前迭代地过滤、提炼和组织证据。此外，我们使用组相对策略优化方法，将定制的检索特定奖励与答案正确性奖励相结合。在单跳和多跳问答基准上的实验表明，AutoRefine 显著优于现有方法，尤其是在复杂的多跳推理场景中。详细分析表明，AutoRefine 发出了更频繁、质量更高的搜索，并有效地综合了证据。",
    "keywords": [
      "大语言模型",
      "检索增强推理",
      "强化学习",
      "多跳推理",
      "AutoRefine"
    ],
    "area": [
      "大模型",
      "自然语言处理",
      "机器学习"
    ],
    "content": "大语言模型展示了令人印象深刻的推理能力，但其固有的知识储备存在局限性。检索增强推理通过允许大语言模型查询外部资源来缓解这一局限性，但现有方法经常检索到不相关或噪声信息，阻碍了准确推理。在本文中，我们提出了 AutoRefine，这是一个采用全新“在思考过程中搜索与精炼”范式的强化学习后训练框架。AutoRefine 在连续的搜索调用之间引入了显式的知识精炼步骤，使模型能够在生成答案之前迭代地过滤、提炼和组织证据。此外，我们使用组相对策略优化方法，将定制的检索特定奖励与答案正确性奖励相结合。在单跳和多跳问答基准上的实验表明，AutoRefine 显著优于现有方法，尤其是在复杂的多跳推理场景中。详细分析表明，AutoRefine 发出了更频繁、质量更高的搜索，并有效地综合了证据。",
    "published_time": "2025-05-16T14:11:29.000Z",
    "download_time": "2025-05-29 07:09:45",
    "visual_resource": [
      "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.11277.png"
    ],
    "extra": {
      "url": "https://huggingface.co/papers/2505.11277",
      "arxiv_url": "https://arxiv.org/abs/2505.11277"
    }
  },
  {
    "id": "2505.18657",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2505.18657",
    "title": "多模态大语言模型深受模态偏差的深刻影响",
    "summary": "多模态大语言模型（MLLMs）的最新进展在整合文本和图像等多种模态方面取得了可喜的成果。MLLMs深受模态偏差的严重影响，它们经常过度依赖语言，而对视觉等其他模态的利用不足。本立场论文认为，MLLMs深受模态偏差的深刻影响。首先，我们诊断了模态偏差的当前状况，强调了它在各种任务中的表现形式。其次，我们提出了关于 MLLMs 中模态偏差的系统研究路线图。第三，我们确定了 MLLMs 中模态偏差的关键因素，并为未来的研究提出了可操作的缓解建议。为了证实这些发现，我们进行了实验来证明每个因素的影响：1. 数据特性：语言数据紧凑且抽象，而视觉数据冗余且复杂，这在学习动态中造成了固有的不平衡。2. 不平衡的骨干能力：预训练语言模型在 MLLMs 中的主导地位导致对语言的过度依赖和对视觉信息的忽视。3. 训练目标：当前的训练目标往往未能促进平衡的跨模态对齐，导致偏向语言的捷径学习。这些发现突出了需要平衡的训练策略和模型架构，以便在 MLLMs 中更好地整合多种模态。我们呼吁跨学科合作来应对这些挑战，并推动 MLLM 研究的创新。我们的工作为 MLLMs 中的模态偏差提供了新的视角，并为开发更鲁棒和更具泛化性的多模态系统（推动通用人工智能的进展）提供了见解。",
    "keywords": [
      "MLLMs",
      "Modality Bias",
      "Multimodal Learning",
      "Cross-modal Alignment",
      "Training Objectives"
    ],
    "area": [
      "多模态",
      "大模型",
      "自然语言处理"
    ],
    "content": "多模态大语言模型（MLLMs）的最新进展在整合文本和图像等多种模态方面取得了可喜的成果。MLLMs深受模态偏差的严重影响，它们经常过度依赖语言，而对视觉等其他模态的利用不足。本立场论文认为，MLLMs深受模态偏差的深刻影响。首先，我们诊断了模态偏差的当前状况，强调了它在各种任务中的表现形式。其次，我们提出了关于 MLLMs 中模态偏差的系统研究路线图。第三，我们确定了 MLLMs 中模态偏差的关键因素，并为未来的研究提出了可操作的缓解建议。为了证实这些发现，我们进行了实验来证明每个因素的影响：1. 数据特性：语言数据紧凑且抽象，而视觉数据冗余且复杂，这在学习动态中造成了固有的不平衡。2. 不平衡的骨干能力：预训练语言模型在 MLLMs 中的主导地位导致对语言的过度依赖和对视觉信息的忽视。3. 训练目标：当前的训练目标往往未能促进平衡的跨模态对齐，导致偏向语言的捷径学习。这些发现突出了需要平衡的训练策略和模型架构，以便在 MLLMs 中更好地整合多种模态。我们呼吁跨学科合作来应对这些挑战，并推动 MLLM 研究的创新。我们的工作为 MLLMs 中的模态偏差提供了新的视角，并为开发更鲁棒和更具泛化性的多模态系统（推动通用人工智能的进展）提供了见解。",
    "published_time": "2025-05-24T11:49:31.000Z",
    "download_time": "2025-05-29 07:10:15",
    "visual_resource": [
      "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.18657.png"
    ],
    "extra": {
      "url": "https://huggingface.co/papers/2505.18657",
      "arxiv_url": "https://arxiv.org/abs/2505.18657"
    }
  },
  {
    "id": "2505.22172",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2505.22172",
    "title": "用于复杂指令遵循的逆向偏好优化",
    "summary": "指令遵循 (IF) 是大型语言模型 (LLM) 的一项关键能力。然而，处理具有多个限制条件的复杂指令仍然具有挑战性。以前的方法通常根据满足的限制条件数量来选择偏好对，这引入了噪声，因为选定的例子可能未能遵循某些限制条件，而被拒绝的例子可能在某些方面优于选定的例子。为了应对与多重偏好对齐的挑战，我们提出了一种简单而有效的方法，称为逆向偏好优化 (RPO)。它通过动态地反转指令中的限制条件来减轻偏好对中的噪声，从而确保选定的响应是完美的，减轻了收集完美响应所需的广泛采样和过滤负担。此外，反转还扩大了选定响应与被拒绝响应之间的差距，从而明确了优化方向，并使其对噪声更具鲁棒性。我们在两个多轮 IF 基准测试 Sysbench 和 Multi-IF 上评估了 RPO，结果表明其相对于 DPO 基线分别平均提高了 4.6 和 2.5 分（在 Llama-3.1 8B 上）。此外，RPO 在不同模型尺寸（8B 到 70B 参数）上表现出有效的可扩展性，其中 70B RPO 模型甚至超越了 GPT-4o。",
    "keywords": [
      "逆向偏好优化 (RPO)",
      "复杂指令遵循",
      "大语言模型 (LLM)",
      "Preference Optimization",
      "噪声缓解"
    ],
    "area": [
      "大模型",
      "自然语言处理",
      "生成式AI"
    ],
    "content": "指令遵循 (IF) 是大型语言模型 (LLM) 的一项关键能力。然而，处理具有多个限制条件的复杂指令仍然具有挑战性。以前的方法通常根据满足的限制条件数量来选择偏好对，这引入了噪声，因为选定的例子可能未能遵循某些限制条件，而被拒绝的例子可能在某些方面优于选定的例子。为了应对与多重偏好对齐的挑战，我们提出了一种简单而有效的方法，称为逆向偏好优化 (RPO)。它通过动态地反转指令中的限制条件来减轻偏好对中的噪声，从而确保选定的响应是完美的，减轻了收集完美响应所需的广泛采样和过滤负担。此外，反转还扩大了选定响应与被拒绝响应之间的差距，从而明确了优化方向，并使其对噪声更具鲁棒性。我们在两个多轮 IF 基准测试 Sysbench 和 Multi-IF 上评估了 RPO，结果表明其相对于 DPO 基线分别平均提高了 4.6 和 2.5 分（在 Llama-3.1 8B 上）。此外，RPO 在不同模型尺寸（8B 到 70B 参数）上表现出有效的可扩展性，其中 70B RPO 模型甚至超越了 GPT-4o。",
    "published_time": "2025-05-28T09:44:27.000Z",
    "download_time": "2025-05-29 07:10:31",
    "visual_resource": [
      "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.22172.png"
    ],
    "extra": {
      "url": "https://huggingface.co/papers/2505.22172",
      "arxiv_url": "https://arxiv.org/abs/2505.22172"
    }
  },
  {
    "id": "2505.20162",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2505.20162",
    "title": "基于能力的LLM红队测试缩放定律",
    "summary": "随着大型语言模型的能力和能动性日益增强，通过红队测试识别漏洞对于安全部署至关重要。然而，一旦红队测试演变为一个从弱到强的问题，即目标模型的能力超出红队测试者，传统的提示工程方法可能失效。为了研究这种转变，我们从攻击者与目标之间能力差距的视角来构建红队测试问题。我们使用模仿人类红队测试者的基于LLM的越狱攻击，评估了涵盖不同系列、规模和能力水平的500多个攻击者-目标对。出现了三个显著趋势：(i) 能力更强的模型是更好的攻击者；(ii) 一旦目标的能力超过攻击者，攻击成功率会急剧下降；(iii) 攻击成功率与在MMLU-Pro基准测试（特别是社会科学分项）上的高性能相关。基于这些趋势，我们推导出了一个越狱攻击的缩放定律，该定律可以根据攻击者与目标之间的能力差距来预测针对固定目标的攻击成功率。这些发现表明，能力固定的攻击者（例如人类）可能对未来的模型无效，能力日益增强的开源模型会放大现有系统的风险，并且模型提供者必须准确测量和控制模型的说服和操纵能力，以限制其作为攻击者的有效性。",
    "keywords": [
      "LLM Red-Teaming",
      "能力差距",
      "缩放定律",
      "越狱攻击",
      "大模型安全"
    ],
    "area": [
      "大模型",
      "自然语言处理",
      "人工智能"
    ],
    "content": "随着大型语言模型的能力和能动性日益增强，通过红队测试识别漏洞对于安全部署至关重要。然而，一旦红队测试演变为一个从弱到强的问题，即目标模型的能力超出红队测试者，传统的提示工程方法可能失效。为了研究这种转变，我们从攻击者与目标之间能力差距的视角来构建红队测试问题。我们使用模仿人类红队测试者的基于LLM的越狱攻击，评估了涵盖不同系列、规模和能力水平的500多个攻击者-目标对。出现了三个显著趋势：(i) 能力更强的模型是更好的攻击者；(ii) 一旦目标的能力超过攻击者，攻击成功率会急剧下降；(iii) 攻击成功率与在MMLU-Pro基准测试（特别是社会科学分项）上的高性能相关。基于这些趋势，我们推导出了一个越狱攻击的缩放定律，该定律可以根据攻击者与目标之间的能力差距来预测针对固定目标的攻击成功率。这些发现表明，能力固定的攻击者（例如人类）可能对未来的模型无效，能力日益增强的开源模型会放大现有系统的风险，并且模型提供者必须准确测量和控制模型的说服和操纵能力，以限制其作为攻击者的有效性。",
    "published_time": "2025-05-26T16:05:41.000Z",
    "download_time": "2025-05-29 07:10:45",
    "visual_resource": [
      "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.20162.png"
    ],
    "extra": {
      "url": "https://huggingface.co/papers/2505.20162",
      "arxiv_url": "https://arxiv.org/abs/2505.20162"
    }
  },
  {
    "id": "2505.19973",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2505.19973",
    "title": "DFIR-Metric：一个用于评估数字取证与事件响应领域大语言模型的评测数据集",
    "summary": "数字取证与事件响应 (DFIR) 涉及分析数字证据以支持法律调查。大语言模型 (LLMs) 在日志分析和内存取证等 DFIR 任务中提供了新的机遇，但它们容易出错和产生幻觉的特性在高风险场景中引发了担忧。尽管兴趣日益增长，但目前还没有一个全面的基准来评估 LLM 在理论和实践 DFIR 领域中的表现。为了弥补这一空白，我们提出了 DFIR-Metric，这是一个包含三个组成部分的基准：(1) 知识评估：一套由行业标准认证和官方文档中提取的 700 道经专家评审的多项选择题；(2) 逼真取证挑战：150 个 CTF 风格的任务，测试多步推理和证据关联能力；(3) 实践分析：来自 NIST 计算机取证工具测试项目 (CFTT) 的 500 个磁盘和内存取证案例。我们使用 DFIR-Metric 评估了 14 个 LLM，分析了它们在多次试验中的准确性和一致性。我们还引入了一种新的度量标准——任务理解得分 (TUS)，旨在更有效地评估在准确率接近零的场景中模型的表现。该基准为推动数字取证领域的人工智能发展提供了一个严格、可复现的基础。所有脚本、工件和结果均可在项目网站 https://github.com/DFIR-Metric 上获取。",
    "keywords": [
      "DFIR",
      "大语言模型 LLMs",
      "评测基准 Benchmark",
      "数字取证 Digital Forensics",
      "事件响应 Incident Response"
    ],
    "area": [
      "人工智能",
      "自然语言处理",
      "大模型"
    ],
    "content": "数字取证与事件响应 (DFIR) 涉及分析数字证据以支持法律调查。大语言模型 (LLMs) 在日志分析和内存取证等 DFIR 任务中提供了新的机遇，但它们容易出错和产生幻觉的特性在高风险场景中引发了担忧。尽管兴趣日益增长，但目前还没有一个全面的基准来评估 LLM 在理论和实践 DFIR 领域中的表现。为了弥补这一空白，我们提出了 DFIR-Metric，这是一个包含三个组成部分的基准：(1) 知识评估：一套由行业标准认证和官方文档中提取的 700 道经专家评审的多项选择题；(2) 逼真取证挑战：150 个 CTF 风格的任务，测试多步推理和证据关联能力；(3) 实践分析：来自 NIST 计算机取证工具测试项目 (CFTT) 的 500 个磁盘和内存取证案例。我们使用 DFIR-Metric 评估了 14 个 LLM，分析了它们在多次试验中的准确性和一致性。我们还引入了一种新的度量标准——任务理解得分 (TUS)，旨在更有效地评估在准确率接近零的场景中模型的表现。该基准为推动数字取证领域的人工智能发展提供了一个严格、可复现的基础。所有脚本、工件和结果均可在项目网站 https://github.com/DFIR-Metric 上获取。",
    "published_time": "2025-05-26T13:35:37.000Z",
    "download_time": "2025-05-29 07:11:07",
    "visual_resource": [
      "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.19973.png"
    ],
    "extra": {
      "url": "https://huggingface.co/papers/2505.19973",
      "arxiv_url": "https://arxiv.org/abs/2505.19973"
    }
  },
  {
    "id": "2505.19650",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2505.19650",
    "title": "模态精选：构建用于高级多模态信息检索的通用嵌入",
    "summary": "多模态信息检索（MIR）由于数据源的异质性和跨模态对齐的复杂性而面临固有挑战。尽管先前的研究已经发现了特征空间中的模态鸿沟，但解决这些挑战的系统方法仍未得到探索。在本项目中，我们引入了UNITE，这是一个通用框架，通过数据精选和模态感知训练配置这两个关键但研究不足的方面来应对这些挑战。我们的工作首次全面分析了模态特定的数据属性如何影响不同场景下的下游任务性能。此外，我们提出了模态感知掩码对比学习（Modal-Aware Masked Contrastive Learning，MAMCL），以减轻不同模态实例之间的竞争关系。我们的框架在多个多模态检索基准上取得了最先进的结果，显著优于现有方法。通过广泛的实验，我们证明了策略性模态精选和定制的训练协议对于鲁棒的跨模态表征学习至关重要。这项工作不仅提高了MIR的性能，还为未来多模态系统的研究提供了基础蓝图。我们的项目位于 https://friedrichor.github.io/projects/UNITE。",
    "keywords": [
      "多模态信息检索",
      "模态精选",
      "通用嵌入",
      "跨模态学习",
      "对比学习"
    ],
    "area": [
      "多模态",
      "机器学习",
      "深度学习"
    ],
    "content": "多模态信息检索（MIR）由于数据源的异质性和跨模态对齐的复杂性而面临固有挑战。尽管先前的研究已经发现了特征空间中的模态鸿沟，但解决这些挑战的系统方法仍未得到探索。在本项目中，我们引入了UNITE，这是一个通用框架，通过数据精选和模态感知训练配置这两个关键但研究不足的方面来应对这些挑战。我们的工作首次全面分析了模态特定的数据属性如何影响不同场景下的下游任务性能。此外，我们提出了模态感知掩码对比学习（Modal-Aware Masked Contrastive Learning，MAMCL），以减轻不同模态实例之间的竞争关系。我们的框架在多个多模态检索基准上取得了最先进的结果，显著优于现有方法。通过广泛的实验，我们证明了策略性模态精选和定制的训练协议对于鲁棒的跨模态表征学习至关重要。这项工作不仅提高了MIR的性能，还为未来多模态系统的研究提供了基础蓝图。我们的项目位于 https://friedrichor.github.io/projects/UNITE。",
    "published_time": "2025-05-26T08:09:44.000Z",
    "download_time": "2025-05-29 07:11:25",
    "visual_resource": [
      "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.19650.png"
    ],
    "extra": {
      "url": "https://huggingface.co/papers/2505.19650",
      "arxiv_url": "https://arxiv.org/abs/2505.19650"
    }
  },
  {
    "id": "2505.22633",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2505.22633",
    "title": "空间知识图谱引导的多模态合成",
    "summary": "近期多模态大语言模型（MLLMs）的进展显著增强了其能力；然而，它们的空间感知能力仍是一个显著的局限。为了解决这一挑战，多模态数据合成提供了一种有前景的解决方案。然而，确保合成数据符合空间常识是一项不平凡的任务。在这项工作中，我们引入了 SKG2Data，一种由空间知识图谱引导的新型多模态合成方法，其基础是知识到数据生成的概念。SKG2Data 自动构建空间知识图谱（SKG），以模拟人类对空间方向和距离的感知，随后利用该图谱来指导多模态数据合成。大量实验表明，利用包括方向和距离在内的各种空间知识合成的数据，不仅增强了 MLLMs 的空间感知和推理能力，而且表现出强大的泛化能力。我们希望基于知识的数据合成这一思想能够推动空间智能的发展。",
    "keywords": [
      "空间知识图谱",
      "多模态合成",
      "MLLMs",
      "空间感知",
      "知识到数据生成"
    ],
    "area": [
      "多模态",
      "大模型",
      "生成式AI"
    ],
    "content": "近期多模态大语言模型（MLLMs）的进展显著增强了其能力；然而，它们的空间感知能力仍是一个显著的局限。为了解决这一挑战，多模态数据合成提供了一种有前景的解决方案。然而，确保合成数据符合空间常识是一项不平凡的任务。在这项工作中，我们引入了 SKG2Data，一种由空间知识图谱引导的新型多模态合成方法，其基础是知识到数据生成的概念。SKG2Data 自动构建空间知识图谱（SKG），以模拟人类对空间方向和距离的感知，随后利用该图谱来指导多模态数据合成。大量实验表明，利用包括方向和距离在内的各种空间知识合成的数据，不仅增强了 MLLMs 的空间感知和推理能力，而且表现出强大的泛化能力。我们希望基于知识的数据合成这一思想能够推动空间智能的发展。",
    "published_time": "2025-05-28T17:50:21.000Z",
    "download_time": "2025-05-29 07:11:38",
    "visual_resource": [
      "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.22633.png"
    ],
    "extra": {
      "url": "https://huggingface.co/papers/2505.22633",
      "arxiv_url": "https://arxiv.org/abs/2505.22633"
    }
  },
  {
    "id": "2505.21499",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2505.21499",
    "title": "AdInject：通过广告投送对网络智能体发起真实世界黑盒攻击",
    "summary": "基于视觉-语言模型（VLM）的网络智能体通过模拟人类与网站的交互，在自动化复杂任务方面迈出了重要一步。然而，它们在不受控的网络环境中部署带来了重大的安全漏洞。现有关于对抗性环境注入攻击的研究通常依赖于不切合实际的假设，例如直接操纵 HTML、了解用户意图或访问智能体模型参数，这限制了它们的实际适用性。在本文中，我们提出了 AdInject，一种新颖且真实世界的黑盒攻击方法，它利用互联网广告投送将恶意内容注入到网络智能体的环境中。 AdInject 在比先前工作更现实的威胁模型下运行，假设智能体是黑盒的，恶意内容具有静态约束，并且不了解用户意图。AdInject 包括旨在误导智能体点击的恶意广告内容设计策略，以及一种基于 VLM 的广告内容优化技术，该技术从目标网站的上下文中推断潜在的用户意图，并将这些意图整合到广告内容中，使其对智能体的任务看起来更相关或更关键，从而增强攻击的有效性。实验评估证明了 AdInject 的有效性，在大多数场景下的攻击成功率超过 60%，在某些情况下接近 100%。这有力地表明，普遍存在的广告投送是针对网络智能体发起环境注入攻击的强大且真实世界的载体。这项工作强调了源自真实世界环境操纵渠道的网络智能体安全面临的关键漏洞，并突显了迫切需要开发针对此类威胁的强大防御机制。我们的代码可在 https://github.com/NicerWang/AdInject 获取。",
    "keywords": [
      "AdInject",
      "网络智能体",
      "对抗性攻击",
      "广告投送",
      "视觉-语言模型"
    ],
    "area": [
      "智能体",
      "多模态",
      "人工智能"
    ],
    "content": "基于视觉-语言模型（VLM）的网络智能体通过模拟人类与网站的交互，在自动化复杂任务方面迈出了重要一步。然而，它们在不受控的网络环境中部署带来了重大的安全漏洞。现有关于对抗性环境注入攻击的研究通常依赖于不切合实际的假设，例如直接操纵 HTML、了解用户意图或访问智能体模型参数，这限制了它们的实际适用性。在本文中，我们提出了 AdInject，一种新颖且真实世界的黑盒攻击方法，它利用互联网广告投送将恶意内容注入到网络智能体的环境中。 AdInject 在比先前工作更现实的威胁模型下运行，假设智能体是黑盒的，恶意内容具有静态约束，并且不了解用户意图。AdInject 包括旨在误导智能体点击的恶意广告内容设计策略，以及一种基于 VLM 的广告内容优化技术，该技术从目标网站的上下文中推断潜在的用户意图，并将这些意图整合到广告内容中，使其对智能体的任务看起来更相关或更关键，从而增强攻击的有效性。实验评估证明了 AdInject 的有效性，在大多数场景下的攻击成功率超过 60%，在某些情况下接近 100%。这有力地表明，普遍存在的广告投送是针对网络智能体发起环境注入攻击的强大且真实世界的载体。这项工作强调了源自真实世界环境操纵渠道的网络智能体安全面临的关键漏洞，并突显了迫切需要开发针对此类威胁的强大防御机制。我们的代码可在 https://github.com/NicerWang/AdInject 获取。",
    "published_time": "2025-05-27T17:59:05.000Z",
    "download_time": "2025-05-29 07:11:48",
    "visual_resource": [
      "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.21499.png"
    ],
    "extra": {
      "url": "https://huggingface.co/papers/2505.21499",
      "arxiv_url": "https://arxiv.org/abs/2505.21499"
    }
  },
  {
    "id": "2505.20279",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2505.20279",
    "title": "VLM-3R：指令对齐三维重建增强的视觉语言模型",
    "summary": "针对2D图像和视频的大型多模态模型（LMMs）的快速发展，促进了将这些模型扩展到理解3D场景，旨在实现类人的视觉空间智能。然而，实现与人类能力相当的深度空间理解在模型编码和数据获取方面带来了显著挑战。现有方法经常依赖外部深度传感器进行几何捕获，或利用现成的算法预构建3D地图，从而限制了其可扩展性，特别是对于普遍存在的单目视频输入和对时间敏感的应用。在这项工作中，我们引入了VLM-3R，一个统一的视觉语言模型（VLMs）框架，它集成了3D重建指令微调。VLM-3R通过使用几何编码器来生成代表空间理解的隐式3D tokens，从而处理单目视频帧。利用我们的空间-视觉-视图融合（Spatial-Visual-View Fusion）以及超过20万对精选的3D重建指令微调问答（QA）对，VLM-3R有效地将现实世界的空间语境与语言指令对齐，从而实现了单目3D空间辅助和具身推理。为了促进时间推理的评估，我们引入了视觉-空间-时间智能基准，包含五个不同任务的超过13.86万对问答对，专注于演变中的空间关系。大量实验表明，我们的模型VLM-3R不仅促进了鲁棒的视觉空间推理，而且能够理解时间性的3D语境变化，在准确性和可扩展性方面均表现出色。",
    "keywords": [
      "VLM-3R",
      "3D Reconstruction",
      "Vision-Language Models",
      "Instruction Tuning",
      "Spatial-Temporal Reasoning"
    ],
    "area": [
      "计算机视觉",
      "多模态",
      "大模型"
    ],
    "content": "针对2D图像和视频的大型多模态模型（LMMs）的快速发展，促进了将这些模型扩展到理解3D场景，旨在实现类人的视觉空间智能。然而，实现与人类能力相当的深度空间理解在模型编码和数据获取方面带来了显著挑战。现有方法经常依赖外部深度传感器进行几何捕获，或利用现成的算法预构建3D地图，从而限制了其可扩展性，特别是对于普遍存在的单目视频输入和对时间敏感的应用。在这项工作中，我们引入了VLM-3R，一个统一的视觉语言模型（VLMs）框架，它集成了3D重建指令微调。VLM-3R通过使用几何编码器来生成代表空间理解的隐式3D tokens，从而处理单目视频帧。利用我们的空间-视觉-视图融合（Spatial-Visual-View Fusion）以及超过20万对精选的3D重建指令微调问答（QA）对，VLM-3R有效地将现实世界的空间语境与语言指令对齐，从而实现了单目3D空间辅助和具身推理。为了促进时间推理的评估，我们引入了视觉-空间-时间智能基准，包含五个不同任务的超过13.86万对问答对，专注于演变中的空间关系。大量实验表明，我们的模型VLM-3R不仅促进了鲁棒的视觉空间推理，而且能够理解时间性的3D语境变化，在准确性和可扩展性方面均表现出色。",
    "published_time": "2025-05-26T17:56:30.000Z",
    "download_time": "2025-05-29 07:12:03",
    "visual_resource": [
      "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.20279.png"
    ],
    "extra": {
      "url": "https://huggingface.co/papers/2505.20279",
      "arxiv_url": "https://arxiv.org/abs/2505.20279"
    }
  },
  {
    "id": "2505.19094",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2505.19094",
    "title": "SATORI-R1：通过空间锚定和可验证奖励激励多模态推理",
    "summary": "DeepSeek-R1 通过稳定的强化学习 (RL) 在文本领域展现了强大的推理能力。近年来，在多模态领域，研究开始直接应用强化学习生成类似 R1 的自由形式推理来完成视觉问答 (VQA) 任务。然而，多模态任务与文本任务本质上存在差异，它们解决问题严重依赖于对输入图像的理解。因此，这种自由形式推理在 VQA 任务中面临两个关键局限：(1) 过长的推理链会使视觉焦点从任务关键区域扩散开，从而降低答案准确性。(2) 不可验证的中间步骤会放大策略梯度方差和计算开销。为了解决这些问题，本文提出了 SATORI (Spatially Anchored Task Optimization with ReInforcement Learning，空间锚定任务优化强化学习)，该方法将 VQA 分解为三个可验证的阶段，包括全局图像描述、区域定位和答案预测，每个阶段都提供明确的奖励信号。此外，我们还引入了 VQA-Verify 数据集，这是一个包含 12k 条标注了答案对齐的图像描述和边界框的数据集，用于促进训练。实验表明，该方法在七个 VQA 基准测试中实现了持续的性能提升，与类似 R1 的基线相比，准确率最高提高了 15.7%。我们对注意力图的分析证实了对关键区域增强的关注，从而带来了准确率的提高。我们的代码可在 https://github.com/justairr/SATORI-R1 获取。",
    "keywords": [
      "多模态推理",
      "视觉问答 (VQA)",
      "强化学习",
      "空间锚定",
      "可验证奖励"
    ],
    "area": [
      "多模态",
      "计算机视觉",
      "机器学习"
    ],
    "content": "DeepSeek-R1 通过稳定的强化学习 (RL) 在文本领域展现了强大的推理能力。近年来，在多模态领域，研究开始直接应用强化学习生成类似 R1 的自由形式推理来完成视觉问答 (VQA) 任务。然而，多模态任务与文本任务本质上存在差异，它们解决问题严重依赖于对输入图像的理解。因此，这种自由形式推理在 VQA 任务中面临两个关键局限：(1) 过长的推理链会使视觉焦点从任务关键区域扩散开，从而降低答案准确性。(2) 不可验证的中间步骤会放大策略梯度方差和计算开销。为了解决这些问题，本文提出了 SATORI (Spatially Anchored Task Optimization with ReInforcement Learning，空间锚定任务优化强化学习)，该方法将 VQA 分解为三个可验证的阶段，包括全局图像描述、区域定位和答案预测，每个阶段都提供明确的奖励信号。此外，我们还引入了 VQA-Verify 数据集，这是一个包含 12k 条标注了答案对齐的图像描述和边界框的数据集，用于促进训练。实验表明，该方法在七个 VQA 基准测试中实现了持续的性能提升，与类似 R1 的基线相比，准确率最高提高了 15.7%。我们对注意力图的分析证实了对关键区域增强的关注，从而带来了准确率的提高。我们的代码可在 https://github.com/justairr/SATORI-R1 获取。",
    "published_time": "2025-05-25T11:11:06.000Z",
    "download_time": "2025-05-29 07:12:19",
    "visual_resource": [
      "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.19094.png"
    ],
    "extra": {
      "url": "https://huggingface.co/papers/2505.19094",
      "arxiv_url": "https://arxiv.org/abs/2505.19094"
    }
  },
  {
    "id": "2505.17908",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2505.17908",
    "title": "ComfyMind：通过基于树的规划和反应式反馈实现通用生成",
    "summary": "随着生成模型的高速发展，通用生成作为一种有望在单一系统中统一跨模态多样化任务的方法，受到越来越多的关注。尽管取得了这些进展，但现有开源框架由于缺乏结构化工作流规划和执行层反馈，往往仍然脆弱且难以支持复杂的现实世界应用。为了解决这些局限性，我们提出了 ComfyMind，这是一个协作式AI系统，旨在实现鲁棒且可扩展的通用生成，该系统构建于 ComfyUI 平台之上。ComfyMind 引入了两项核心创新：语义工作流接口 (SWI)，它将低层次节点图抽象为自然语言描述的可调用功能模块，实现高层次组合并减少结构错误；具有局部反馈执行的搜索树规划机制，它将生成建模为分层决策过程，并允许在每个阶段进行自适应修正。这些组件共同提升了复杂生成工作流的稳定性和灵活性。我们在三个公开基准测试集上评估了 ComfyMind：ComfyBench、GenEval 和 Reason-Edit，这些基准涵盖生成、编辑和推理任务。结果表明，ComfyMind 持续优于现有开源基线，并达到了与 GPT-Image-1 相当的性能。ComfyMind 为开源通用生成式AI系统的发展开辟了一条有前景的道路。项目页面：https://github.com/LitaoGuo/ComfyMind",
    "keywords": [
      "通用生成",
      "树形规划",
      "反应式反馈",
      "工作流",
      "ComfyUI"
    ],
    "area": [
      "人工智能",
      "生成式AI",
      "智能体"
    ],
    "content": "随着生成模型的高速发展，通用生成作为一种有望在单一系统中统一跨模态多样化任务的方法，受到越来越多的关注。尽管取得了这些进展，但现有开源框架由于缺乏结构化工作流规划和执行层反馈，往往仍然脆弱且难以支持复杂的现实世界应用。为了解决这些局限性，我们提出了 ComfyMind，这是一个协作式AI系统，旨在实现鲁棒且可扩展的通用生成，该系统构建于 ComfyUI 平台之上。ComfyMind 引入了两项核心创新：语义工作流接口 (SWI)，它将低层次节点图抽象为自然语言描述的可调用功能模块，实现高层次组合并减少结构错误；具有局部反馈执行的搜索树规划机制，它将生成建模为分层决策过程，并允许在每个阶段进行自适应修正。这些组件共同提升了复杂生成工作流的稳定性和灵活性。我们在三个公开基准测试集上评估了 ComfyMind：ComfyBench、GenEval 和 Reason-Edit，这些基准涵盖生成、编辑和推理任务。结果表明，ComfyMind 持续优于现有开源基线，并达到了与 GPT-Image-1 相当的性能。ComfyMind 为开源通用生成式AI系统的发展开辟了一条有前景的道路。项目页面：https://github.com/LitaoGuo/ComfyMind",
    "published_time": "2025-05-23T13:53:03.000Z",
    "download_time": "2025-05-29 07:12:35",
    "visual_resource": [
      "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.17908.png"
    ],
    "extra": {
      "url": "https://huggingface.co/papers/2505.17908",
      "arxiv_url": "https://arxiv.org/abs/2505.17908"
    }
  },
  {
    "id": "2505.16673",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2505.16673",
    "title": "R1-ShareVL：通过 Share-GRPO 激励多模态大语言模型的推理能力",
    "summary": "在这项工作中，我们旨在通过强化学习 (RL) 激励多模态大语言模型 (MLLMs) 的推理能力，并开发一种有效方法来缓解 강화学习过程中稀疏奖励和优势值消失的问题。为此，我们提出了 Share-GRPO，一种新颖的强化学习方法，它通过在扩展的问题空间上探索和共享多样化的推理轨迹来解决这些问题。具体来说，Share-GRPO 首先通过数据转换技术扩展给定问题的问题空间，然后在强化学习过程中鼓励 MLLM 有效地探索扩展问题空间上的多样化推理轨迹，并跨扩展问题共享发现的推理轨迹。此外，Share-GRPO 在优势计算期间也共享奖励信息，它在问题变体之间和内部层级地估计解决方案优势，从而实现更准确的相对优势估计并提高策略训练的稳定性。在六个广泛使用的推理基准上进行的广泛评估展示了我们方法的优越性能。代码将发布在 https://github.com/HJYao00/R1-ShareVL。",
    "keywords": [
      "多模态大语言模型",
      "强化学习",
      "推理能力",
      "Share-GRPO",
      "推理轨迹"
    ],
    "area": [
      "人工智能",
      "多模态",
      "大模型"
    ],
    "content": "在这项工作中，我们旨在通过强化学习 (RL) 激励多模态大语言模型 (MLLMs) 的推理能力，并开发一种有效方法来缓解 강화学习过程中稀疏奖励和优势值消失的问题。为此，我们提出了 Share-GRPO，一种新颖的强化学习方法，它通过在扩展的问题空间上探索和共享多样化的推理轨迹来解决这些问题。具体来说，Share-GRPO 首先通过数据转换技术扩展给定问题的问题空间，然后在强化学习过程中鼓励 MLLM 有效地探索扩展问题空间上的多样化推理轨迹，并跨扩展问题共享发现的推理轨迹。此外，Share-GRPO 在优势计算期间也共享奖励信息，它在问题变体之间和内部层级地估计解决方案优势，从而实现更准确的相对优势估计并提高策略训练的稳定性。在六个广泛使用的推理基准上进行的广泛评估展示了我们方法的优越性能。代码将发布在 https://github.com/HJYao00/R1-ShareVL。",
    "published_time": "2025-05-22T13:39:32.000Z",
    "download_time": "2025-05-29 07:13:00",
    "visual_resource": [
      "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.16673.png"
    ],
    "extra": {
      "url": "https://huggingface.co/papers/2505.16673",
      "arxiv_url": "https://arxiv.org/abs/2505.16673"
    }
  },
  {
    "id": "2505.22096",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2505.22096",
    "title": "用于知识增强的Text-to-SQL的知识库构建",
    "summary": "Text-to-SQL旨在将自然语言查询转换为SQL语句，这非常实用，因为它使任何人都能轻松地从数据库中检索所需信息。近年来，许多现有方法利用大型语言模型（LLMs）强大的理解用户查询和生成相应SQL代码的能力来解决这个问题。然而，LLMs中的参数知识可能不足以覆盖需要基于各种数据库模式（schema）进行推理的各种多样化和领域特定查询，这常常导致生成的SQL不够准确。为了解决这个问题，我们提出构建用于Text-to-SQL的知识库，它是一个基础知识来源，我们可以从中检索和生成给定查询所需的必要知识。特别地，与现有方法不同（它们或手动标注知识，或仅为每个查询生成少量知识），我们的知识库是全面的，它是结合所有可用问题及其相关的数据库模式及其相关知识构建的，并且可以重复用于不同数据集和领域中未曾见过的数据库。我们在多个Text-to-SQL数据集上验证了我们的方法，同时考虑了数据库重叠和非重叠的场景，结果显示其表现显著优于相关基线方法。",
    "keywords": [
      "Text-to-SQL",
      "知识库构建",
      "知识增强",
      "LLMs",
      "数据库模式"
    ],
    "area": [
      "自然语言处理",
      "机器学习",
      "大模型"
    ],
    "content": "Text-to-SQL旨在将自然语言查询转换为SQL语句，这非常实用，因为它使任何人都能轻松地从数据库中检索所需信息。近年来，许多现有方法利用大型语言模型（LLMs）强大的理解用户查询和生成相应SQL代码的能力来解决这个问题。然而，LLMs中的参数知识可能不足以覆盖需要基于各种数据库模式（schema）进行推理的各种多样化和领域特定查询，这常常导致生成的SQL不够准确。为了解决这个问题，我们提出构建用于Text-to-SQL的知识库，它是一个基础知识来源，我们可以从中检索和生成给定查询所需的必要知识。特别地，与现有方法不同（它们或手动标注知识，或仅为每个查询生成少量知识），我们的知识库是全面的，它是结合所有可用问题及其相关的数据库模式及其相关知识构建的，并且可以重复用于不同数据集和领域中未曾见过的数据库。我们在多个Text-to-SQL数据集上验证了我们的方法，同时考虑了数据库重叠和非重叠的场景，结果显示其表现显著优于相关基线方法。",
    "published_time": "2025-05-28T08:17:58.000Z",
    "download_time": "2025-05-29 07:13:16",
    "visual_resource": [
      "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.22096.png"
    ],
    "extra": {
      "url": "https://huggingface.co/papers/2505.22096",
      "arxiv_url": "https://arxiv.org/abs/2505.22096"
    }
  },
  {
    "id": "2505.21062",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2505.21062",
    "title": "逆向虚拟试穿：从穿着衣服的个体图像中生成多类别产品样式图像",
    "summary": "虚拟试穿（VTON）系统旨在将一件服装渲染到目标人物图像上，与此不同，本文处理一项新颖的任务——虚拟脱衣（VTOFF），它解决的是一个逆向问题：从穿着衣服的个体的真实世界照片中生成标准化的服装产品图像。与VTON必须解决多样的姿态和样式变化不同，VTOFF受益于一致且明确定义的输出格式——通常是服装的平铺式表示——这使其成为数据生成和数据集增强的有前途的工具。然而，现有的VTOFF方法面临两个主要限制：(i) 难以将服装特征与遮挡和复杂姿态分离，经常导致视觉伪影，以及 (ii) 仅限于单类别服装（例如，仅限上半身衣物），限制了泛化能力。为解决这些挑战，我们提出了一种文本增强的多类别虚拟脱衣（TEMU-VTOFF）方法，这是一种新颖的架构，其核心是一个基于双DiT的骨干网络，并带有改进的多模态注意力机制，用于鲁棒的服装特征提取。我们的架构被设计为接收来自图像、文本和掩码等多种模态的服装信息，以适应多类别设置。最后，我们提出了一个额外的对齐模块，以进一步细化生成的视觉细节。在VITON-HD和Dress Code数据集上的实验表明，TEMU-VTOFF在VTOFF任务上达到了新的最先进水平，显著提高了视觉质量以及与目标服装的逼真度。",
    "keywords": [
      "虚拟脱衣 (VTOFF)",
      "多类别",
      "图像生成",
      "逆向问题",
      "多模态"
    ],
    "area": [
      "计算机视觉",
      "深度学习",
      "生成式AI"
    ],
    "content": "虚拟试穿（VTON）系统旨在将一件服装渲染到目标人物图像上，与此不同，本文处理一项新颖的任务——虚拟脱衣（VTOFF），它解决的是一个逆向问题：从穿着衣服的个体的真实世界照片中生成标准化的服装产品图像。与VTON必须解决多样的姿态和样式变化不同，VTOFF受益于一致且明确定义的输出格式——通常是服装的平铺式表示——这使其成为数据生成和数据集增强的有前途的工具。然而，现有的VTOFF方法面临两个主要限制：(i) 难以将服装特征与遮挡和复杂姿态分离，经常导致视觉伪影，以及 (ii) 仅限于单类别服装（例如，仅限上半身衣物），限制了泛化能力。为解决这些挑战，我们提出了一种文本增强的多类别虚拟脱衣（TEMU-VTOFF）方法，这是一种新颖的架构，其核心是一个基于双DiT的骨干网络，并带有改进的多模态注意力机制，用于鲁棒的服装特征提取。我们的架构被设计为接收来自图像、文本和掩码等多种模态的服装信息，以适应多类别设置。最后，我们提出了一个额外的对齐模块，以进一步细化生成的视觉细节。在VITON-HD和Dress Code数据集上的实验表明，TEMU-VTOFF在VTOFF任务上达到了新的最先进水平，显著提高了视觉质量以及与目标服装的逼真度。",
    "published_time": "2025-05-27T11:47:51.000Z",
    "download_time": "2025-05-29 07:13:31",
    "visual_resource": [
      "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.21062.png"
    ],
    "extra": {
      "url": "https://huggingface.co/papers/2505.21062",
      "arxiv_url": "https://arxiv.org/abs/2505.21062"
    }
  },
  {
    "id": "2505.19377",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2505.19377",
    "title": "绝对坐标使运动生成更容易",
    "summary": "最先进的文本到运动生成模型依赖于 HumanML3D 推广的、具有运动学感知能力的局部相对运动表示，该表示将运动编码为相对于骨盆和前一帧，并具有内置冗余。虽然这种设计简化了早期生成模型的训练，但它给扩散模型带来了关键限制，并阻碍了其在下游任务中的应用。在这项工作中，我们重新审视了运动表示，并提出了一种针对文本到运动生成的、被长期放弃但被彻底简化的替代方案：全局空间中的绝对关节坐标。通过对设计选择进行系统分析，我们表明，即使采用简单的 Transformer 主干网络且不使用辅助的运动学感知损失，这种表达方式也能显著提高运动保真度、改善文本对齐，并具有强大的可扩展性。此外，我们的表达方式自然地支持文本驱动的运动控制以及时间/空间编辑等下游任务，无需额外的针对特定任务的重新设计以及昂贵的来自控制信号的分类器指导生成。最后，我们展示了直接从文本生成运动中的 SMPL-H 网格顶点的良好泛化能力，为未来的研究和运动相关应用奠定了坚实基础。",
    "keywords": [
      "文本到运动生成",
      "绝对关节坐标",
      "运动表示",
      "局部相对运动",
      "下游任务"
    ],
    "area": [
      "生成式AI",
      "多模态",
      "深度学习"
    ],
    "content": "最先进的文本到运动生成模型依赖于 HumanML3D 推广的、具有运动学感知能力的局部相对运动表示，该表示将运动编码为相对于骨盆和前一帧，并具有内置冗余。虽然这种设计简化了早期生成模型的训练，但它给扩散模型带来了关键限制，并阻碍了其在下游任务中的应用。在这项工作中，我们重新审视了运动表示，并提出了一种针对文本到运动生成的、被长期放弃但被彻底简化的替代方案：全局空间中的绝对关节坐标。通过对设计选择进行系统分析，我们表明，即使采用简单的 Transformer 主干网络且不使用辅助的运动学感知损失，这种表达方式也能显著提高运动保真度、改善文本对齐，并具有强大的可扩展性。此外，我们的表达方式自然地支持文本驱动的运动控制以及时间/空间编辑等下游任务，无需额外的针对特定任务的重新设计以及昂贵的来自控制信号的分类器指导生成。最后，我们展示了直接从文本生成运动中的 SMPL-H 网格顶点的良好泛化能力，为未来的研究和运动相关应用奠定了坚实基础。",
    "published_time": "2025-05-26T00:36:00.000Z",
    "download_time": "2025-05-29 07:13:48",
    "visual_resource": [
      "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.19377.png"
    ],
    "extra": {
      "url": "https://huggingface.co/papers/2505.19377",
      "arxiv_url": "https://arxiv.org/abs/2505.19377"
    }
  },
  {
    "id": "2505.19235",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2505.19235",
    "title": "CoreMatching: 一种结合Token与神经元剪枝的协同自适应稀疏推理框架，用于视觉-语言模型的全面加速",
    "summary": "视觉-语言模型 (VLM) 在各种任务中表现出色，但面临高昂的时空推理成本。Token 稀疏性缓解了 Token 使用中的低效问题，而神经元稀疏性则减少了高维计算，两者都为提高效率提供了有前景的解决方案。近年来，这两种稀疏范式在很大程度上是并行发展的，由此产生了它们独立运作的主流假设。然而，一个基本却未得到充分探索的问题依然存在：它们真的各自独立运作吗，还是存在尚未被揭示的更深层潜在相互作用？在本文中，我们首次对这一问题进行了全面探究。通过引入和分析核心神经元（Core Neurons）与核心 Token（Core Tokens）之间的匹配机制，我们发现对于推理而言，关键神经元和 Token 之间存在相互影响和强化的关系。基于这一洞察，我们提出了 CoreMatching，一个协同自适应稀疏推理框架，它利用 Token 和神经元稀疏性之间的协同作用来提高推理效率。通过理论分析和效率评估，我们证明了所提出的方法在十个图像理解任务和三种硬件设备上超越了现有最佳基线。值得注意的是，在 NVIDIA Titan Xp 上，它实现了 5 倍的 FLOPs 降低和 10 倍的整体加速。代码已在 https://github.com/wangqinsi1/2025-ICML-CoreMatching/tree/main 发布。",
    "keywords": [
      "VLMs",
      "Sparse Inference",
      "Token Pruning",
      "Neuron Pruning",
      "CoreMatching"
    ],
    "area": [
      "多模态",
      "深度学习",
      "计算机视觉"
    ],
    "content": "视觉-语言模型 (VLM) 在各种任务中表现出色，但面临高昂的时空推理成本。Token 稀疏性缓解了 Token 使用中的低效问题，而神经元稀疏性则减少了高维计算，两者都为提高效率提供了有前景的解决方案。近年来，这两种稀疏范式在很大程度上是并行发展的，由此产生了它们独立运作的主流假设。然而，一个基本却未得到充分探索的问题依然存在：它们真的各自独立运作吗，还是存在尚未被揭示的更深层潜在相互作用？在本文中，我们首次对这一问题进行了全面探究。通过引入和分析核心神经元（Core Neurons）与核心 Token（Core Tokens）之间的匹配机制，我们发现对于推理而言，关键神经元和 Token 之间存在相互影响和强化的关系。基于这一洞察，我们提出了 CoreMatching，一个协同自适应稀疏推理框架，它利用 Token 和神经元稀疏性之间的协同作用来提高推理效率。通过理论分析和效率评估，我们证明了所提出的方法在十个图像理解任务和三种硬件设备上超越了现有最佳基线。值得注意的是，在 NVIDIA Titan Xp 上，它实现了 5 倍的 FLOPs 降低和 10 倍的整体加速。代码已在 https://github.com/wangqinsi1/2025-ICML-CoreMatching/tree/main 发布。",
    "published_time": "2025-05-25T17:16:34.000Z",
    "download_time": "2025-05-29 07:14:02",
    "visual_resource": [
      "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.19235.png"
    ],
    "extra": {
      "url": "https://huggingface.co/papers/2505.19235",
      "arxiv_url": "https://arxiv.org/abs/2505.19235"
    }
  },
  {
    "id": "2505.17855",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2505.17855",
    "title": "解释自动化事实核查中不确定性的来源",
    "summary": "理解模型对其预测的不确定性来源对于有效的人机协作至关重要。先前工作提出了使用数值不确定性或模糊表达（如“我不确定，但……”），但这些方法未能解释源于证据冲突的不确定性，导致用户无法解决分歧或依赖输出。我们引入了 CLUE（冲突与一致性感知语言模型不确定性解释），这是首个通过以下方式生成模型不确定性自然语言解释的框架：(i) 以无监督方式识别文本片段之间揭示主张-证据或证据间冲突与一致性关系的联系，这些关系驱动着模型的预测不确定性；(ii) 通过提示和注意力导向生成解释，以语言形式阐述这些关键的交互。在三种语言模型和两个事实核查数据集上，我们表明 CLUE 生成的解释比没有文本片段交互指导的直接提示方式，更能忠实于模型的不确定性，也与事实核查决策更一致。人类评估者认为我们的解释比该基线方法更有帮助、信息量更大、更少冗余且与输入更具逻辑一致性。CLUE 无需微调或改变模型架构，使其对于任何白盒语言模型都即插即用。通过将不确定性明确关联到证据冲突，它为事实核查提供了实用的支持，并易于推广到其他需要对复杂信息进行推理的任务。",
    "keywords": [
      "自动化事实核查",
      "不确定性解释",
      "语言模型",
      "证据冲突",
      "自然语言解释"
    ],
    "area": [
      "自然语言处理",
      "大模型",
      "人工智能"
    ],
    "content": "理解模型对其预测的不确定性来源对于有效的人机协作至关重要。先前工作提出了使用数值不确定性或模糊表达（如“我不确定，但……”），但这些方法未能解释源于证据冲突的不确定性，导致用户无法解决分歧或依赖输出。我们引入了 CLUE（冲突与一致性感知语言模型不确定性解释），这是首个通过以下方式生成模型不确定性自然语言解释的框架：(i) 以无监督方式识别文本片段之间揭示主张-证据或证据间冲突与一致性关系的联系，这些关系驱动着模型的预测不确定性；(ii) 通过提示和注意力导向生成解释，以语言形式阐述这些关键的交互。在三种语言模型和两个事实核查数据集上，我们表明 CLUE 生成的解释比没有文本片段交互指导的直接提示方式，更能忠实于模型的不确定性，也与事实核查决策更一致。人类评估者认为我们的解释比该基线方法更有帮助、信息量更大、更少冗余且与输入更具逻辑一致性。CLUE 无需微调或改变模型架构，使其对于任何白盒语言模型都即插即用。通过将不确定性明确关联到证据冲突，它为事实核查提供了实用的支持，并易于推广到其他需要对复杂信息进行推理的任务。",
    "published_time": "2025-05-23T13:06:43.000Z",
    "download_time": "2025-05-29 07:14:18",
    "visual_resource": [
      "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.17855.png"
    ],
    "extra": {
      "url": "https://huggingface.co/papers/2505.17855",
      "arxiv_url": "https://arxiv.org/abs/2505.17855"
    }
  },
  {
    "id": "2505.15561",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2505.15561",
    "title": "RAG 系统存在位置偏差问题吗？",
    "summary": "检索增强生成（Retrieval Augmented Generation, RAG）通过将从外部语料库检索到的文本段落添加到大型语言模型（LLM）的提示中，从而提高LLM的准确性。本文研究了位置偏差——即LLM根据信息在提示中的位置赋予其不同权重的倾向——如何不仅影响LLM利用相关段落的能力，还影响其对干扰性段落的敏感性。通过在三个基准数据集上的广泛实验，我们表明，最先进的检索流程在试图检索相关段落的同时，系统性地将高度干扰性的段落置于靠前的位置，超过60%的查询在其检索到的前10个段落中至少包含一个高度干扰性段落。因此，在真实场景中，LLM位置偏差的影响实际上是微不足道的，这与相关工作在受控设置下报告的非常显著的结果不同，因为相关段落和干扰性段落在这类位置上的影响都会受到削弱。事实上，我们的研究发现，试图根据LLM的位置偏好重新排列段落的复杂策略，其表现并不优于随机打乱。",
    "keywords": [
      "RAG",
      "LLM",
      "位置偏差",
      "检索增强生成",
      "干扰信息"
    ],
    "area": [
      "大模型",
      "生成式AI",
      "自然语言处理"
    ],
    "content": "检索增强生成（Retrieval Augmented Generation, RAG）通过将从外部语料库检索到的文本段落添加到大型语言模型（LLM）的提示中，从而提高LLM的准确性。本文研究了位置偏差——即LLM根据信息在提示中的位置赋予其不同权重的倾向——如何不仅影响LLM利用相关段落的能力，还影响其对干扰性段落的敏感性。通过在三个基准数据集上的广泛实验，我们表明，最先进的检索流程在试图检索相关段落的同时，系统性地将高度干扰性的段落置于靠前的位置，超过60%的查询在其检索到的前10个段落中至少包含一个高度干扰性段落。因此，在真实场景中，LLM位置偏差的影响实际上是微不足道的，这与相关工作在受控设置下报告的非常显著的结果不同，因为相关段落和干扰性段落在这类位置上的影响都会受到削弱。事实上，我们的研究发现，试图根据LLM的位置偏好重新排列段落的复杂策略，其表现并不优于随机打乱。",
    "published_time": "2025-05-21T14:18:01.000Z",
    "download_time": "2025-05-29 07:14:36",
    "visual_resource": [
      "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.15561.png"
    ],
    "extra": {
      "url": "https://huggingface.co/papers/2505.15561",
      "arxiv_url": "https://arxiv.org/abs/2505.15561"
    }
  },
  {
    "id": "2505.21501",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2505.21501",
    "title": "带自蒸馏寄存器的视觉Transformer",
    "summary": "视觉Transformer (ViT) 已成为视觉处理任务的主流架构，随着训练数据和模型规模的增加，展现出出色的可扩展性。然而，最近的研究发现 ViT 中会出现与局部语义不符的伪影（artifact）标记。这些异常标记会降低 ViT 在需要细粒度定位或结构一致性的任务中的性能。解决此问题的一种有效方法是向 ViT 添加寄存器（register）标记，这些标记在训练期间隐式地“吸收”伪影项。鉴于存在各种大规模预训练的 ViT 模型，本文旨在为其配备此类寄存器标记，而无需从头开始对其进行重新训练，考虑到模型的规模，这通常是不可行的。具体来说，我们提出了 后验寄存器 (Post Hoc Registers, PH-Reg) 方法，这是一种高效的自蒸馏方法，可以将寄存器整合到现有的 ViT 中，而无需额外的标注数据和全面再训练。PH-Reg 从相同的预训练 ViT 初始化教师网络和学生网络。教师网络保持冻结和不变，而学生网络则新增了随机初始化的寄存器标记。通过对教师网络的输入应用测试时增强（test-time augmentation），我们生成了无伪影的降噪密集嵌入（dense embeddings），然后仅使用这些嵌入来优化学生网络中一小部分未冻结的权重。我们证明了我们的方法可以有效减少伪影标记数量，并在零样本（zero-shot）和线性探测（linear probing）设置下改进学生 ViT 的分割和深度预测性能。",
    "keywords": [
      "Vision Transformers",
      "Registers",
      "Self-Distillation",
      "Artifact Tokens",
      "Pre-trained Models"
    ],
    "area": [
      "计算机视觉",
      "深度学习",
      "人工智能"
    ],
    "content": "视觉Transformer (ViT) 已成为视觉处理任务的主流架构，随着训练数据和模型规模的增加，展现出出色的可扩展性。然而，最近的研究发现 ViT 中会出现与局部语义不符的伪影（artifact）标记。这些异常标记会降低 ViT 在需要细粒度定位或结构一致性的任务中的性能。解决此问题的一种有效方法是向 ViT 添加寄存器（register）标记，这些标记在训练期间隐式地“吸收”伪影项。鉴于存在各种大规模预训练的 ViT 模型，本文旨在为其配备此类寄存器标记，而无需从头开始对其进行重新训练，考虑到模型的规模，这通常是不可行的。具体来说，我们提出了 后验寄存器 (Post Hoc Registers, PH-Reg) 方法，这是一种高效的自蒸馏方法，可以将寄存器整合到现有的 ViT 中，而无需额外的标注数据和全面再训练。PH-Reg 从相同的预训练 ViT 初始化教师网络和学生网络。教师网络保持冻结和不变，而学生网络则新增了随机初始化的寄存器标记。通过对教师网络的输入应用测试时增强（test-time augmentation），我们生成了无伪影的降噪密集嵌入（dense embeddings），然后仅使用这些嵌入来优化学生网络中一小部分未冻结的权重。我们证明了我们的方法可以有效减少伪影标记数量，并在零样本（zero-shot）和线性探测（linear probing）设置下改进学生 ViT 的分割和深度预测性能。",
    "published_time": "2025-05-27T17:59:41.000Z",
    "download_time": "2025-05-29 07:14:49",
    "visual_resource": [
      "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.21501.png"
    ],
    "extra": {
      "url": "https://huggingface.co/papers/2505.21501",
      "arxiv_url": "https://arxiv.org/abs/2505.21501"
    }
  },
  {
    "id": "2505.20052",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2505.20052",
    "title": "Ankh3：通过序列去噪和补全的多任务预训练增强蛋白质表征",
    "summary": "蛋白质语言模型 (PLMs) 已成为检测蛋白质序列复杂模式的强大工具。然而，PLMs 充分捕捉蛋白质序列信息的能力可能因专注于单一预训练任务而受到限制。尽管增加数据模态或监督目标可以提高 PLMs 的性能，但 pre-training 通常仍专注于对受损序列进行去噪。为了拓展 PLMs 的边界，我们的研究探索了一种多任务预训练策略。我们开发了 Ankh3 模型，该模型针对两个目标联合优化：具有多种掩码概率的掩码语言建模，以及仅依赖蛋白质序列作为输入的蛋白质序列补全。这种多任务 pre-training 表明，PLMs 仅凭蛋白质序列就能学习到更丰富、更具泛化性的表征。结果表明，在二级结构预测、荧光、GB1 适应度和接触预测等下游任务中性能有所提升。多任务的整合使得模型对蛋白质特性有了更全面的理解，从而带来了更稳健和准确的预测。",
    "keywords": [
      "蛋白质语言模型",
      "多任务预训练",
      "蛋白质表征",
      "序列学习",
      "下游任务"
    ],
    "area": [
      "深度学习",
      "机器学习",
      "人工智能"
    ],
    "content": "蛋白质语言模型 (PLMs) 已成为检测蛋白质序列复杂模式的强大工具。然而，PLMs 充分捕捉蛋白质序列信息的能力可能因专注于单一预训练任务而受到限制。尽管增加数据模态或监督目标可以提高 PLMs 的性能，但 pre-training 通常仍专注于对受损序列进行去噪。为了拓展 PLMs 的边界，我们的研究探索了一种多任务预训练策略。我们开发了 Ankh3 模型，该模型针对两个目标联合优化：具有多种掩码概率的掩码语言建模，以及仅依赖蛋白质序列作为输入的蛋白质序列补全。这种多任务 pre-training 表明，PLMs 仅凭蛋白质序列就能学习到更丰富、更具泛化性的表征。结果表明，在二级结构预测、荧光、GB1 适应度和接触预测等下游任务中性能有所提升。多任务的整合使得模型对蛋白质特性有了更全面的理解，从而带来了更稳健和准确的预测。",
    "published_time": "2025-05-26T14:41:10.000Z",
    "download_time": "2025-05-29 07:15:06",
    "visual_resource": [
      "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.20052.png"
    ],
    "extra": {
      "url": "https://huggingface.co/papers/2505.20052",
      "arxiv_url": "https://arxiv.org/abs/2505.20052"
    }
  },
  {
    "id": "2505.20036",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2505.20036",
    "title": "超越简单拼接：公平评估 PLM 架构用于多链蛋白-蛋白相互作用预测",
    "summary": "蛋白-蛋白相互作用（PPIs）是众多细胞过程的基础，其特征描述对于理解疾病机制和指导药物发现至关重要。虽然蛋白质语言模型（PLMs）在预测蛋白质结构和功能方面已取得显著成功，但它们在基于序列的 PPI 结合亲和力预测方面的应用仍相对有待深入探索。这一差距通常归因于高质量、严格精炼数据集的稀缺性以及对简单拼接蛋白质表示策略的依赖。在本工作中，我们解决了这些局限性。首先，我们通过解决多链蛋白质相互作用的注释不一致和重复条目问题，构建了一个精心整理的 PPB-Affinity 数据集版本，共包含 8,207 个独特的蛋白-蛋白相互作用条目。该数据集采用了严格的、小于等于 30% 的序列同一性阈值，以确保数据集能够稳健地划分为训练集、验证集和测试集，从而最大程度地减少数据泄露。其次，我们提出并系统评估了四种用于将 PLMs 适配到 PPI 结合亲和力预测的架构：嵌入层拼接（EC）、序列拼接（SC）、分层池化（HP）和池化注意力相加（PAD）。这些架构使用两种训练方法进行了评估：全微调和一种在冻结的 PLM 特征上使用 ConvBERT 头部的轻量级方法。我们对多种领先的 PLMs（ProtT5、ESM2、Ankh、Ankh2 和 ESM3）进行的综合实验表明，HP 和 PAD 架构始终优于传统的拼接方法，在 Spearman 相关系数方面实现了高达 12% 的提升。这些结果突显了需要复杂的架构设计来充分利用 PLMs 的能力进行细致的 PPI 结合亲和力预测。",
    "keywords": [
      "Protein-Protein Interaction",
      "Protein Language Models",
      "Deep Learning Architectures",
      "Binding Affinity Prediction",
      "Datasets"
    ],
    "area": [
      "深度学习",
      "机器学习",
      "自然语言处理"
    ],
    "content": "蛋白-蛋白相互作用（PPIs）是众多细胞过程的基础，其特征描述对于理解疾病机制和指导药物发现至关重要。虽然蛋白质语言模型（PLMs）在预测蛋白质结构和功能方面已取得显著成功，但它们在基于序列的 PPI 结合亲和力预测方面的应用仍相对有待深入探索。这一差距通常归因于高质量、严格精炼数据集的稀缺性以及对简单拼接蛋白质表示策略的依赖。在本工作中，我们解决了这些局限性。首先，我们通过解决多链蛋白质相互作用的注释不一致和重复条目问题，构建了一个精心整理的 PPB-Affinity 数据集版本，共包含 8,207 个独特的蛋白-蛋白相互作用条目。该数据集采用了严格的、小于等于 30% 的序列同一性阈值，以确保数据集能够稳健地划分为训练集、验证集和测试集，从而最大程度地减少数据泄露。其次，我们提出并系统评估了四种用于将 PLMs 适配到 PPI 结合亲和力预测的架构：嵌入层拼接（EC）、序列拼接（SC）、分层池化（HP）和池化注意力相加（PAD）。这些架构使用两种训练方法进行了评估：全微调和一种在冻结的 PLM 特征上使用 ConvBERT 头部的轻量级方法。我们对多种领先的 PLMs（ProtT5、ESM2、Ankh、Ankh2 和 ESM3）进行的综合实验表明，HP 和 PAD 架构始终优于传统的拼接方法，在 Spearman 相关系数方面实现了高达 12% 的提升。这些结果突显了需要复杂的架构设计来充分利用 PLMs 的能力进行细致的 PPI 结合亲和力预测。",
    "published_time": "2025-05-26T14:23:08.000Z",
    "download_time": "2025-05-29 07:15:24",
    "visual_resource": [
      "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.20036.png"
    ],
    "extra": {
      "url": "https://huggingface.co/papers/2505.20036",
      "arxiv_url": "https://arxiv.org/abs/2505.20036"
    }
  },
  {
    "id": "2505.19954",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2505.19954",
    "title": "一种基于强化优化大语言模型推理的神经退行性痴呆可解释诊断框架",
    "summary": "神经退行性痴呆的鉴别诊断是一项具有挑战性的临床任务，主要原因是症状表现的重叠以及结构性神经影像中观察到的相似模式。为了提高诊断效率和准确性，已经提出了基于深度学习的方法，例如卷积神经网络和视觉Transformer，用于脑部MRI的自动分类。然而，尽管这些模型具有很强的预测性能，但由于其不透明的决策过程，临床应用受到限制。在本文中，我们提出一种框架，整合两个核心组件以增强诊断透明性。首先，我们引入了一个模块化流程，用于将三维T1加权脑部MRI转换为文本形式的放射学报告。其次，我们探索了现代大语言模型（LLMs）基于生成的报告辅助临床医生对额颞叶痴呆亚型、阿尔茨海默病和正常衰老进行鉴别诊断的潜力。为了弥合预测准确性和可解释性之间的差距，我们采用强化学习来激励LLMs进行诊断推理。我们的方法无需监督的推理轨迹或从大型模型中蒸馏，即可使基于神经影像学发现的结构化诊断理由得以产生。与追溯解释模型决策的后验可解释性方法不同，我们的框架在推理过程中生成诊断理由，从而产生因果基础的解释，这些解释告知并指导模型的决策过程。通过这种方式，我们的框架在提供支持其诊断结论的理由的同时，也达到了现有深度学习方法的诊断性能。",
    "keywords": [
      "神经退行性痴呆",
      "可解释AI",
      "大语言模型",
      "强化学习",
      "神经影像"
    ],
    "area": [
      "大模型",
      "强化学习",
      "计算机视觉"
    ],
    "content": "神经退行性痴呆的鉴别诊断是一项具有挑战性的临床任务，主要原因是症状表现的重叠以及结构性神经影像中观察到的相似模式。为了提高诊断效率和准确性，已经提出了基于深度学习的方法，例如卷积神经网络和视觉Transformer，用于脑部MRI的自动分类。然而，尽管这些模型具有很强的预测性能，但由于其不透明的决策过程，临床应用受到限制。在本文中，我们提出一种框架，整合两个核心组件以增强诊断透明性。首先，我们引入了一个模块化流程，用于将三维T1加权脑部MRI转换为文本形式的放射学报告。其次，我们探索了现代大语言模型（LLMs）基于生成的报告辅助临床医生对额颞叶痴呆亚型、阿尔茨海默病和正常衰老进行鉴别诊断的潜力。为了弥合预测准确性和可解释性之间的差距，我们采用强化学习来激励LLMs进行诊断推理。我们的方法无需监督的推理轨迹或从大型模型中蒸馏，即可使基于神经影像学发现的结构化诊断理由得以产生。与追溯解释模型决策的后验可解释性方法不同，我们的框架在推理过程中生成诊断理由，从而产生因果基础的解释，这些解释告知并指导模型的决策过程。通过这种方式，我们的框架在提供支持其诊断结论的理由的同时，也达到了现有深度学习方法的诊断性能。",
    "published_time": "2025-05-26T13:18:32.000Z",
    "download_time": "2025-05-29 07:15:41",
    "visual_resource": [
      "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.19954.png"
    ],
    "extra": {
      "url": "https://huggingface.co/papers/2505.19954",
      "arxiv_url": "https://arxiv.org/abs/2505.19954"
    }
  },
  {
    "id": "2505.17190",
    "source": "huggingface",
    "url": "https://huggingface.co/papers/2505.17190",
    "title": "热带注意力：用于组合算法的神经算法推理",
    "summary": "组合优化问题的动态规划（DP）算法在其递归算法中涉及取最大值、最小值和经典加法运算。相关的价值函数对应于最大加半环中的凸多面体。然而，现有的神经算法推理模型依赖于softmax归一化的点积注意力，这种平滑的指数加权会模糊这些尖锐的多面体结构，并在分布外（OOD）设置下评估时出现性能崩溃。我们引入了热带注意力，这是一种新颖的注意力函数，它在热带几何的最大加半环中原生运行。我们证明了热带注意力可以近似DP型组合算法的热带电路。接着我们提出，在算法推理任务中，使用热带Transformer可以增强在长度泛化和值泛化方面的经验性OOD性能，超越softmax基线，同时在对抗性攻击下保持稳定。我们还将对抗性攻击泛化作为神经算法推理基准测试的第三个维度。我们的结果表明，热带注意力恢复了softmax所缺乏的尖锐、尺度不变的推理能力。",
    "keywords": [
      "热带注意力",
      "神经算法推理",
      "组合优化",
      "分布外泛化",
      "最大加半环"
    ],
    "area": [
      "深度学习",
      "机器学习",
      "人工智能"
    ],
    "content": "组合优化问题的动态规划（DP）算法在其递归算法中涉及取最大值、最小值和经典加法运算。相关的价值函数对应于最大加半环中的凸多面体。然而，现有的神经算法推理模型依赖于softmax归一化的点积注意力，这种平滑的指数加权会模糊这些尖锐的多面体结构，并在分布外（OOD）设置下评估时出现性能崩溃。我们引入了热带注意力，这是一种新颖的注意力函数，它在热带几何的最大加半环中原生运行。我们证明了热带注意力可以近似DP型组合算法的热带电路。接着我们提出，在算法推理任务中，使用热带Transformer可以增强在长度泛化和值泛化方面的经验性OOD性能，超越softmax基线，同时在对抗性攻击下保持稳定。我们还将对抗性攻击泛化作为神经算法推理基准测试的第三个维度。我们的结果表明，热带注意力恢复了softmax所缺乏的尖锐、尺度不变的推理能力。",
    "published_time": "2025-05-22T18:01:25.000Z",
    "download_time": "2025-05-29 07:15:52",
    "visual_resource": [
      "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.17190.png"
    ],
    "extra": {
      "url": "https://huggingface.co/papers/2505.17190",
      "arxiv_url": "https://arxiv.org/abs/2505.17190"
    }
  }
]